{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9245ae36",
   "metadata": {},
   "source": [
    "add description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bfc4c3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fbabd2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader('../data/agentic-ai-system.pdf')\n",
    "corpus = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d2c596c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f62912c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Adobe PDF Library 17.0; modified using iText® 5.5.13 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'Adobe InDesign 18.5 (Windows)(Foxit Advanced PDF Editor)', 'creationdate': '2025-04-01T12:11:31+05:30', 'icnappname': 'Foxit Advanced PDF Editor', 'icnappplatform': 'Windows', 'icnappversion': '3.05', 'moddate': 'D:20250424033741', 'trapped': '/False', 'source': '../data/agentic-ai-system.pdf', 'total_pages': 288, 'page': 0, 'page_label': 'i'}, page_content='')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7e6890",
   "metadata": {},
   "source": [
    "Document(metadata={'producer': 'Adobe PDF Library 17.0; modified using iText® 5.5.13 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'Adobe InDesign 18.5 (Windows)(Foxit Advanced PDF Editor)', 'creationdate': '2025-04-01T12:11:31+05:30', 'icnappname': 'Foxit Advanced PDF Editor', 'icnappplatform': 'Windows', 'icnappversion': '3.05', 'moddate': 'D:20250424033741', 'trapped': '/False', 'source': '../data/agentic-ai-system.pdf', 'total_pages': 288, 'page': 0, 'page_label': 'i'}, page_content='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "63ecc163",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus[12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "13400de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1215909a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Adobe PDF Library 17.0; modified using iText® 5.5.13 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'Adobe InDesign 18.5 (Windows)(Foxit Advanced PDF Editor)', 'creationdate': '2025-04-01T12:11:31+05:30', 'icnappname': 'Foxit Advanced PDF Editor', 'icnappplatform': 'Windows', 'icnappversion': '3.05', 'moddate': 'D:20250424033741', 'trapped': '/False', 'source': '../data/agentic-ai-system.pdf', 'total_pages': 288, 'page': 123, 'page_label': '99'}, page_content='Use cases and examples 99\\nserve user needs. In addition to content analysis, reflective chatbots can also assess the effectiveness \\nof their communication styles and language usage. By analyzing user feedback and reactions, they can \\ndetermine which tones, wordings, or levels of formality resonate better with different user groups or \\ncontexts. This insight can then inform the chatbot’s ability to adapt its communication style dynamically, \\nfostering more natural and personalized interactions.\\nMoreover, self-assessment can help chatbots identify knowledge gaps or areas where their understanding \\nis limited. By recognizing instances where they struggle to provide satisfactory responses, chatbots can \\nproactively seek out additional information or consult with human experts to expand their knowledge \\nbase and improve their ability to handle a wider range of queries effectively.\\nSoftware companies such as Zendesk and Drift use AI-powered chatbots that learn from conversations. \\nThese chatbots monitor ratings and comments made by users regarding their satisfaction levels. By \\nreflecting on this feedback, the chatbots can better develop responses and improve their ability to \\nprovide satisfactory solutions in the future. For instance, if a chatbot notices that users frequently \\nexpress frustration or dissatisfaction with its responses on a particular topic, it can analyze those \\nconversations, identify patterns or gaps in its knowledge, and refine its response strategies accordingly. \\nAdditionally, the chatbot could learn to adapt its tone, language, and communication style based on \\nuser preferences and feedback, fostering a more natural and personalized interaction experience.\\nPersonal marketing agents\\nPersonalized marketing also makes use of reflective agents. Reflective agents analyze consumer behavior \\nand feedback for successful marketing strategies. They mull over the successes and failures of past \\ncampaigns to make adjustments based on key performance metrics for upcoming ones.\\nFor example, Amazon uses reflective AI agents that implement studying customer buying trends and \\nreviews to suggest identical products. These continue to learn with the users, thereby perfecting the \\nsuggestions and the parameters for marketing to ensure better sales and customer interaction.\\nPersonalized marketing has become increasingly crucial in today’s competitive business landscape, \\nand reflective agents play a pivotal role in delivering tailored and effective marketing strategies. These \\nagents leverage self-assessment and introspection to analyze consumer behavior, feedback, and the \\nsuccess or failure of past campaigns, enabling them to continuously refine and optimize their marketing \\napproaches. At the core of reflective personal marketing agents is their ability to collect and analyze \\nvast amounts of data on consumer behavior, preferences, and interactions. By studying patterns in \\npurchasing decisions, browsing histories, reviews, and engagement metrics, these agents can gain insights \\ninto what resonates with different consumer segments and what factors drive purchasing decisions.\\nThe key aspect of reflection in personal marketing agents is their ability to evaluate the success or \\nfailure of past marketing campaigns. These agents can analyze key performance indicators (KPIs) \\nsuch as click-through rates, conversion rates, and customer acquisition costs, and correlate them \\nwith the specific strategies, messaging, and targeting employed in each campaign. By introspecting \\non these metrics, the agents can identify which approaches were most effective and which ones fell \\nshort, enabling them to make data-driven adjustments for future campaigns.')"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e3cf7cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Use cases and examples 99\\nserve user needs. In addition to content analysis, reflective chatbots can also assess the effectiveness \\nof their communication styles and language usage. By analyzing user feedback and reactions, they can \\ndetermine which tones, wordings, or levels of formality resonate better with different user groups or \\ncontexts. This insight can then inform the chatbot’s ability to adapt its communication style dynamically, \\nfostering more natural and personalized interactions.\\nMoreover, self-assessment can help chatbots identify knowledge gaps or areas where their understanding \\nis limited. By recognizing instances where they struggle to provide satisfactory responses, chatbots can \\nproactively seek out additional information or consult with human experts to expand their knowledge \\nbase and improve their ability to handle a wider range of queries effectively.\\nSoftware companies such as Zendesk and Drift use AI-powered chatbots that learn from conversations. \\nThese chatbots monitor ratings and comments made by users regarding their satisfaction levels. By \\nreflecting on this feedback, the chatbots can better develop responses and improve their ability to \\nprovide satisfactory solutions in the future. For instance, if a chatbot notices that users frequently \\nexpress frustration or dissatisfaction with its responses on a particular topic, it can analyze those \\nconversations, identify patterns or gaps in its knowledge, and refine its response strategies accordingly. \\nAdditionally, the chatbot could learn to adapt its tone, language, and communication style based on \\nuser preferences and feedback, fostering a more natural and personalized interaction experience.\\nPersonal marketing agents\\nPersonalized marketing also makes use of reflective agents. Reflective agents analyze consumer behavior \\nand feedback for successful marketing strategies. They mull over the successes and failures of past \\ncampaigns to make adjustments based on key performance metrics for upcoming ones.\\nFor example, Amazon uses reflective AI agents that implement studying customer buying trends and \\nreviews to suggest identical products. These continue to learn with the users, thereby perfecting the \\nsuggestions and the parameters for marketing to ensure better sales and customer interaction.\\nPersonalized marketing has become increasingly crucial in today’s competitive business landscape, \\nand reflective agents play a pivotal role in delivering tailored and effective marketing strategies. These \\nagents leverage self-assessment and introspection to analyze consumer behavior, feedback, and the \\nsuccess or failure of past campaigns, enabling them to continuously refine and optimize their marketing \\napproaches. At the core of reflective personal marketing agents is their ability to collect and analyze \\nvast amounts of data on consumer behavior, preferences, and interactions. By studying patterns in \\npurchasing decisions, browsing histories, reviews, and engagement metrics, these agents can gain insights \\ninto what resonates with different consumer segments and what factors drive purchasing decisions.\\nThe key aspect of reflection in personal marketing agents is their ability to evaluate the success or \\nfailure of past marketing campaigns. These agents can analyze key performance indicators (KPIs) \\nsuch as click-through rates, conversion rates, and customer acquisition costs, and correlate them \\nwith the specific strategies, messaging, and targeting employed in each campaign. By introspecting \\non these metrics, the agents can identify which approaches were most effective and which ones fell \\nshort, enabling them to make data-driven adjustments for future campaigns.'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[111].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "18f61263",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [page.page_content for page in corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a574ffbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Fundamentals of Generative AI 10\\n• Domain-specific LLMs: As mentioned earlier, while LLMs are often trained on a large set \\nof open, generally available, web data, they may not perform very well in domain-specific \\nenvironments. While instruction-tuned LLMs are an avenue to make these general-purpose \\nmodels work for domain-specific tasks, researchers have innovated on training domain-specific \\nLLMs from the ground up. This means that these models were pre-trained on highly specialized, \\ndomain knowledge. For example, the BioBERT model is trained on hyper-specialized medical \\ndata, whereas LegalBERT is trained on legal documents. These models are useful for specialized \\ntasks in specific fields such as medicine, law, and finance.\\nLLM-powered AI agents\\nEach of the previously discussed LLM types has its own strengths and weaknesses and is well-suited \\nfor different applications. However, our focus in this book would be to dive deeper into LLM agent \\ncapabilities and explore how advanced systems can be built utilizing them. It is important to note \\nthat LLM agents do not fit neatly into a single category, as they represent an advanced application \\nof LLM technology rather than a specific type of model architecture. Agents are typically built using \\ninstruction-tuned LLMs as their foundation, often combined with additional components and \\ncapabilities as you will learn further in this book.\\nLet us take a look at a simple example to demonstrate the capabilities of an agentic system powered \\nby an LLM. Our example is a travel website that has a Flight Booking Assistant chatbot that is a \\nconversational interface built with an LLM. It can help customers book travel tickets via human-like \\nconversations. In the backend, the chatbot can perform various tasks as the conversation progresses. \\nHere’s what a sample conversation may look like for a customer who is looking to book a flight ticket:\\nFlight Booking Assistant\\nHi, I want to book a flight.\\n🤖 Hello! I’ d be happy to help you book a flight. To get started, could you please tell me your \\ndeparture city and destination?\\nI want to go from San Diego to SFO.\\n🤖 Great, thank you for providing that information. Y ou’re looking to fly from San Diego (SAN) \\nto San Francisco International Airport (SFO). To help you find the best flight options, I’ll \\nneed a few more details.\\n1. What is your preferred travel date?\\n2. Is this a one-way trip or a round trip?\\n3. How many passengers will be traveling?'"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[22]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c870667e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "a5c32a78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Understanding the concept of tool use in agents 111\\nIt is worth noting that not all LLMs are capable or efficient (or rather accurate) in tool/function calling. \\nWhile larger models are more capable of tool calling, some larger models (such as OpenAI’s GPT-4 \\nand -4o, Anthropic’s Claude Sonnet, Haiku, Opus, and Meta’s Llama 3 models) are explicitly trained \\nfor tool calling behavior. While other models are not explicitly trained on tool calling, they may still \\nbe able to achieve similar functionality with aggressive prompt engineering, but with varying degrees \\nof success.\\nDefining tools for agents\\nTools are defined with clear descriptions, typically using docstrings or a JSON schema, to communicate \\ntheir purpose, required inputs, and expected outputs to the agent. There are two main approaches to \\ndefining tools, depending on whether you’re using a framework or working directly with LLM APIs.\\nFramework approach – using docstrings\\nIn frameworks such as CrewAI or LangGraph, tools are defined using docstrings – descriptive text \\nthat appears at the beginning of a function. Here’s an example of a weather lookup tool:\\n1 def weather_lookup(location: str, date: str = None):\\n2     \"\"\"\\n3     A tool that can lookup real-time weather data.\\n4     Arguments:\\n5       location (str): The location to lookup weather for\\n6       date (str) Optional: The date in MM/DD/YYYY format\\n7     \"\"\"\\n8    # function code and logic\\nThe docstring, enclosed within triple quotes (\"\"\"), provides crucial information about the following:\\n• The tool’s purpose\\n• Required and optional arguments\\n• Expected return values\\nThis approach makes tool creation intuitive for developers, as it uses standard programming practices. \\nWhile Python uses triple quotes for docstrings, other programming languages may have different \\nconventions for defining such documentation.'"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[123]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d0dd51a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "document = [\n",
    "            Document(page_content=text, metadata={'page': idx+1}) \n",
    "            for idx, text in enumerate(corpus)\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ae9c8038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'page': 223}, page_content='Managing Safety and Ethical Considerations 210\\nFor example, an agentic AI system in healthcare might not only have access to historical medical \\nrecords for training but also actively manage patient scheduling, treatment plans, and medical device \\nsettings. If such a system mishandles private information, it could autonomously share sensitive medical \\ndetails with unauthorized parties, schedule appointments that reveal confidential conditions, or make \\ntreatment decisions that inadvertently expose protected health information.\\nIn the travel industry, privacy violations could occur when agentic systems go beyond simple data \\nexposure to actively making privacy-compromising decisions. An autonomous travel assistant might \\nnot just leak travel itineraries but could also make bookings that reveal sensitive personal information, \\nautomatically share location data with third parties, or create patterns of behavior that expose confidential \\nbusiness travel or personal relationships. The risks became evident in 2019 when OpenAI’s language \\nmodel was found to have memorized and reproduced portions of its training data such as personal \\ninformation like emails, home addresses, and phone numbers. For agentic systems, similar issues \\ncould lead to automated decisions being made based on memorized private information, potentially \\ncausing systematic privacy violations at scale.\\nAddressing data privacy violations in agentic AI systems requires an enhanced approach beyond \\ntraditional generative AI safeguards. While robust data governance and sanitization remain crucial, \\nagentic systems also need real-time privacy monitoring, decision auditing systems, and automatic \\nprivacy-preserving mechanisms that prevent unauthorized data access or sharing during autonomous \\noperations. Additionally, techniques such as differential privacy must be adapted for dynamic decision-\\nmaking scenarios. Organizations need to implement privacy-aware decision protocols that ensure \\nautonomous actions don’t inadvertently reveal sensitive information through patterns of behavior or \\nchains of decisions, even when individual actions appear privacy-compliant.\\nTo safeguard privacy in these systems, new frameworks must extend beyond traditional data protection \\nmeasures. Teams deploying agentic AI need to scrutinize how autonomous decisions could compromise \\nprivacy across time – watching for subtle patterns that might reveal sensitive information through a \\nseries of seemingly innocent actions. This means rethinking privacy from the ground up: privacy isn’t \\njust about protecting data anymore, but about understanding how chains of autonomous decisions \\ncould inadvertently reveal what should stay hidden.\\nThe most successful deployments of agentic AI will likely be those that make privacy an integral part \\nof their system’s “nervous system” rather than an afterthought. This means building systems that \\ninstinctively protect privacy at every decision point, much like how humans naturally modulate their \\nbehavior to protect sensitive information in different contexts. When privacy becomes part of the \\nagent’s core decision-making process rather than just a compliance checkbox, we can better ensure these \\npowerful systems enhance rather than endanger our privacy rights in an increasingly automated world.\\nIntellectual property risks\\nThe integration of generative AI capabilities into agentic systems introduces complex intellectual \\nproperty challenges that go far beyond traditional content generation concerns. When autonomous \\nagents are empowered to not only create content but also make decisions about how to use, modify, \\nand deploy intellectual property, the stakes become significantly higher.')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document[222]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e5910403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'langchain_core.documents.base.Document'>\n"
     ]
    }
   ],
   "source": [
    "print(type(document[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8b7693",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
