{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9245ae36",
   "metadata": {},
   "source": [
    "add description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "bfc4c3cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "import re\n",
    "from typing import Dict\n",
    "import pprint\n",
    "from langchain import hub\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain_core.documents import Document\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.output_parsers import PydanticOutputParser\n",
    "from langchain_community.tools import DuckDuckGoSearchRun\n",
    "from IPython.display import Image, display\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_core.messages import SystemMessage, AIMessage\n",
    "\n",
    "import pinecone  # Official Pinecone SDK to create/manage index\n",
    "from pinecone import ServerlessSpec\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "import operator\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "from typing import Sequence\n",
    "from langchain_core.messages import BaseMessage\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.metrics.pairwise import euclidean_distances\n",
    "\n",
    "os.environ['GOOGLE_API_KEY'] = os.getenv('GOOGLE_API_KEY')\n",
    "PINECONE_API_KEY=os.getenv('PINECONE_API_KEY')\n",
    "PINECONE_INDEX_ENVIRONMENT=os.getenv('PINECONE_INDEX_ENVIRONMENT')\n",
    "PINECONE_CLOUD = os.getenv('PINECONE_CLOUD')\n",
    "PINECONE_INDEX_NAME = os.getenv('PINECONE_INDEX_NAME')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbabd2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader('../data/agentic-ai-system.pdf')\n",
    "corpus = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2c596c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f62912c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Adobe PDF Library 17.0; modified using iText® 5.5.13 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'Adobe InDesign 18.5 (Windows)(Foxit Advanced PDF Editor)', 'creationdate': '2025-04-01T12:11:31+05:30', 'icnappname': 'Foxit Advanced PDF Editor', 'icnappplatform': 'Windows', 'icnappversion': '3.05', 'moddate': 'D:20250424033741', 'trapped': '/False', 'source': '../data/agentic-ai-system.pdf', 'total_pages': 288, 'page': 0, 'page_label': 'i'}, page_content='')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc7e6890",
   "metadata": {},
   "source": [
    "Document(metadata={'producer': 'Adobe PDF Library 17.0; modified using iText® 5.5.13 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'Adobe InDesign 18.5 (Windows)(Foxit Advanced PDF Editor)', 'creationdate': '2025-04-01T12:11:31+05:30', 'icnappname': 'Foxit Advanced PDF Editor', 'icnappplatform': 'Windows', 'icnappversion': '3.05', 'moddate': 'D:20250424033741', 'trapped': '/False', 'source': '../data/agentic-ai-system.pdf', 'total_pages': 288, 'page': 0, 'page_label': 'i'}, page_content='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63ecc163",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = corpus[12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13400de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "276"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1215909a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'producer': 'Adobe PDF Library 17.0; modified using iText® 5.5.13 ©2000-2018 iText Group NV (AGPL-version)', 'creator': 'Adobe InDesign 18.5 (Windows)(Foxit Advanced PDF Editor)', 'creationdate': '2025-04-01T12:11:31+05:30', 'icnappname': 'Foxit Advanced PDF Editor', 'icnappplatform': 'Windows', 'icnappversion': '3.05', 'moddate': 'D:20250424033741', 'trapped': '/False', 'source': '../data/agentic-ai-system.pdf', 'total_pages': 288, 'page': 123, 'page_label': '99'}, page_content='Use cases and examples 99\\nserve user needs. In addition to content analysis, reflective chatbots can also assess the effectiveness \\nof their communication styles and language usage. By analyzing user feedback and reactions, they can \\ndetermine which tones, wordings, or levels of formality resonate better with different user groups or \\ncontexts. This insight can then inform the chatbot’s ability to adapt its communication style dynamically, \\nfostering more natural and personalized interactions.\\nMoreover, self-assessment can help chatbots identify knowledge gaps or areas where their understanding \\nis limited. By recognizing instances where they struggle to provide satisfactory responses, chatbots can \\nproactively seek out additional information or consult with human experts to expand their knowledge \\nbase and improve their ability to handle a wider range of queries effectively.\\nSoftware companies such as Zendesk and Drift use AI-powered chatbots that learn from conversations. \\nThese chatbots monitor ratings and comments made by users regarding their satisfaction levels. By \\nreflecting on this feedback, the chatbots can better develop responses and improve their ability to \\nprovide satisfactory solutions in the future. For instance, if a chatbot notices that users frequently \\nexpress frustration or dissatisfaction with its responses on a particular topic, it can analyze those \\nconversations, identify patterns or gaps in its knowledge, and refine its response strategies accordingly. \\nAdditionally, the chatbot could learn to adapt its tone, language, and communication style based on \\nuser preferences and feedback, fostering a more natural and personalized interaction experience.\\nPersonal marketing agents\\nPersonalized marketing also makes use of reflective agents. Reflective agents analyze consumer behavior \\nand feedback for successful marketing strategies. They mull over the successes and failures of past \\ncampaigns to make adjustments based on key performance metrics for upcoming ones.\\nFor example, Amazon uses reflective AI agents that implement studying customer buying trends and \\nreviews to suggest identical products. These continue to learn with the users, thereby perfecting the \\nsuggestions and the parameters for marketing to ensure better sales and customer interaction.\\nPersonalized marketing has become increasingly crucial in today’s competitive business landscape, \\nand reflective agents play a pivotal role in delivering tailored and effective marketing strategies. These \\nagents leverage self-assessment and introspection to analyze consumer behavior, feedback, and the \\nsuccess or failure of past campaigns, enabling them to continuously refine and optimize their marketing \\napproaches. At the core of reflective personal marketing agents is their ability to collect and analyze \\nvast amounts of data on consumer behavior, preferences, and interactions. By studying patterns in \\npurchasing decisions, browsing histories, reviews, and engagement metrics, these agents can gain insights \\ninto what resonates with different consumer segments and what factors drive purchasing decisions.\\nThe key aspect of reflection in personal marketing agents is their ability to evaluate the success or \\nfailure of past marketing campaigns. These agents can analyze key performance indicators (KPIs) \\nsuch as click-through rates, conversion rates, and customer acquisition costs, and correlate them \\nwith the specific strategies, messaging, and targeting employed in each campaign. By introspecting \\non these metrics, the agents can identify which approaches were most effective and which ones fell \\nshort, enabling them to make data-driven adjustments for future campaigns.')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[111]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e3cf7cda",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Use cases and examples 99\\nserve user needs. In addition to content analysis, reflective chatbots can also assess the effectiveness \\nof their communication styles and language usage. By analyzing user feedback and reactions, they can \\ndetermine which tones, wordings, or levels of formality resonate better with different user groups or \\ncontexts. This insight can then inform the chatbot’s ability to adapt its communication style dynamically, \\nfostering more natural and personalized interactions.\\nMoreover, self-assessment can help chatbots identify knowledge gaps or areas where their understanding \\nis limited. By recognizing instances where they struggle to provide satisfactory responses, chatbots can \\nproactively seek out additional information or consult with human experts to expand their knowledge \\nbase and improve their ability to handle a wider range of queries effectively.\\nSoftware companies such as Zendesk and Drift use AI-powered chatbots that learn from conversations. \\nThese chatbots monitor ratings and comments made by users regarding their satisfaction levels. By \\nreflecting on this feedback, the chatbots can better develop responses and improve their ability to \\nprovide satisfactory solutions in the future. For instance, if a chatbot notices that users frequently \\nexpress frustration or dissatisfaction with its responses on a particular topic, it can analyze those \\nconversations, identify patterns or gaps in its knowledge, and refine its response strategies accordingly. \\nAdditionally, the chatbot could learn to adapt its tone, language, and communication style based on \\nuser preferences and feedback, fostering a more natural and personalized interaction experience.\\nPersonal marketing agents\\nPersonalized marketing also makes use of reflective agents. Reflective agents analyze consumer behavior \\nand feedback for successful marketing strategies. They mull over the successes and failures of past \\ncampaigns to make adjustments based on key performance metrics for upcoming ones.\\nFor example, Amazon uses reflective AI agents that implement studying customer buying trends and \\nreviews to suggest identical products. These continue to learn with the users, thereby perfecting the \\nsuggestions and the parameters for marketing to ensure better sales and customer interaction.\\nPersonalized marketing has become increasingly crucial in today’s competitive business landscape, \\nand reflective agents play a pivotal role in delivering tailored and effective marketing strategies. These \\nagents leverage self-assessment and introspection to analyze consumer behavior, feedback, and the \\nsuccess or failure of past campaigns, enabling them to continuously refine and optimize their marketing \\napproaches. At the core of reflective personal marketing agents is their ability to collect and analyze \\nvast amounts of data on consumer behavior, preferences, and interactions. By studying patterns in \\npurchasing decisions, browsing histories, reviews, and engagement metrics, these agents can gain insights \\ninto what resonates with different consumer segments and what factors drive purchasing decisions.\\nThe key aspect of reflection in personal marketing agents is their ability to evaluate the success or \\nfailure of past marketing campaigns. These agents can analyze key performance indicators (KPIs) \\nsuch as click-through rates, conversion rates, and customer acquisition costs, and correlate them \\nwith the specific strategies, messaging, and targeting employed in each campaign. By introspecting \\non these metrics, the agents can identify which approaches were most effective and which ones fell \\nshort, enabling them to make data-driven adjustments for future campaigns.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[111].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "901f7bb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8eea1ff5",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_text = ''\n",
    "for page in corpus:\n",
    "    my_text = my_text + page.page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "857ed271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Preface xix\\nPart 1: Foundations of Generative AI and  \\nAgentic Systems\\n1\\nFundamentals of Generative AI 3\\nIntroduction to generative AI 3\\nTypes of generative AI models 4\\nV AEs 5\\nGANs 6\\nAutoregressive models and Transformer \\narchitecture 7\\nLLM-powered AI agents 10\\nApplications of generative AI 16\\nChallenges and limitations of \\ngenerative AI 20\\nQuality of data and bias 21\\nData privacy 21\\nComputational resources 22\\nEthical and social implications 23\\nGeneralization and creativity 23\\nSummary 23\\nQuestions 24\\nAnswers 24\\nFurther reading 24\\nReferences 24\\n2\\nPrinciples of Agentic Systems 27\\nTechnical requirements 28\\nUnderstanding self-governance, \\nagency, and autonomy 28\\nSelf-governance 29\\nAgency 29\\nAutonomy 30\\nExample of agency and autonomy in agents 32\\nReviewing intelligent agents and \\ntheir characteristics 35\\nTable of ContentsTable of Contents xiv\\nExploring the architecture  \\nof agentic systems 36\\nDeliberative architectures 36\\nReactive architectures 38\\nHybrid architectures 39\\nUnderstanding multi-agent systems 40\\nDefinition and characteristics of MASs 42\\nInteraction mechanisms in MASs 43\\nSummary 48\\nQuestions 49\\nAnswers 49\\n3\\nEssential Components of Intelligent Agents 51\\nTechnical requirements 51\\nKnowledge representation in \\nintelligent agents 52\\nSemantic networks 52\\nFrames 54\\nLogic-based representations 55\\nReasoning in intelligent agents 56\\nDeductive reasoning 57\\nInductive reasoning 58\\nAbductive reasoning 59\\nLearning mechanisms for  \\nadaptive agents 61\\nDecision-making and planning in \\nagentic systems 62\\nUtility function 63\\nPlanning algorithms 65\\nEnhancing agent capabilities with \\ngenerative AI 68\\nStart building agentic AI 69\\nSummary 72\\nQuestions 72\\nAnswers 72\\nPart 2: Designing and Implementing Generative \\nAI-Based Agents\\n4\\nReflection and Introspection  \\nin Agents 77\\nTechnical requirements 78\\nThe importance of reflection in agents 78\\nEnhanced decision-making 78\\nAdaptation 79\\nEthical consideration 80\\nHuman-computer interaction 81\\nIntrospection in intelligent agents 82\\nImplementing reflective capabilities 83\\nTraditional reasoning 83\\nMeta-reasoning 83Table of Contents xv\\nSelf-explanation 92\\nSelf-modeling 96\\nUse cases and examples 98\\nCustomer service chatbots 98\\nPersonal marketing agents 99\\nFinancial trading systems 100\\nForecast agents 101\\nPrice strategies in e-commerce 102\\nSummary 103\\nQuestions 104\\nAnswers 104\\n5\\nEnabling Tool Use and Planning in Agents 107\\nTechnical requirements 108\\nUnderstanding the concept of tool \\nuse in agents 108\\nTool and function calling 109\\nDefining tools for agents 111\\nTypes of tools 113\\nThe significance of tools in agentic systems 116\\nPlanning algorithms for agents 117\\nLess practical planning algorithms 117\\nModerately practical planning algorithm – FF 118\\nMost practical planning algorithms 119\\nIntegrating tool use and planning 126\\nReasoning about tools 126\\nPlanning for tool use 128\\nExploring practical implementations 129\\nCrewAI example 129\\nAutoGen example 130\\nLangGraph example 132\\nSummary 134\\nQuestions 135\\nAnswers 135\\n6\\nExploring the Coordinator, Worker, and Delegator Approach 137\\nTechnical requirements 138\\nUnderstanding the CWD model 138\\nKey principles of the CWD model 140\\nThe CWD model for the intelligent travel agent 141\\nDesigning agents with role \\nassignments 143\\nRoles and responsibilities of each agent 146\\nCommunication and collaboration \\nbetween agents 151\\nCommunication 152\\nCoordination mechanism 152\\nNegotiation and conflict resolution 152\\nKnowledge sharing 153\\nImplementing the CWD approach in \\ngenerative AI systems 154\\nSystem prompts and agent behavior 154Table of Contents xvi\\nInstruction formatting 155\\nInteraction patterns 156\\nSummary 157\\nQuestions 157\\nAnswers 158\\n7\\nEffective Agentic System Design Techniques 161\\nTechnical requirements 161\\nFocused system prompts and \\ninstructions for agents 162\\nDefining objectives 162\\nTask specifications 163\\nContextual awareness 165\\nState spaces and  \\nenvironment modeling 167\\nState space representation 167\\nEnvironment modeling 169\\nIntegration and interaction patterns 171\\nMonitoring and adaptation 173\\nAgent memory architecture and \\ncontext management 173\\nShort-term memory (working memory) 174\\nLong-term memory (knowledge base) 175\\nEpisodic memory (interaction history) 176\\nContext management 177\\nIntegration with decision-making 179\\nSequential and parallel processing in \\nagentic workflows 180\\nSequential processing 180\\nParallel processing 181\\nWorkflow optimization 182\\nSummary 184\\nQuestions 184\\nAnswers 185\\nPart 3: Trust, Safety, Ethics, and Applications\\n8\\nBuilding Trust in Generative AI Systems 189\\nTechnical requirements 190\\nImportance of trust in AI 190\\nTechniques for establishing trust 191\\nTransparency and explainability 191\\nDealing with uncertainty and biases 196\\nEffective output communication 197\\nUser control and consent 198\\nEthical development and responsibility 199\\nImplementing transparency and \\nexplainability 200\\nHandling uncertainty and biases 201\\nSummary 202\\nQuestions 203\\nAnswers 203Table of Contents xvii\\n9\\nManaging Safety and \\n Ethical Considerations 205\\nUnderstanding potential  \\nrisks and challenges 206\\nAdversarial attacks 206\\nBias and discrimination 207\\nMisinformation and hallucinations 208\\nData privacy violations 209\\nIntellectual property risks 210\\nEnsuring safe and responsible AI 212\\nExploring ethical guidelines  \\nand frameworks 216\\nHuman-centric design 216\\nAccountability and responsibility 216\\nPrivacy and data protection 216\\nInvolvement of diverse stakeholders 217\\nAddressing privacy and security \\nconcerns 217\\nSummary 218\\nQuestions 219\\nAnswers 219\\n10\\nCommon Use Cases and Applications 221\\nCreative and artistic applications 222\\nEvolution of creative and artistic agents 222\\nReal-world applications 223\\nNatural language processing and \\nconversational agents 225\\nEvolution of language agents 225\\nReal-world applications 226\\nRobotics and autonomous systems 228\\nEvolution of robotic agents 228\\nReal-world applications 229\\nDecision support and optimization 231\\nEvolution of decision support agents 232\\nReal-world applications 232\\nSummary 236\\nQuestions 236\\nAnswers 237\\n11\\nConclusion and Future Outlook 239\\nRecap of key concepts 240\\nEmerging trends and research \\ndirections 241\\nMulti-modal intelligence – integrating diverse \\ninputs 241\\nAdvanced language comprehension 241Table of Contents xviii\\nExperiential learning – reinforcement \\nlearning innovations 242\\nPractical implications across industries 242\\nArtificial general intelligence 243\\nWhat makes AGI different 243\\nThe big challenge 243\\nLearning to learn 243\\nReal-world understanding 244\\nChallenges and opportunities 245\\nSummary 246\\nIndex 249\\nOther Books You May Enjoy 260Preface\\nBuilding Agentic AI Systems is designed to provide both a theoretical foundation and practical \\nguidance on generative AI and agent-based intelligence. Generative AI and agentic systems are at the \\nforefront of the next wave of AI, driving automation, creativity, and decision-making in ways that \\nwere previously unimaginable. By enabling machines to generate text, images, and even strategic plans \\nwhile reasoning and adapting autonomously, these technologies are transforming industries such as \\nhealthcare, finance, and robotics.\\nThe book begins by introducing generative AI, covering key models such as Variational Autoencoders \\n(VA E s), Generative Adversarial Networks (GANs), and autoregressive models. We explore their \\napplications in content creation, design, and scientific research while addressing the limitations and \\nchallenges of these models.\\nNext, we dive into the world of agentic systems, defining concepts such as agency, autonomy, and multi-\\nagent collaboration. We analyze different agent architectures—deliberative, reactive, and hybrid—and \\nexplore how multiple agents can interact, cooperate, and coordinate toward common goals.\\nOnce the foundations are established, we move into practical implementation. We explore how agents \\ncan reflect on their own reasoning processes, plan, and use external tools effectively. This includes \\nhands-on techniques for meta-reasoning, self-explanation, strategic planning, and multi-agent \\ncoordination. The book also introduces best practices for designing intelligent, trustworthy AI agents, \\nbalancing autonomy with control, and ensuring ethical and responsible AI development.\\nTo conclude, we examine real-world use cases and applications across multiple domains, from NLP \\nand robotics to decision support and optimization. We also explore trust, transparency, bias mitigation, \\nand AI safety—key elements for ensuring the reliability of AI-driven systems.\\nThroughout this book, you will find code examples, practical exercises, and implementation strategies \\nto help bridge the gap between theory and real-world application. Whether you are an AI practitioner, \\nresearcher, engineer, or technology leader, this book will equip you with the skills and knowledge to \\nbuild autonomous, adaptive, and intelligent AI agents that can reason, collaborate, and evolve.\\nLet’s embark on this journey together, shaping the future of intelligent systems—one agent at a time.Preface xx\\nWho this book is for\\nThis book is intended for AI practitioners, developers, researchers, engineers, and technology leaders \\nwho want to understand and build AI-driven agents that exhibit autonomy, adaptability, and intelligence. \\nWhether you are a developer looking to integrate generative models into intelligent systems or an \\nAI architect exploring advanced agentic capabilities, this book will equip you with both theoretical \\nfoundations and hands-on implementation strategies.\\nWhat this book covers\\nChapter 1, Fundamentals of Generative AI, introduces generative AI, explaining its core concepts, \\nvarious model types—including V AEs, GANs, and autoregressive models—real-world applications, \\nand challenges such as bias, limitations, and ethical concerns.\\nChapter 2, Principles of Agentic Systems, defines agentic systems, covering agency, autonomy, and the \\nessential characteristics of intelligent agents, including reactivity, proactiveness, and social ability. It \\nalso explores different agent architectures and multi-agent collaboration.\\nChapter 3, Essential Components of Intelligent Agents, details key elements of intelligent agents, \\nincluding knowledge representation, reasoning, learning mechanisms, decision-making, and the role \\nof Generative AI in enhancing agent capabilities.\\nChapter 4, Reflection and Introspection in Agents, explores how intelligent agents analyze their reasoning, \\nlearn from experience, and improve decision-making using techniques such as meta-reasoning, self-\\nexplanation, and self-modeling.\\nChapter 5, Enabling Tool Use and Planning in Agents, discusses how agents leverage external tools, \\nimplement planning algorithms, and integrate tool use with strategic decision-making to improve \\nefficiency and goal achievement.\\nChapter 6, Exploring the Coordinator, Worker, and Delegator Approach, introduces the CWD model \\nfor multi-agent collaboration, explaining how agents take on specialized roles—coordinator, worker, \\nor delegator—to optimize task execution and resource allocation.\\nChapter 7, Effective Agentic System Design Techniques, covers best practices for designing intelligent \\nagents, including focused instructions, setting guardrails and constraints, balancing autonomy and \\ncontrol, and ensuring transparency and accountability.\\nChapter 8, Building Trust in Generative AI Systems, examines techniques for fostering trust in AI, \\nincluding transparency, explainability, handling uncertainty and bias, and designing AI systems that \\nare reliable and interpretable.\\nChapter 9, Managing Safety and Ethical Considerations, addresses the risks and challenges of generative \\nAI, strategies for ensuring responsible AI development, ethical guidelines, and privacy and security \\nconsiderations for AI deployments.Preface xxi\\nChapter 10, Common Use Cases and Applications, showcases real-world applications of Generative \\nAI, covering areas such as creative content generation, conversational AI, robotics, and \\ndecision-support systems.\\nChapter 11, Conclusion and Future Outlook, summarizes key concepts covered in the book, explores \\nemerging trends in generative AI and agentic intelligence, discusses artificial general intelligence \\n(AGI), and highlights future challenges and opportunities in the field.\\nTo get the most out of this book\\nFollowing along will be a bit easier if you have the following:\\n• Familiarity with AI and machine learning concepts : While the book covers foundational \\nprinciples, prior knowledge of AI/ML, deep learning, and Python programming will help you \\nunderstand the more advanced topics.\\n• Hands-on practice: Experiment with the provided code examples and frameworks for building \\nGenerative AI and agentic systems. Setting up a local or cloud-based development environment \\nwill enhance your learning experience.\\n• Think critically about AI ethics and safety : As you explore Generative AI and autonomous \\nagents, consider the implications of trust, bias, and responsible AI design to build intelligent \\nsystems that align with ethical guidelines.\\nSoftware/hardware covered in the book Operating system requirements\\nPython, Jupyter Notebooks, and CrewAI Windows, macOS, Linux\\nDownload the example code files\\nThe code bundle for the book is hosted on GitHub at https://github.com/PacktPublishing/\\nBuilding-Agentic-AI-Systems. We also have other code bundles from our rich catalog of \\nbooks and videos available at https://github.com/PacktPublishing. Check them out!\\nConventions used\\nThere are a number of text conventions used throughout this book.\\nBold: Indicates a new term, an important word, or words that you see onscreen. For instance, words \\nin menus or dialog boxes appear in bold. Here is an example: “Customized onboarding plan: Based \\non the goals and needs identified, create a bespoke onboarding plan that outlines the steps, milestones, \\nand timelines toward achieving the set objectives. ”Preface xxii\\nTips or important notes\\nAppear like this.\\nGet in touch\\nNewsletter: To keep up with the latest developments in the fields of Generative AI and LLMs, subscribe \\nto our weekly newsletter, AI_Distilled, at https://packt.link/817Ur.\\nFeedback from our readers is always welcome.\\nGeneral feedback: If you have questions about any aspect of this book, email us at customercare@\\npacktpub.com and mention the book title in the subject of your message.\\nErrata: Although we have taken every care to ensure the accuracy of our content, mistakes do happen. \\nIf you have found a mistake in this book, we would be grateful if you would report this to us. Please \\nvisit www.packtpub.com/support/errata and fill in the form.\\nPiracy: If you come across any illegal copies of our works in any form on the internet, we would \\nbe grateful if you would provide us with the location address or website name. Please contact us at \\ncopyright@packt.com with a link to the material.\\nIf you are interested in becoming an author: If there is a topic that you have expertise in and you \\nare interested in either writing or contributing to a book, please visit authors.packtpub.com.Preface xxiii\\nShare Your Thoughts\\nOnce you’ve read Building Agentic Systems with Generative AI, we’ d love to hear your thoughts! Please \\nclick here to go straight to the Amazon review page for this book and share \\nyour feedback.\\nY our review is important to us and the tech community and will help us make sure we’re delivering \\nexcellent quality content.Preface xxiv\\nDownload a free PDF copy of this book\\nThanks for purchasing this book!\\nDo you like to read on the go but are unable to carry your print books everywhere?\\nIs your eBook purchase not compatible with the device of your choice?\\nDon’t worry, now with every Packt book you get a DRM-free PDF version of that book at no cost.\\nRead anywhere, any place, on any device. Search, copy, and paste code from your favorite technical \\nbooks directly into your application.\\nThe perks don’t stop there, you can get exclusive access to discounts, newsletters, and great free content \\nin your inbox daily.\\nFollow these simple steps to get the benefits:\\n1. Scan the QR code or visit the link below\\nhttps://packt.link/free-ebook/9781803238753\\n2. Submit your proof of purchase\\n3. That’s it! We’ll send your free PDF and other benefits to your email directlyPart 1:  \\nFoundations of Generative AI \\nand Agentic Systems\\nThis part establishes the fundamental concepts of generative AI and agentic systems, providing you \\nwith a solid theoretical foundation for understanding and developing intelligent, autonomous agents.\\nThis part contains the following chapters:\\n• Chapter 1, Fundamentals of Generative AI\\n• Chapter 2, Principles of Agentic Systems\\n• Chapter 3, Essential Components of Intelligent Agents1\\nFundamentals of Generative AI\\nGenerative AI has quickly become a transformative technology in the field of artificial intelligence (AI) \\nand machine learning, revolutionizing creative processes and problem-solving across diverse industries \\nand use cases. It is pushing the boundaries of autonomy in agent-based intelligent systems. In this chapter, \\nwe will cover the basics of generative AI. We will explore what generative AI is along with a brief history \\nof generative AI models. We will then discuss the different types of generative models, which include \\nvariational autoencoders (VA E s), generative adversarial networks (GANs), autoregressive, and \\nTransformer models. Next, we will delve into the applications of generative AI and wrap up the chapter \\nwith a brief discussion of some of the limitations and challenges related to generative AI.\\nWe will cover the following topics in this introductory chapter that will help set the foundations of generative \\nAI as we explore further the capabilities of autonomous intelligent agents powered by generative AI:\\n• Introduction to generative AI\\n• Types of generative AI models\\n• Applications of generative AI\\n• Challenges and limitations of generative AI\\nBy the end of this chapter, you will have gained a comprehensive understanding of generative AI, \\nincluding its fundamental concepts, diverse applications, and current challenges. Y ou will also learn \\nabout the technology’s potential and limitations, with a particular focus on its critical role in advancing \\nintelligent agents and agentic systems.\\nIntroduction to generative AI\\nGenerative AI refers to a class of AI technologies that is capable of generating various forms of content, \\nincluding but not limited to text, images, audio, and video. These AI systems can generate new content, \\nbased on their training data and input parameters, which usually include text prompts but can also \\ninvolve other forms of input such as images. The recent buzz around generative AI comes from the \\nsimplicity with which new user interfaces powered by this AI technology can create high-quality text, \\ngraphics, and videos in seconds.Fundamentals of Generative AI 4\\nIn very simple terms, generative AI is about making new data that looks like the data from which it has \\nbeen trained. In other words, learning the underlying patterns, structures, and distributions of input data \\nenables a procedure within the model allowing it to generate new data in a similar way. For instance, if \\ntrained on a dataset of human faces, a generative AI model will be able to create completely new faces \\nof people that don’t actually exist in real life but are very realistic. In essence, generative AI models work \\nby learning the probability distribution of a dataset and then sampling from that distribution to create \\nnew instances. This approach is different from discriminative models, whose goal is to learn how to tell \\nclasses of data apart. For example, a discriminative model could be trained to separate pictures of cats \\nand dogs, but a generative model would be trained to make up completely new pictures of cats or dogs.\\nThe concept of generative AI goes a long way back; in fact, it dates back to the time when machine \\nlearning was in its cradle. However, it is only recently that this field has come under the limelight due \\nto neural networks and drastic improvements in computing power over the last 10 years. In the early \\nattempts at generative modeling—Gaussian mixture models and hidden Markov models—many simpler \\nstatistical techniques were involved. Methods of modeling arbitrary complex data distributions have \\nmuch higher potential compatibility with the kinds of methods that were previously dominant but \\nhave recently been overcome by deep learning. Deep learning was therefore a watershed development \\nfor the field of generative AI. Models, such as V AEs, which started appearing around the beginning \\nof the 2010s, were able to leverage deep neural networks to model more complex data distributions. \\nAround that same period, GANs were proposed; for the first time, they offered a new way for two \\nneural networks to work together to create data, using principles from game theory. In a general \\nsense, these breakthroughs took leaps toward the possibilities of making real, high-quality, realistic \\ncreation of data.\\nThis can lead to innovation in most fields across industries, such as healthcare, finance, education, \\ntravel and hospitality, manufacturing, and more. Generative AI in creative industries helps artists and \\ndesigners think outside the box, helping with the conception of new and innovative content. It opens \\nways for new routes of drug discovery and personalized medicine in health. In the business world, \\ngenerative AI works by providing efficient and effective customer engagement through personalized \\ncontent and experiences. The other point involves questioning one’s own stance regarding creativity \\nand originality: when machines are able to pump out very similar material, one is automatically forced \\nto think about what creativity is, who the artist really is, and what the ethical parameters should be \\nfor AI-created content.\\nHaving understood what generative AI is and its brief history, let’s explore the different types of \\ngenerative AI models.\\nTypes of generative AI models\\nGenerative AI is an exciting domain of AI that deals with the generation of new, synthetic data by \\nlearning patterns from existing datasets, aiming to generate outputs that share similar statistical \\nproperties and characteristics with the training data. Here is a broad overview of some of the most \\nprominent types of generative models: V AEs, GANs, and autoregressive models.Types of generative AI models 5\\nVAEs\\nOne of the most popular generative models is the V AE. The core idea behind V AE consists of learning \\na probabilistic mapping between data and a latent space, and vice versa. This means learning how to \\nconvert real data into a simplified representation (such as a compressed form) and then back again \\ninto data that looks real. V AEs are designed to ensure a high likelihood of the data while preserving a \\nwell-structured latent space to enable the generation of new data samples similar to the training data. \\nSome of the most common flavors of V AE are as follows:\\n• VA E: The basic model that compresses and reconstructs data. It gives a framework for generating \\nnew samples out of the learned latent space. The V AE is a generative model that learns to compress \\nand reconstruct data while also learning a probability distribution of the latent space. In simpler \\nterms, a V AE is like a clever algorithm that learns to understand and recreate data. Imagine it \\nas a skilled artist who can compress a detailed painting into a simple sketch (encoding) and \\nthen recreate the full painting from that sketch (decoding). What makes V AEs special is that \\nthey don’t just copy data but also learn the essence of it, allowing them to create new, similar \\ndata. This is like an artist learning not just to copy specific paintings but also to understand the \\nstyle so well that they can paint new, original works in that style. In real life, V AEs have been \\nused in many creative ways. For instance, in drug discovery, V AEs have been used to generate \\nnovel molecular structures. Researchers at AstraZeneca used V AEs to explore chemical space \\nand propose new drug-like molecules with desired properties, potentially accelerating the drug \\ndevelopment process [1].\\n• Beta-V AE: An extension of V AE that introduces a hyperparameter to control explicitly the \\ntrade-off between the reconstruction quality and the disentanglement of the latent space. The \\nmodel undertakes the creation of more interpretable disentangled representations. In simpler \\nterms, Beta-V AE is like a more flexible version of the original V AE. It allows researchers to adjust \\nhow much the model focuses on recreating exact details versus understanding the underlying \\nfeatures of the data. This is similar to teaching an art student to not just copy a painting but \\nalso to understand and separate the key elements such as color, shape, and style. This ability to \\ndisentangle features makes Beta-V AE particularly useful in fields such as computer vision and \\nrobotics. For example, researchers have used Beta-V AE to teach robots to understand objects \\nbetter. By learning to separate features such as size, color, and position, robots can more easily \\nrecognize and manipulate objects in different situations, making them more adaptable and \\nefficient in various tasks [2].\\n• Conditional variational autoencoder (CV AE): A variant that conditions the generation process \\non some extra information, typically class labels, producing not just data similar to the training \\nset but also samples that can then be drawn from specific classes . Think of CV AE as a more \\ncontrolled version of V AE, like an artist who can paint in different styles on demand. Instead \\nof just creating random new paintings, this artist can be told to “Paint a landscape” or “Paint \\na portrait” and they’ll create new art in that specific category. This added control makes CV AE \\nvery useful in practical applications. For instance, in the field of computer games, CV AE has \\nbeen used for game development and procedural content generation with the generation ofFundamentals of Generative AI 6\\ngame elements such as character design, level layouts, music and sound effects, and so on. By \\nproviding different conditions such as “Create a forest level” or “Create a desert level, ” the CV AE \\ncan produce a wide variety of game environments, saving time for designers and enhancing \\nthe player’s experience with more diverse and interesting game worlds [3].\\nGANs\\nA GAN is basically formed by two neural networks: a generator and a discriminator. The generator \\ngenerates synthetic data samples; the other trained neural network should then be able to tell the \\ndifference between real and created samples. While training these networks, they are trained together \\nantagonistically: the generator tries to fool the discriminator, while the discriminator tries rightly to \\nclassify real versus fake data. In this competition, the generator gets better and better at faking data. \\nThe following are some of the different types of GANs:\\n• GAN: The basic model in which the generator and discriminator are trained adversarially; it is the \\nroot model for most innovations in generative modeling. As explained earlier, you can imagine \\nGAN as a game between two players—a counterfeiter (generator) trying to create fake money, \\nand a detective (discriminator) trying to identify the fakes. As they compete, they both get better \\nat their jobs, which means that the counterfeiter gets increasingly better at creating fake money. \\nThis clever setup allows GANs to create incredibly realistic fake data, such as images or sounds [4].\\n• Deep convolutional GAN (DCGAN): This is a refinement of the base GAN model with deep \\nconvolutional neural networks; at the moment, it is one of the best architectures for generating \\nimages of high quality. Think of DCGAN as a more sophisticated artist compared to the basic \\nGAN. It’s like upgrading from simple sketching tools to a full digital art studio, allowing for \\nthe creation of much more detailed and realistic images. DCGANs are particularly good at \\nunderstanding and recreating complex patterns in images [5].\\n• Wasserstein GAN (WGAN): This proposes a different loss function with the Wasserstein distance. \\nThis removes problems while training with a GAN, hence making training more stable and \\nimproving sample quality. This helps measure the distance between two probability distributions \\nbetter. WGAN is like giving the artist (generator) and critic (discriminator) in a GAN a better \\nway to communicate and evaluate each other’s work. Instead of just saying “good” or “bad,”  \\nthey can now give more nuanced feedback, such as “You’re getting warmer” or “You’re way off.”  \\nThis leads to more consistent improvement and high-quality results. In practical applications, \\nWGANs have been used in medical imaging to generate synthetic medical images for training \\npurposes. This helps in creating larger, more diverse datasets for training diagnostic AI systems, \\npotentially improving their accuracy in detecting diseases from scans and X-rays [6].\\n• StyleGAN: This generates high-quality realistic images. The model is especially good at handling \\nstyle and content separately. Progressions offered by the introductions of StyleGAN2 and \\nStyleGAN3 are still aimed at improving image fidelity and realism. Think of StyleGAN as an \\nadvanced digital artist that can not only create realistic images but also mix and match different \\nstyles and contents. It’s like having a painter who can take the style of Van Gogh and apply it \\nto a modern cityscape. This flexibility makes StyleGAN incredibly versatile [7].Types of generative AI models 7\\nAutoregressive models and Transformer architecture\\nAutoregressive models generate their data points one at a time, conditioning each of its data points \\non the previous one. Surprisingly, this ultimately proves very useful in tasks in which the sequence \\nor structure of data is relevant, such as text generation and image generation. The Transformer \\narchitecture, introduced in the Attention Is All You Need paper [8], is a model architecture that has \\nrevolutionized many sequential data tasks, especially in natural language processing (NLP). Its key \\ncomponents are demonstrated in Figure 1.1:\\nFigure 1.1 – The Transformer architectureFundamentals of Generative AI 8\\nThese key components include the following:\\n• Self-attention mechanism: A computational technique that allows the model to dynamically \\nfocus on different parts of the input when processing each element\\n• Multi-head attention: Multiple attention mechanisms running in parallel, allowing the model \\nto focus on different aspects of the input simultaneously\\n• Positional encoding: Adds information about the position of each element in the sequence\\n• Feed-forward neural networks: Process the output of the attention layers\\n• Layer normalization and residual connections: Enhance training stability and information flow\\nTransformers can be used in both autoregressive and non-autoregressive configurations, making them \\nversatile for various tasks. The following are some examples:\\n• PixelCNN: Autoregressively generates images pixel by pixel, conditioning each pixel on the \\npreviously generated ones. This model works very well in generating high-quality images with \\nfine details [9].\\n• PixelSNAIL: A refinement over PixelCNN that adds attention mechanisms into the model \\nto capture strong dependencies between pixels, and hence, a better quality of an image [10].\\n• GPT: Standing for Generative Pre-trained Transformer, it is a line of models specializing in \\ntext generation—namely, predicting which words should come next. Among them are GPT-2, \\nGPT-3, and GPT-4, making a huge leap in generating coherent and contextually relevant text \\n[11] [12].\\n• BERT: Unlike GPT, BERT, which stands for Bidirectional Encoder Representations from \\nTransformers, is designed to understand the context from both directions in text. It uses the \\nencoder part of the Transformer and is typically used for tasks that require an understanding \\nof the entire input at once, rather than generating text autoregressively [13].\\n• Text-To-Text Transfer Transformer (T5): This model frames all NLP tasks in a text-to-text \\nformat. It uses the full Transformer architecture (both encoder and decoder) and can handle \\nvarious text generation tasks [14].\\nAlthough it depends on the task, these models demonstrate how the Transformer architecture can \\nbe adapted for both autoregressive (such as GPT) and non-autoregressive (such as BERT) tasks, \\nshowcasing its versatility in handling sequential data. Strengths differ across generative models. This \\nclass of models goes from generating photorealistic images to coherent text to totally new data samples.\\nBuilding upon the success of models such as GPT, researchers have scaled up these architectures to \\ncreate large language models (LLMs). These models, often trained on vast amounts of open web text \\nand other freely available text data, have demonstrated exceptional proficiency in understanding and \\ngenerating human-like text across diverse applications, showcasing their versatility and advancedTypes of generative AI models 9\\nlinguistic abilities. Examples of LLMs include GPT-3, GPT-4, PaLM, and BERT-large. These models \\nhave pushed the boundaries of what’s possible in NLP , showing proficiency in tasks ranging from \\nquestion-answering and summarization to creative writing and code generation. The following is an \\noverview of the common types of LLMs:\\n• Autoregressive LLMs: These language models are typically capable of generating text sequentially, \\nthat is, one token at a time. Some of the common tasks that these types of models are used for \\ninclude text generation, text completion tasks, and creative writing. Some popular examples \\nof autoregressive LLMs are the GPT series (GPT-3, GPT-4), and PaLM.\\n• Encoder-only LLMs: These models specialize in natural language understanding (NLU) tasks, \\nwhich involve analyzing and comprehending input text without generating new text. Encoder-only \\nLLMs, such as BERT and its variants including RoBERTa, focus on understanding the context \\nand meaning of input text. These models process the entire input sequence simultaneously, \\nallowing them to capture the context helping with tasks such as text classification, named entity \\nrecognition (NER), and sentiment analysis.\\n• Encoder-decoder LLMs: This is a combination of encoder and decoder architecture where \\nthe models can not only understand the context of the input text (NLU) but are also capable \\nof generating textual output. The T5 model discussed earlier is a very popular example of an \\nencoder-decoder LLM, along with models such as BERT. These models are capable of language \\ntranslation, summarization, and question-answering.\\n• Multimodal LLMs: Multimodality is a concept where an AI model can not only handle text \\nbut also other modalities such as image, video, and audio. Multimodal LLMs can process and \\ngenerate content in various modalities such as text, image, audio, video, and any combination \\nthereof. These models are rather novel in nature and recent advancements in compute have \\nmade it possible to train multimodal LLMs. Some of the well-known multimodal LLMs are \\nDALL-E, Stable Diffusion, Flamingo, GPT-4, and LlaVa.\\n• Instruction-tuned LLMs: LLMs are often trained on a large corpus of openly available web or \\nother text. As such, in certain scenarios, these models may not perform effectively for tasks that \\nuse data that the model has never seen before and thus may fail to follow the user intent. For \\nexample, a manufacturing manual for a proprietary instrument may contain domain-specific \\nproprietary language, which the model may not have been exposed to during training. In such \\ncases, LLMs can be fine-tuned using the domain-specific data to follow specific instructions \\nand prompts (that is, text input to the model). This special fine-tuning enables the model to \\nperform domain-specific tasks on which the model was fine-tuned, in addition to its other \\ncapabilities. Think of this as localizing a personal copy of a model to be good at performing \\na task that is meaningful for your use case. One of the common examples of such a model is \\nInstructGPT, where researchers fine-tuned the GPT-3 model on specific instructions. These \\ntypes of models are used in a multitude of different tasks such as chatbots, virtual assistants, \\nand task-specific applications.Fundamentals of Generative AI 10\\n• Domain-specific LLMs: As mentioned earlier, while LLMs are often trained on a large set \\nof open, generally available, web data, they may not perform very well in domain-specific \\nenvironments. While instruction-tuned LLMs are an avenue to make these general-purpose \\nmodels work for domain-specific tasks, researchers have innovated on training domain-specific \\nLLMs from the ground up. This means that these models were pre-trained on highly specialized, \\ndomain knowledge. For example, the BioBERT model is trained on hyper-specialized medical \\ndata, whereas LegalBERT is trained on legal documents. These models are useful for specialized \\ntasks in specific fields such as medicine, law, and finance.\\nLLM-powered AI agents\\nEach of the previously discussed LLM types has its own strengths and weaknesses and is well-suited \\nfor different applications. However, our focus in this book would be to dive deeper into LLM agent \\ncapabilities and explore how advanced systems can be built utilizing them. It is important to note \\nthat LLM agents do not fit neatly into a single category, as they represent an advanced application \\nof LLM technology rather than a specific type of model architecture. Agents are typically built using \\ninstruction-tuned LLMs as their foundation, often combined with additional components and \\ncapabilities as you will learn further in this book.\\nLet us take a look at a simple example to demonstrate the capabilities of an agentic system powered \\nby an LLM. Our example is a travel website that has a Flight Booking Assistant chatbot that is a \\nconversational interface built with an LLM. It can help customers book travel tickets via human-like \\nconversations. In the backend, the chatbot can perform various tasks as the conversation progresses. \\nHere’s what a sample conversation may look like for a customer who is looking to book a flight ticket:\\nFlight Booking Assistant\\nHi, I want to book a flight.\\n🤖 Hello! I’ d be happy to help you book a flight. To get started, could you please tell me your \\ndeparture city and destination?\\nI want to go from San Diego to SFO.\\n🤖 Great, thank you for providing that information. Y ou’re looking to fly from San Diego (SAN) \\nto San Francisco International Airport (SFO). To help you find the best flight options, I’ll \\nneed a few more details.\\n1. What is your preferred travel date?\\n2. Is this a one-way trip or a round trip?\\n3. How many passengers will be traveling?Types of generative AI models 11\\nI want to go next Friday and come back on Sunday. Just me traveling.\\n🤖 Thank you for the additional information. Let me summarize what I have so far:\\n- Departure: San Diego (SAN) to San Francisco (SFO)\\n- Outbound Date: Next Friday – 08/23/2024\\n- Return Date: Sunday – 08/25/2024\\n- Passengers: 1 adult\\nBefore I search for flights, I have a few more questions:\\n1. Do you have a preferred time of day for your flights (morning, afternoon, or evening)?\\n2. Do you have a preferred airline or are you open to all airlines?\\n3. What class of service would you prefer (Economy, Premium Economy, Business, or \\nFirst Class)?\\nI prefer morning flights. No airline preference. Economy is fine.\\n🤖 Thank you for those details. I’ll search for morning flights in Economy class across all \\nairlines for your trip. Give me a moment to find the best options for you.\\n[searching flights...please stand by….]\\n🤖 I’ve found a few options for your trip. Here are the best morning flights:\\nOutbound (SAN to SFO) - Next Friday:\\n1. United Airlines UA1234: Depart 7:15 AM, Arrive 8:45 AM\\n2. Alaska Airlines AS5678: Depart 8:30 AM, Arrive 10:00 AM\\nReturn (SFO to SAN) - Sunday:\\n1. Delta Air Lines DL9876: Depart 9:00 AM, Arrive 10:30 AM\\n2. Southwest Airlines WN5432: Depart 10:15 AM, Arrive 11:45 AM\\nThe total price for the round trip, including taxes and fees, is:\\n- Option 1 (United/Alaska): $325\\n- Option 2 (Delta/Southwest): $310\\nWhich option would you prefer? Or would you like me to look for different flights?Fundamentals of Generative AI 12\\nThe second option looks good. Can you book that for me?\\n🤖 Certainly! I’ d be happy to book the second option for you. Just to confirm, I’ll be booking \\nthe following itinerary:\\nOutbound: Alaska Airlines AS5678\\n- Date: 08/23/2024\\n- Depart San Diego at 8:30 AM, Arrive in SFO at 10:00 AM\\nReturn: Southwest Airlines WN5432\\n- Date: 08/25/2024\\n- Depart SFO at 10:15 AM, Arrive in San Diego at 11:45 AM\\nTotal price: $310\\nTo proceed with the booking, I’ll need some additional information:\\n1. Y our full name as it appears on your government-issued ID\\n2. Y our date of birth\\n3. Y our email address (for sending the confirmation)\\n4. Y our phone number\\n5. Any special requests (for example, meal preferences, seat preferences)\\nAlso, please note that you’ll need to provide a form of payment to complete the booking. \\nAre you ready to proceed with this information?Types of generative AI models 13\\nY es, I’m ready. My name is John Smith, born on 05/15/1985. My email is john.smith@email.\\ncom and my phone number is 555-123-4567. No special requests.\\n🤖 Thank you for providing that information, Mr. Smith. I’ve entered your details into the \\nbooking system. Here’s a summary of the information I have:\\n- Name: John Smith\\n- Date of Birth: 05/15/1985\\n- Email: john.smith@email.com\\n- Phone: 555-123-4567\\n- Special Requests: None\\nThe final step is to process the payment of $310 for your flights. For security reasons, I can’t \\naccept credit card information directly in this chat. Instead, I’ll send a secure payment link \\nto your email address (john.smith@email.com).\\nOnce you receive the email, please follow the link to complete the payment process. \\nAfter the payment is successfully processed, you’ll receive another email with your flight \\nconfirmation and e-tickets.\\nIs it okay to proceed with sending the payment link to your email?\\nY es, that’s fine. Please send the payment link.\\n🤖 Excellent, Mr. Smith. I’ve initiated the process to send the secure payment link to your \\nemail address (john.smith@email.com). Y ou should receive it within the next few minutes. \\nPlease check your inbox and spam folder if you don’t see it right away.\\nOnce you complete the payment, the system will automatically process your booking \\nand send your confirmation email with the e-tickets. This email will include important \\ninformation such as:\\n1. Booking confirmation number\\n2. Detailed flight itinerary\\n3. Check-in instructions\\n4. Baggage allowance information\\n5. Airline contact information\\nAfter you receive your confirmation email, please review all the details to ensure everything \\nis correct. If you notice any issues or have any questions, please don’t hesitate to contact us.\\nIs there anything else you need assistance with regarding your trip or the booking process?Fundamentals of Generative AI 14\\nNo, that’s all. Thank you for your help!\\n🤖 Y ou’re welcome, Mr. Smith! I’m glad I could assist you with booking your flights from San \\nDiego to San Francisco. If you need any further assistance with this booking or have any \\nquestions about your trip, please don’t hesitate to reach out. We’re here to help 24/7. Have \\na great trip to San Francisco next week!\\nOn the surface, this example looks pretty straightforward. However, there are a number of things that \\nare happening in the background. Firstly, the customer starts with a vague request to book a flight. \\nThe AI assistant understands that in order to proceed with this request, it needs a few more pieces \\nof information to look up available flights, such as departure/arrival city, dates of travel, and so on.\\nAs the conversation progresses, the AI assistant requests further pieces of information to be able to \\nsuccessfully complete the booking. The information it gathers at each step is used as a parameter value to \\ncall flight booking-related APIs in the backend; for example, city/travel dates/number of passengers are \\nrequired to look up available flight information using a (fictitious) API named flightLookup, customer \\nname/phone/email are required to actually make the booking using an API named bookFlight, and \\nso on. Figure 1.2 gives an overview of the decisions that the model makes, the flow of the interaction, \\nand the tools (API functions) it calls to complete each step:Types of generative AI models 15\\nFigure 1.2 – Flight Booking Assistant chatbot with LLM-powered multi-agents\\nIn addition to just tool calling, you will also notice that the model does a bit of introspection, also \\nknown as chain of thought (CoT), at the beginning of the conversation. This means the model in the \\nbackend crafts a step-by-step approach to complete the task but identifies some missing information. It \\nthen responds back to the customer with a request to provide the required information. Subsequently, \\nbased on the input from the customer, it makes certain decisions autonomously to call specific tools \\nusing the agent and completes the task.Fundamentals of Generative AI 16\\nIn addition to the external tools and APIs, there are a number of other things to consider when \\ndesigning such a system. We will cover the fundamentals of each of these components in detail in the \\nsubsequent chapters. For now, it is sufficient to know that agents are an advanced application of LLMs \\n(such as this travel booking AI assistant) and represent an emerging field that combines aspects of \\nvarious LLM types with additional AI techniques such as reinforcement learning, planning, and tool \\nuse. As you learn more in subsequent chapters, you will notice that agents are designed to be more \\ninteractive, adaptable, and capable of completing complex, multi-step tasks compared to standard \\nLLMs, which makes them suitable for a variety of different complex tasks and workflows.\\nBut before we dive deeper into the details of agentic systems, let us review some of the applications \\nof generative AI.\\nApplications of generative AI\\nGenerative AI has innovation capabilities that cover a diverse set of fields. As discussed earlier, industries \\nsuch as healthcare, finance, education, media and entertainment, marketing, manufacturing, retail, \\nand so on all have the potential to benefit from generative AI capabilities. The following is a survey \\nof only a few of the primary applications of generative AI:\\n• Generation of images and videos: Multimodal generative models (that is, LLMs that can handle \\nimages, text, audio, and videos) are making it possible to generate realistic audio/visuals through \\nvarious platforms and tools. For example, in media and entertainment, generative AI can help \\nin generating visual effects, designing avatars, and developing virtual reality content. In the \\nfashion and design industry, it is being used to conceptualize new clothing designs, prepare \\nvirtual fashion shows, and make fashion trend predictions. In marketing ads and promotion \\nspace, generative AI is being used to generate tailor-made advertisements, campaigns, marketing \\ncommunications, and other marketing materials creatives such as images and logos.\\n• Text and content generation: Generative AI has made significant strides when it comes to text-\\nbased tasks. For instance, content writing such as rapid and hassle-free generation of articles, \\nblog posts, marketing, and product copies are already some of the most common use cases. \\nChatbots and virtual assistants are providing customer support in a very humanlike manner \\nto information-related inquiries. Generative AI is also assisting in text translation, document \\nsummarization, and content localization for increased accessibility of content for platforms \\nsuch as online learning and specialized search engines.\\n• Music and audio generation: Creating original music, sound effects, and voice synthesis is yet \\nanother paradigm of multi-media content generation that is being powered by generative AI. \\nPractically, contents such as these are being used in the gaming and entertainment industry to \\ncreate audio-assisted training materials, automated call center assistants, and IoT devices such \\nas Amazon Alexa, or Google Next that can take audio commands and use voice responses to \\ncomplete automated tasks.Applications of generative AI 17\\n• Healthcare and drug discovery : Generative AI finds space in health care. For example, the \\ndesign of new drugs and the prediction of their capability to treat diseases or other conditions; \\npersonalized medicine, whereby treatment plans are tailored individually on a patient-by-patient \\nbasis; and medical imaging, whereby image quality is refined and synthetic images generated \\nfor research purposes.\\n• Code generation: Code generation is an emerging LLM feature that is helping developers in \\nsoftware development. These models can often generate accurate code snippets, or sometimes \\nan entire function based on text prompts. Advanced implementation of generative AI in \\ncode generation includes plugins created for various integrated development environments \\n(IDEs), such as Visual Studio Code (VS Code), that can understand the entire context of the \\ncode base, identify errors, create code documentation, and generate unit test scripts. Another \\nimplementation of code generation is text-to-query use cases where a natural language prompt \\nis converted into a SQL query, which can then be executed against a database to get the desired \\nresults. However, this is one of the areas where special caution must be taken, especially before \\nexecuting the code generated by an LLM, to prevent risks of malicious code execution. Often, \\nin these situations, the code generated by the LLM is executed in a sandbox and sanitized to \\ncheck whether the code is safe and appropriate for execution in an autonomous environment.\\n• Autonomous workflows and robotics: As we briefly discussed earlier, LLM-powered AI agents \\nare an advanced implementation of generative AI with LLMs serving as their foundations. \\nThese agents can perform several tasks in various use cases. For example, a travel booking \\nwebsite with a virtual assistant chatbot can implement agents to automate the travel and hotel \\nbooking process for the customer. In these cases, the agent-based system can act on specific \\ntasks using tools (such as calling a flight booking API) simply by understanding the context \\nof the conversation that the customer is having with the chatbot. More advanced agent-based \\nsystems often come into play when discussing robotics, where a robot’s actions are primarily \\ncontrolled by agents. The robotic agent essentially determines what decisions to make based on \\nits environment or the specific task it is assigned to perform. It uses agents to execute actions \\nthat an LLM would otherwise be unable to perform; for example, an agent can turn on or off  \\nthe limb actuators of a robot. AI in robotics is a novel and open field of research, with numerous \\ninnovations emerging in the industry, particularly targeted toward manufacturing applications.Fundamentals of Generative AI 18\\nThese are just some of the common examples of the uses of generative AI with LLMs. Other specific \\nexamples include uses in fashion and design, synthetic data generation, personalized educational \\ncontent, financial modeling and forecasting, and predictive maintenance. The following is a brief list \\nof examples of commercial and open source tools that use generative AI for the number of use cases \\nwe discussed:\\nUse case Commercial tools Open source tools\\nVisual effects and \\navatar design\\n• Unreal Engine’s MetaHuman \\nCreator: Allows for the creation \\nof highly realistic digital humans \\nfor games and films\\n• NVIDIA Omniverse: A platform \\nfor 3D design collaboration and \\nsimulation, useful for creating \\nvisual effects\\n• DeepFaceLab: Used for \\nface swapping and creating \\ndigital avatars\\n• StyleGAN: Capable of \\ngenerating highly realistic \\nfaces and can be adapted for \\navatar creation\\nVirtual reality \\ncontent development\\n• Unity: While not exclusively \\nfor VR, it has robust VR \\ndevelopment capabilities\\n• Adobe Aero: Allows for the \\ncreation of AR experiences\\n• A-Frame: A web frame-\\nwork for building virtual \\nreality experiences\\n• Godot: An open source \\ngame engine with \\nVR support\\nClothing design \\nand virtual \\nfashion shows\\n• CLO3D: A 3D garment design \\nsoftware that can create virtual \\nfashion shows\\n• Browzwear: Offers 3D design \\nsolutions for the fashion industry\\n• Blender: While primarily a \\n3D modeling tool, it can be \\nused for fashion design and \\nvirtual shows\\nFashion \\ntrend predictions\\n• WGSN: Uses AI for trend fore-\\ncasting in fashion\\n• Heuritech: Provides AI-powered \\ntrend forecasting\\n• None\\nMarketing – ad \\ngeneration and \\ncampaign creation\\n• Jasper: An AI writing assis-\\ntant that can help create \\nmarketing copy\\n• Midjourney: An AI image \\ngeneration tool useful for creat-\\ning marketing visuals\\n• GPT-J: An open source \\nlanguage model that can be \\nfine-tuned for marketing \\ncontent generation\\n• Stable Diffusion:An open \\nsource image generation \\nmodel that can create \\nmarketing visuals.Applications of generative AI 19\\nUse case Commercial tools Open source tools\\nLogo and \\nimage creation\\n• DALL-E 2: Can generate unique \\nimages and logos based on \\ntext descriptions\\n• Canva: While not fully AI-pow-\\nered, it incorporates AI features \\nfor design assistance\\n• Stable Diffusion: Can \\nbe used for logo and \\nimage generation\\n• Craiyon (formerly DALL-E \\nmini): An open source alter-\\nnative to DALL-E\\nText and \\ncontent generation\\n• ChatGPT by OpenAI\\n• Claude AI by Anthropic\\n• Jasper\\n• Copy.ai\\n• Anyword\\n• Writer\\n• WriteSonic\\nAnd many more…\\n• Mistral 7B: An open source \\nLLM known for its effi-\\nciency and precision in text \\ngeneration tasks\\n• LLaMA: A collection of open \\nsource pre-trained and fine-\\ntuned generative text models, \\noffering versions with differ-\\nent parameter sizes\\n• BLOOM Language Model: \\nA large open-access AI \\nmodel developed by over \\n1,000 AI researchers, known \\nfor its robustness and versa-\\ntility in text generation\\nAnd many more…\\nCode generation • GitHub Copilot\\n• Amazon Q for Developers\\n• Tabnine\\n• OpenAI Codex\\nAnd many more…\\n• Code T5: An open source \\nAI model trained for \\ncode-related tasks. It \\ncan generate code snip-\\npets, complete code, and \\neven translate between \\nprogramming languages.\\n• Polycoder: An open source \\nalternative to commercial \\ncode generators. It’s trained \\non a large code base span-\\nning multiple programming \\nlanguages and can generate \\ncode for various tasks.Fundamentals of Generative AI 20\\nUse case Commercial tools Open source tools\\nAutonomous work-\\nflows and robotics\\n• UiPath incorporates genera-\\ntive AI into its robotic process \\nautomation (R PA) platform. It \\nuses AI to discover automation \\nopportunities and enhance tasks \\nsuch as document understanding \\nand communications mining.\\n• Automation Anywhere inte-\\ngrates generative AI into its \\nautomation platform. It offers \\nfeatures such as Automation \\nCo-Pilot for Automators, which \\nuses generative AI to accelerate \\ndeveloper productivity.\\n• NVIDIA provides AI workflows \\nthat leverage their AI frame-\\nworks, including generative \\nAI capabilities, for developing \\ninnovative solutions in robotics \\nand autonomous systems.\\n• OpenAI Gym provides a \\ntoolkit for developing and \\ncomparing reinforcement \\nlearning algorithms, which \\ncan be combined with \\nLLMs for more advanced \\nrobotics applications.\\n• Hugging Face offers open \\nsource libraries that can be \\nused to implement LLMs in \\nrobotics and autonomous \\nworkflow applications.\\n• LangChain is an open \\nsource Python library used \\nfor developing applications \\nusing LLMs, which can be \\napplied to create more intelli-\\ngent autonomous workflows \\nand robotic systems.\\nTable 1.1 – Examples of commercial and open source tools that use generative AI\\nThis is in no way an exhaustive list of commercial and open source tools available in the market at the \\nmoment and the landscape is changing every day. We are witnessing a host of new start-ups providing \\nnew and innovative ways of solving real-life use cases with generative AI, and we are also witnessing \\nnew model providers developing state-of-the-art LLMs that are more capable than the previous ones \\nand are much cheaper to operate. This just goes to show you how dynamic and exciting the field of \\ngenerative AI is.\\nChallenges and limitations of generative AI\\nThough generative AI has immense benefits, it is not without its own set of challenges and limitations. \\nSome of these challenges and limitations need to be taken into account with a lot of caution while \\nconsidering a generative AI technology for any particular use case. Here’s a brief discussion of some \\nof the most common caveats related to LLMs and some of the ways to mitigate them.Challenges and limitations of generative AI 21\\nQuality of data and bias\\nThe generative models are largely aided by the quality and diversity of data in the training dataset. \\nAny model trained with biased or unrepresentative data will reproduce outputs with the same kind \\nof bias, hence solidifying existing biases or allowing marginalization of one or several groups in case \\nof bias in the training data.\\nOne way this challenge can be dealt with is by ensuring richness in diversity, good quality data, and \\nso on for a wide array of perspectives within the dataset itself used for training. As with any machine \\nlearning problem, analysis of the data and knowing the data distribution across features is often helpful. \\nData analysis can reveal imbalances that can introduce bias in the model. There are several algorithmic \\nways of mitigating bias in training data (for instance, using oversampling or undersampling), but \\neach of these methods has its own advantages and disadvantages. For example, consider two classes \\nof data in a training dataset that contains more instances of Class 0 data than Class 1 data, causing \\na natural imbalance in the dataset. When a model is trained with such a dataset, the model would \\n“overfit” on the Class 0 type of data and would become more proficient in or even memorize data that \\nbelongs to Class 0 and may not perform well for data belonging to Class 1 This inherently causes the \\nmodel to perform poorly and demonstrate heavy bias. The following figure demonstrates the effect \\nof oversampling and undersampling on such a dataset to mitigate bias:\\nFigure 1.3 – Imbalanced data distribution and effects of oversampling and undersampling\\nData privacy\\nMultiple experiments and researchers have proven that LLMs have a propensity to leak data they \\nare trained on. This is especially problematic if the models are trained on large amounts of private \\nor proprietary information. Special techniques and styles of prompting LLMs have shown that it is \\nsufficient to coerce the model to generate data that includes verbatim text from its training dataset. \\nThese prompting techniques are not sophisticated and often make it a very easy, cost-effective attack \\nvector to get a model to leak information. For example, as discussed in the paper named Scalable \\nExtraction of Training Data from (Production) Language Models [15], researchers were able to spend \\nonly $200 worth of API calls to OpenAI’s GPT-3.5 model and use prompt injection techniques toFundamentals of Generative AI 22\\ncoerce the model to leak private information. The leaked information includes people’s names, email \\nand physical addresses, and phone numbers that were inadvertently present in the model’s training \\ndataset. While some of these issues are actively being addressed by model providers such as OpenAI, \\nit can still be problematic for organizations that choose to train their own models in-house.\\nSome of the common mechanisms to mitigate this is to perform data anonymization or pseudonymization \\non the training data to remove or obscure personal, private, and or proprietary information, even \\nbefore training the model. Both of these techniques involved using smaller, cheaper, and faster AI \\nmodels to perform classification and entity detection to identify the presence of personal or private \\ndata in the training dataset. Once identified, the private information can be obscured, masked, or \\nentirely removed from the training dataset. Note that there could be several implications to doing this \\ndepending on your use case, so special analysis must be performed to ensure that it doesn’t impact \\nthe model’s performance.\\nComputational resources\\nTraining sophisticated generative models is very resource-intensive and requires high computational \\npower; this often makes it economically cost-prohibitive and energy-consuming to train large language \\nmodels. Although there have been several hardware breakthroughs that make it possible to train such \\nmodels, access to these hardware assets still remains expensive, privileged, and limited. For example, \\ngraphics processing units  (GPUs), initially designed for rendering high-fidelity graphics, have \\nbecome crucial for AI model training, fine-tuning, and computations. NVIDIA ’s CUDA architecture, \\nintroduced in 2006, allowed GPUs to be used for general-purpose computing, and modern GPUs \\nsuch as NVIDIA ’s A100 and H100 have since been specifically optimized for AI workloads. However, \\nthese high-end GPUs can often cost tens of thousands of dollars per unit.\\nTraining large models such as GPT-3 is estimated to cost millions of dollars in compute resources alone. \\nThe exact cost depends on factors such as model size, training duration, and hardware efficiency. For \\nexample, training GPT-3 was estimated to cost around $4–5 million in compute resources, and more \\nrecent models such as GPT-4 and PaLM are likely even more expensive to train. Beyond the hardware \\nitself, there are significant infrastructure costs related to power consumption, cooling, and data center \\nspace. Due to the high costs, training large language models is primarily done by large tech companies \\nor well-funded research institutions. Cloud services now offer access to pre-trained models and fine-\\ntuning capabilities, making some level of LLM work more accessible to smaller organizations and \\nthe general public. A way to overcome this challenge can be found in recent innovations with small \\nlanguage models (SLMs), which are much smaller generative AI models that can be trained to achieve \\nspecific tasks. Even though these models are limited to a very narrow set of domain-specific tasks, it \\nis much more economical to train these models since they require far fewer computational resources.Summary 23\\nEthical and social implications\\nThe range of issues in ethics and society exposed by strides in technological generative AI opened up \\nthe following many-headed issues, which is far from an exhaustive list:\\n• Deepfakes and misinformation: It is able to produce very realistic synthetically generated \\ncontent. If that were to happen, it would yield deepfakes or even misinformation, which could \\nbe a threat to privacy, security, or even public trust.\\n• Intellectual property: The process of developing comparable content to existing ones brings \\nforth issues with copyright and intellectual property rights. The legal complexity attached to \\nthe very originality of the creation and correct ownership can be most perplexing.\\n• Job displacement: Economists often downplay concerns about significant job losses in content \\ngeneration and other automated task sectors. Of concern is the fact that resultant effects are \\nexpected to be paralleled with studies on ways of reskilling and adjustment strategies that can \\nhelp the affected workers, as well as entrepreneurial opportunities.\\nWhen it comes to mitigating social and ethical implications, the question is more philosophical than \\ntechnical. While some measures such as deepfake AI image detection and private and personal data \\ndetection methods are common strategies, the societal implications are a larger question in the context \\nof AI’s benefit to society and any existing or impending government regulations.\\nGeneralization and creativity\\nOne of the big problems with these generative AI models is that their generalization ability turns \\nout to be very poor. More concretely, they seldom generate content that is strikingly different from \\nthe training data. That is, they are brilliant at copying the repeating patterns but fail really to create \\nsomething original or novel. As a consequence, their potential for capital C creativity stays very limited.\\nAs generative AI continues to evolve in novel ways, it is bound to introduce novel challenges, as \\nwe are witnessing the barrage of new research and efforts to ensure sensible and responsible use of \\nthis technology.\\nSummary\\nGenerative AI is a rather rapidly growing area, having huge disruptive potential for industries and \\nchanging areas of our lives. In contrast, applications of generative AI include very realistic image \\ngeneration and generation of text, accelerated drug discovery, and enriched creative expression.\\nOne of the key points regarding this is an understanding of the different generative models, such as \\nV AEs, GANs, and autoregressive models, that provide insight into how technologies work and where \\nthey can be applied. It would also, however, be important to state the many problems and limitations \\ngenerative AI faces, including data quality, computational resources, ethical considerations, and \\neven creativity.Fundamentals of Generative AI 24\\nIn the next chapter, we will learn about the principles of agentic systems, which include the concepts \\nof agency and autonomy, the characteristics of intelligent agents, various architectures of intelligent \\nsystems, and multi-agent systems.\\nQuestions\\n1. Generative AI models can only take text data as input. True or false?\\n2. What are the different types of generative AI models?\\n3. What are some of the ethical and social implications of generative AI?\\n4. What are some of the methods to mitigate bias in training data?\\n5. What are some of the text and content generation open source LLMs?\\nAnswers\\n1. False. Generative AI models can take text as well as image, video, and audio data as inputs.\\n2. V AEs, GANs, and autoregressive models.\\n3. Deepfakes, misinformation, issues with copyright or intellectual property, and job displacements \\nare some of the social and ethical implications of generative AI.\\n4. Some of the common methods to address bias in training data are oversampling or undersampling.\\n5. Mistral, LLaMA, and Bloom are some of the open source text and content generation LLMs.\\nFurther reading\\n• Mastering Machine Learning Algorithms – Second Edition by Giuseppe Bonaccorso\\n• Machine Learning for Imbalanced Data by Kumar Abhishek and Dr. Mounir Abdelaziz\\n• Generative AI with Python and TensorFlow 2 by Joseph Babcock and Raghav Bali\\nReferences\\n1. Auto-Encoding Variational Bayes: https://arxiv.org/abs/1312.6114\\n2. beta-VAE: Learning Basic Visual Concepts with a Constrained Variational Framework: https://\\nopenreview.net/forum?id=Sy2fzU9gl\\n3. Learning Structured Output Representation using Deep Conditional Generative Models: https://\\npapers.nips.cc/paper_files/paper/2015/hash/8d55a249e6baa5c0677\\n2297520da2051-Abstract.html\\n4. Generative Adversarial Networks: https://arxiv.org/abs/1406.2661Join our communities on Discord and Reddit 25\\n5. Unsupervised Representation Learning with Deep Convolutional Generative Adversarial \\nNetworks: https://arxiv.org/abs/1511.06434\\n6. Wasserstein GAN: https://arxiv.org/abs/1701.07875\\n7. A Style-Based Generator Architecture for Generative Adversarial Networks : https://\\nieeexplore.ieee.org/document/8953766\\n8. Attention Is All You Need: https://arxiv.org/abs/1706.03762\\n9. Conditional Image Generation with PixelCNN Decoders : https://arxiv.org/\\nabs/1606.05328\\n10. PixelSNAIL: An Improved Autoregressive Generative Model: https://www.researchgate.\\nnet/publication/322114155_PixelSNAIL_An_Improved_Autoregressive_\\nGenerative_Model\\n11. Language Models are Few-Shot Learners: https://arxiv.org/abs/2005.14165\\n12. GPT-4 Technical Report: https://arxiv.org/abs/2303.08774\\n13. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding: https://\\narxiv.org/abs/1810.04805\\n14. Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer: https://\\narxiv.org/abs/1910.10683\\n15. Scalable Extraction of Training Data from (Production) Language Models: https://arxiv.\\norg/abs/2311.17035\\nJoin our communities on Discord and Reddit\\nHave questions about the book or want to contribute to discussions on Generative AI and LLMs? \\nJoin our Discord server at https://packt.link/I1tSU and our Reddit channel at https://\\npackt.link/ugMW0 to connect, share, and collaborate with like-minded enthusiasts.2\\nPrinciples of Agentic Systems\\nIn the previous chapter, we introduced the basics of generative AI, learned about types of generative \\nAI models, and briefly discussed LLM-powered AI agents. In this chapter, we will discuss the basic \\nprinciples of agentic systems, starting with a brief discussion about the concept of agency and autonomy, \\nfollowed by a discussion about intelligent agents and their characteristics. We will also discuss various \\nagentic system architectures as well as multi-agent systems through the lens of the travel booking \\nassistant example that we discussed in the previous chapter.\\nThe main topics discussed in this chapter are as follows:\\n• Understanding self-governance, agency, and autonomy\\n• Reviewing intelligent agents and their characteristics\\n• Exploring the architecture of agentic systems\\n• Understanding multi-agent systems\\nBy the end of this chapter, you will have an overview of the basics of intelligent agents and the most \\ncritical aspects of agentic system architecture that must be considered while building an intelligent \\nagentic system.Principles of Agentic Systems 28\\nTechnical requirements\\nY ou can find the code files for this chapter at https://github.com/PacktPublishing/\\nBuilding-Agentic-AI-Systems and follow the README file in the repository to set up your \\ndevelopment environment.\\nUnderstanding self-governance, agency, and autonomy\\nThe captivating aspect of agentic systems lies in the intricate decision-making processes they employ, \\nwhich provide valuable insights into how choices are optimized within specific contexts. These systems \\noften challenge our conventional understanding of accountability and responsibility.\\nAgentic systems act as the driving force behind innovation and technological advancements in \\nvarious fields, including robotics, AI, and systems engineering. The development and deployment of \\nthese systems have catalyzed the exploration and creation of new forms of automation and intelligent \\nbehaviors. Let’s discuss some of the areas where agentic systems are making headway:\\n• Robotics: In the field of robotics, agentic systems have paved the way for the design and \\nimplementation of autonomous robots capable of navigating complex environments, performing \\nintricate tasks, and adapting to changing conditions. These robots, equipped with decision-making \\ncapabilities and agency, have found applications in areas such as manufacturing, exploration, \\nsearch and rescue operations, and healthcare. For instance, robots with agentic behavior can \\nautonomously navigate through disaster zones, assess potential risks, and make decisions to \\nassist in rescue efforts, demonstrating intelligent and adaptive behavior.\\n• AI: In AI, agentic systems have been instrumental in the development of intelligent agents \\nand decision support systems. These systems leverage advanced algorithms, machine learning \\ntechniques, and knowledge representation methods to analyze data, reason about complex \\nscenarios, and provide intelligent recommendations or automated decision-making capabilities. \\nAgentic AI systems have been applied in domains such as finance, healthcare, transportation, \\nand marketing, enabling more efficient and effective decision-making processes.\\n• Systems engineering: In the field of systems engineering, agentic systems have facilitated the \\ndesign and implementation of complex, distributed, and adaptive systems. These systems often \\nconsist of multiple interacting components or subsystems, each exhibiting agentic behavior and \\ndecision-making capabilities. Such systems are found in areas such as power grids, transportation \\nnetworks, and cyber-physical systems, where intelligent and autonomous decision-making is \\ncrucial for efficient operation, resource allocation, and fault tolerance.\\nCentral to the idea of agentic systems are the concepts of self-governance, agency, and autonomy. Let’s \\ndiscuss each of these concepts in the subsequent sections to understand what they are and explore \\nthe critical role they play within an agentic system architecture.Understanding self-governance, agency, and autonomy 29\\nSelf-governance\\nAgentic systems are artificial and human systems that possess self-governance, adaptability, and \\ninteraction. Self-governance refers to the ability of a system or entity to govern or control itself \\nautonomously, without external direction or control. In the context of agentic systems, self-governance \\nimplies that the system can make its own decisions, set its own goals, and regulate its behavior based \\non its internal rules, models, and decision-making algorithms. Basically, they operate according to \\ntheir rules and internal states, and execute a change of behavior, if necessary, due to a change of the \\nenvironment or the objectives. Such systems interact with the environment or other systems in a way \\nthat is meaningful to them and, through these interactions, become influenced.\\nSome key aspects of self-governance in agentic systems are as follows:\\n• Self-organization: The ability to organize and structure its own internal processes, resources, \\nand behavior without external intervention\\n• Self-regulation: The capability to monitor and adjust its own actions and outputs based on \\nfeedback from the environment or internal states, to ensure it operates within desired parameters \\nor constraints\\n• Self-adaptation: The ability to modify its behavior, strategies, or decision-making processes \\nin response to changes in the environment or its own internal conditions, to achieve its goals \\nmore effectively\\n• Self-optimization: The ability to continuously improve its performance, efficiency, or decision-\\nmaking capabilities through learning, experience, or evolutionary processes\\n• Self-determination: The ability to set its own objectives, priorities, and courses of action based \\non its internal decision-making processes, without being entirely controlled by external forces\\nSelf-governance in agentic systems is often enabled by the integration of various technologies, \\nframeworks, and methodologies such as machine learning, knowledge representation, reasoning, \\nand decision-making algorithms. These allow the system to process information, learn from data and \\nexperiences, and make autonomous decisions based on its acquired knowledge and the current context.\\nAgency\\nAgency is described as the capability of an individual, or any other entity, to act independently and \\nmake choices. In the context of human and artificial systems, agency encompasses the following \\nkey elements:\\n• Decisional authority: This refers to the power or ability to act and perform actions according to \\na chosen alternative or course of action. Systems with agency possess the autonomy to evaluate \\ndifferent options and select the most appropriate action based on their internal decision-making \\nprocesses, rather than being solely driven by external forces or predetermined rules.Principles of Agentic Systems 30\\n• Intentionality: Agency implies the existence of intentions, goals, or objectives that guide the \\nactions and behavior of the system. Agentic systems are not merely reactive; they have a sense \\nof purpose and can pursue specific objectives, adjusting their actions and strategies as necessary \\nto achieve those goals.\\n• Responsibility: Agency is closely tied to the concept of responsibility, which is the answerability \\nor accountability for the outcomes and consequences of one’s actions. Systems with agency are \\nconsidered responsible for their decisions and the impact of their actions on the environment \\nor other entities they interact with.\\nIn most cases, AI agency involves the system’s ability to make decisions autonomously based on its \\ninternal programs, models, and the data it processes. These decisions can have a significant impact \\non the functioning of the system itself or its interactions with the environment.\\nLet’s go back to our travel booking assistant example from the previous chapter, which is responsible \\nfor booking flight tickets and perhaps even making hotel reservations. In this case, the system would \\nexhibit agency by analyzing various factors, such as the availability of flights between two cities, the \\nprice of the tickets, and any other restrictions given by the user such as preferred seat class and so on, \\nand then making decisions on how to optimally look for flights and hotels that meet those criteria \\nso that it minimizes the overall cost of travel for the customer. The system would be responsible for \\nthe outcome of its decisions, which would impact the overall travel plan and the cost of travel for \\nthe customer.\\nAutonomy\\nAutonomy is closely related to the concept of agency but focuses more specifically on the degree of \\nindependence an entity or system possesses. It can be broken down into several aspects:\\n• Operational autonomy: This refers to the ability of a system to perform a specific task or set \\nof tasks without direct human intervention or control. A system with operational autonomy \\ncan execute its functions independently, relying on its own internal processes, decision-making \\nalgorithms, and environmental sensing capabilities.\\n• Functional autonomy: This aspect of autonomy involves the system’s ability to make choices \\nand take action to achieve set targets or objectives, modulated by the environment or context \\nin which it operates. Functionally autonomous systems can adapt their behavior and decision-\\nmaking processes in response to changing conditions or stimuli, enabling them to pursue their \\ngoals more effectively.Understanding self-governance, agency, and autonomy 31\\n• Hierarchical autonomy: This aspect relates to the amount of decisional authority or decision-\\nmaking power awarded to a system within a larger framework or organizational structure. \\nSystems with higher hierarchical autonomy have greater latitude in making decisions that impact \\ntheir subsystems or broader operations, while systems with lower hierarchical autonomy may \\nhave more constraints or oversight from higher-level entities.\\nIn AI and robotics, autonomy is a key concept that refers to the extent to which a system can perform \\ntasks and make decisions without the need for continuous human intervention.\\nIn our travel booking assistant example, the system would have operational autonomy to carry out \\ntasks such as booking flights or hotels, managing reminders, and retrieving travel information with \\nlittle or no human input. It would also possess functional autonomy, allowing it to interpret user \\ncommands, adapt to individual preferences, and make decisions that align with the user’s goals and \\ncontext. The level of hierarchical autonomy granted to such a system might depend on factors such \\nas user privacy preferences or the system’s access to sensitive data and resources.\\nNote that autonomy in AI and robotic systems does not necessarily imply a complete absence of human \\noversight or control. Often, these systems operate within well-defined boundaries and constraints set \\nby their designers or operators, while still exhibiting a significant degree of autonomy. In our travel \\nbooking example, the chatbot requests additional information, such as travel dates, locations, name, \\nand address, from the user to make flight bookings. It then cross-references this data with available \\nflights, suggesting options that match the user’s preferences. If any detail is missing or unclear, the \\nchatbot prompts the user for clarification, ensuring accuracy while still operating autonomously within \\nthe boundaries set by its programming.\\nThe concepts of self-governance, agency, and autonomy in AI systems are often accompanied by \\nethical considerations, particularly regarding the level of autonomy granted to these systems and the \\npotential risks and implications of their decisions. As AI systems become more advanced and capable \\nof independent decision-making, ensuring their alignment with human values and ethical principles \\nbecomes crucial.Principles of Agentic Systems 32\\nExample of agency and autonomy in agents\\nLet’s illustrate the concept of agency and autonomy with a simple algorithm for the travel booking \\nassistant. Note that this algorithm doesn’t necessarily use AI just yet, but it would help understand \\nthe concepts. Our travel booking assistant algorithm may look as follows.\\nAlgorithm 1: Travel booking assistant algorithm with agency and autonomy\\nRequire: Agent name N\\nEnsure: Initialized TravelAgent object A with agency and autonomy \\n1: Initialize A ← CreateTravelAgent(N)\\n2: Initialize A.goals ← empty list\\n3: Initialize A.knowledge_base ← empty dictionary \\n// Agency: Ability to act on behalf of a user\\n4: function SetGoal(G)\\n5: A.goals.Append(G)  // Agency: Defining objectives\\n6: function UpdateKnowledge(K, V)\\n7: A.knowledge_base[K] ← V  // Agency: Acquiring information from an API, and scoring \\n// Autonomy: Ability to operate independently\\n8: function MakeDecision(Options)\\n9: best_option ← max(Options, key =score)  // Autonomy: Independent decision-making\\n10: return best_option\\n11: function BookTravel(Departure, Destination)\\n12: Output “ Agent A.name is booking travel to Destination”\\n// Agency: Execute action on behalf of user\\n13: SetGoal(“Book flight from Departure to Destination”)\\n14: UpdateKnowledge({Departure, Destination})\\n// Autonomy: Book travel independently by finding best flight\\n15: MakeDecision()\\n// Implement booking logic here and store into A\\n16: Output AUnderstanding self-governance, agency, and autonomy 33\\nHere is how the algorithm works, demonstrating the abilities of agency and autonomy:\\n1. We start by naming our agent; we call it TripPlanner.\\n2. Next, we initialize a new TravelAgent object with the name N = \"TripPlanner\"; this \\nrepresents the creation of an entity capable of both agency and autonomy.\\n3. We then set up a list to store the goals for the agent. This relates to agency, as goals represent \\nthe intentions or desired outcomes the agent will work towards on behalf of the user. This is \\nindicated by A.goals ← empty list.\\n4. Next, we initialize an empty dictionary (also known as a map or key-value pairs) to store the \\nagent’s knowledge. This is crucial for both agency (acting on behalf of users) and autonomy \\n(independent operation), as it will contain information the agent uses to make decisions.\\n5. Steps 4 and 5 in the algorithm indicate the definition of a function that adds a new goal G to \\nthe agent’s list of goals. This is akin to the agent taking on objectives on behalf of the user. This \\nis indicated by A.goals.Append(G). Think of this as the piece of code that will receive \\nthe user’s chat message, such as “Book me a flight from San Diego to Seattle. ” Here, the goal is \\nto book a flight from San Diego to Seattle.\\n6. Steps 6 and 7 in the algorithm indicate the definition of a function that updates the agent’s \\nknowledge base with a new key-value pair (map or dictionary). This represents agency through \\nthe acquisition of information that will be used to act on behalf of the user. It also supports \\nautonomy by providing the agent with information it can use to make independent decisions. \\nThis operation is represented as A.knowledge_base[K] ← V. In our case, this function \\nuses several travel-related APIs (in theory) to get flight options between two cities, thus forming \\nthe knowledge into a knowledge base. This is also a place where each of these flight options will \\nbe scored; for example, late flights get low scores, and early flights get higher scores.\\n7. Steps 8 through 10 define a function that does a few different things. It takes a list of options \\nand selects the best one based on some scoring criteria. This is an example of autonomy in \\nthe algorithm since the agent independently evaluates options and makes a decision without \\ndirect human intervention.\\n8. Finally, steps 10 through 15 demonstrate how all of these components work together, starting \\nfrom setting the goal of flight booking using the departure and destination cities, updating the \\nknowledge base using a flight lookup API, and then scoring the available flights. Subsequently, \\nit uses the MakeDecision function to find the best possible flight as per the highest score \\nand performs the flight booking for the user.\\nA Python implementation of the BookTravel function from the algorithm is shown in the following \\ncode snippet:\\n1 def book_travel(departure: str, destination: str):\\n2     self.set_goal(f\"Book flight from {departure} to {destination}\")\\n3     self.update_knowledge(departure, destination)\\n4Principles of Agentic Systems 34\\n5     try:\\n6        best_flight = self.make_decision()\\n7        booking_confirmation = f\"BOOKING_#12345\"\\n8        self.knowledge_base[\\'booking_confirmation\\'] = \\\\\\n9                         booking_confirmation\\n10       print(f\"Booking confirmed: {booking_confirmation}\")\\n11    except Exception as e:\\n12       print(f\"Booking failed: {str(e)}\")\\n13\\n14 if __name__ == \"__main__\":\\n15    agent = TravelAgent(\"TripPlanner\")\\n16    agent.book_travel(\"SAN\", \"SEA\")\\n17    print(\"\\\\n----------- Final Agent State: -----------\")\\n18    print(f\"Name: {agent.name}\")\\n19    print(f\"Goals: {agent.goals}\")\\n20    if \\'booking_confirmation\\' in agent.knowledge_base:\\n21      print(f\"Booking Confirmation: \\\\\\n22      {agent.knowledge_base[\\'booking_confirmation\\']}\")\\nThe output of this code when the agent is initialized to book a flight from SAN (San Diego) to SEA \\n(Seattle) looks as follows:\\n1 Agent TripPlanner is booking travel from SAN to SEA\\n2 Goal set: Book flight from SAN to SEA\\n3 Knowledge updated with 3 flight options\\n4 Decision made: Selected flight JetBlue\\n5 Booking confirmed: BOOK-JetBlue-TRIPPLANNER\\n6 ----------- Final Agent State: -----------\\n7 Name: TripPlanner\\n8 Goals: [\\'Book flight from SAN to SEA\\']\\n9 Booking Confirmation: BOOK-JetBlue-TRIPPLANNER\\nFor the full implementation of the trip planner agent, refer to the Chapter_02.ipynb Python \\nnotebook in the GitHub repository.\\nIn this code snippet, the book_travel function takes a departure city code (such as SAN or SEA, \\nwhich are airport codes) and subsequently calls other functions to set the goal, update its knowledge \\nbase, and then make a decision on which flight to choose and book that flight. Note that our agent, \\nalthough has some functionality of agency and autonomy, is not intelligent. It cannot take plain text \\nmessages from a user and decipher what the user intends to do to set its goals, update its knowledge \\nbase, and then perform the actions; rather, it needs the airport codes. However, as we saw in our \\nexample, a user (or customer) may simply express their intentions in plain language such as “Book \\nme a flight from San Diego to Seattle”.Reviewing intelligent agents and their characteristics 35\\nIn its current form, given any such user input (message), the agent is incapable of determining what \\nthe departure and destination cities are, what the user is asking for, or even what the string of input \\ntext even means. This is where generative AI steps in, as we will see in the subsequent chapters. For \\nnow, let’s continue with our discussion by looking at the characteristics of agents.\\nReviewing intelligent agents and their characteristics\\nAn intelligent agent is a complex, self-governed entity that perceives its environment and takes action \\nto achieve certain goals or objectives. These agents can range from basic systems that strictly adhere to \\na predefined set of rules to highly advanced systems with the ability to learn and adapt from experience. \\nIntelligent agents are characterized by several key attributes:\\n• Reactivity: Reactive agents respond to changes and events occurring in their environment in \\nreal time. They continuously monitor their surroundings and adjust their behavior accordingly. \\nThis reactivity allows agents to adapt to dynamic conditions and respond appropriately to \\nstimuli, ensuring their actions remain relevant and effective.\\n• Proactiveness: An ideal intelligent agent should not merely react to events but also exhibit \\nproactive behavior. Proactive agents anticipate future needs, challenges, or opportunities, \\nand take the initiative to plan and act accordingly. They are goal-oriented and actively pursue \\nstrategies to achieve their objectives, rather than simply reacting to circumstances as they arise.\\n• Social ability: Many intelligent agents operate in multi-agent systems, where they interact and \\ncooperate with other agents or humans to achieve common goals that require collaborative \\neffort. Social ability encompasses communication, coordination, and negotiation skills, enabling \\nagents to work together effectively and leverage collective intelligence or resources.\\nWith these key characteristics, intelligent agents demonstrate remarkable versatility and efficiency \\nacross a wide spectrum of domains and scenarios. Their capabilities enable them to excel in tasks \\nranging from simple, automated processes to highly complex, dynamic decision-making situations \\nthat demand real-time adaptation and environmental responsiveness. In addition to these core \\ncharacteristics, intelligent agents may possess other advanced capabilities:\\n• Learning and adaptation: Intelligent agents have the ability to learn from experience and \\nadapt their behavior over time. They can acquire new knowledge, refine their decision-making \\nprocesses, and improve their performance through techniques such as machine learning, \\nreinforcement learning, or evolutionary algorithms.\\n• Reasoning and planning: Intelligent agents may employ reasoning and planning capabilities \\nto analyze complex situations, formulate strategies, and make informed decisions. They can \\nleverage techniques such as knowledge representation, logical inference, and planning algorithms \\nto navigate through intricate problem spaces and determine optimal courses of action.Principles of Agentic Systems 36\\n• Autonomy and self-governance: Intelligent agents often exhibit a degree of autonomy and self-\\ngovernance, allowing them to make decisions and take actions independently without constant \\nhuman intervention or supervision. This autonomy enables agents to operate efficiently in \\ndynamic environments or scenarios where continuous human control is impractical or impossible.\\nWith these characteristics, intelligent agents can be versatile and efficient in a wide range of domains, \\nfrom simple, automated tasks to highly complex, dynamic decision-making situations. They find \\napplications in areas such as robotics, decision support systems, virtual assistants, gaming, and \\nsimulations, among others.\\nExploring the architecture of agentic systems\\nAgentic systems, designed for executing complex goals in an autonomous way, can be implemented \\nusing a good variety of architectural patterns. In general, these patterns define the structure and \\nthe behavior that allows the system to perceive, reason, learn, and act upon the environment in an \\neffective way. Three main architectural patterns for agentic systems are deliberative, reactive, and \\nhybrid architectures. Let’s discuss them in detail.\\nDeliberative architectures\\nAlso known as knowledge-based or symbolic architectures, rely on the use of explicit representations of \\nknowledge and reasoning mechanisms to reach decisions. They typically follow a sense-plan-act cycle, \\nwhere they first perceive information about the environment, then make a plan of action according \\nto that perception and the knowledge base, and finally execute such plans of action.\\nThe key advantage of deliberative architectures is their ability to handle tasks that involve complex \\nreasoning, such as planning, problem-solving, and decision-making. These architectures leverage \\ntechniques such as rule-based reasoning, constraint satisfaction, and heuristic search to navigate \\nthrough intricate problem spaces and formulate appropriate courses of action.\\nOne of the critical components of a deliberative architecture is the knowledge base that stores symbolic \\nrepresentations of the environment, goals, constraints, and domain-specific knowledge. This knowledge \\nbase is typically encoded using formal language or logic, enabling the system to perform logical \\ninference and reasoning. The sense-plan-act cycle in deliberative architectures typically involves the \\nfollowing steps:\\n1. Sensing: The agent perceives and acquires information about the environment through various \\nsensors or input mechanisms.\\n2. Knowledge updating : The perceived information is used to update the agent’s internal \\nknowledge base, ensuring that it maintains an accurate representation of the current state of \\nthe environment.Exploring the architecture of agentic systems 37\\n3. Planning and reasoning: Based on the updated knowledge base, the agent employs reasoning \\ntechniques and algorithms to formulate plans and make decisions. This may involve techniques \\nsuch as constraint satisfaction, logical inference, search algorithms, or heuristic-based planning.\\n4. Plan execution: Once a plan or course of action has been determined, the agent executes the \\ncorresponding actions in the environment, potentially modifying the environment or achieving \\nspecific goals.\\nThe following figure depicts a deliberative architecture of an agentic system with a sense-plan-act cycle:\\nFigure 2.1 – Deliberative architecture of an agentic system\\nDeliberative architectures excel in handling tasks that require complex reasoning, planning, and \\ndecision-making in well-defined environments. They can effectively handle uncertainty and ambiguity \\nthrough techniques such as probabilistic reasoning, fuzzy logic, or belief revision mechanisms.\\nHowever, deliberative architectures also have some disadvantages. One significant challenge is the \\ncomputational cost associated with maintaining and reasoning over complex knowledge bases, which \\ncan limit real-time responsiveness in dynamic environments. Additionally, the explicit representation of \\nknowledge can be challenging in domains where knowledge is difficult to formalize or constantly evolving.\\nTo address these limitations, deliberative architectures are often combined with reactive or behavior-\\nbased components in hybrid architectures, allowing both complex reasoning and rapid response to \\nenvironmental changes.\\nDespite their limitations, deliberative architectures remain a crucial component in many intelligent \\nsystems, particularly in domains where complex decision-making, planning, and reasoning are essential, \\nsuch as robotics, decision support systems, and intelligent tutoring systems.Principles of Agentic Systems 38\\nReactive architectures\\nReactive architectures, also known as behavior-based or stimulus-response architectures, aim to provide \\nimmediate responses to stimuli from the environment. Unlike deliberative architectures, reactive \\narchitectures do not rely on explicit models of the world or complex reasoning processes. Instead, \\nthese systems directly map perceptions onto actions, typically using simple condition-action rules or \\nneural networks as depicted in the following figure:\\nFigure 2.2 – Reactive architecture of an agentic system\\nSome of the key properties and characteristics of reactive architectures include the following:\\n• Speed and responsiveness: Reactive architectures are designed to react rapidly to changes in \\nthe environment. By directly coupling perceptions to actions, they can bypass time-consuming \\ndeliberative reasoning processes, enabling swift and timely responses.\\n• Robustness and fault tolerance: These architectures are generally robust and less susceptible \\nto noise or incomplete information. Their simple, standalone nature makes them less prone to \\ncatastrophic failures, as individual components or behaviors can compensate for or mitigate \\nthe effects of faulty or missing input, especially when used within a deliberative architecture.\\n• Handling uncertainty: Reactive architectures can effectively handle uncertainty in dynamic \\nenvironments. Their ability to respond directly to environmental stimuli allows them to adapt \\nand adjust their actions based on the current situation, without relying on precise or complete \\nmodels of the entire world.\\n• Parallel and distributed processing: Reactive architectures often employ parallel and distributed \\nprocessing using multiple reactive modules, where multiple modules operate simultaneously \\nand independently. This decentralized approach enables efficient handling of complex tasks \\nand provides inherent scalability and modularity.Exploring the architecture of agentic systems 39\\n• Emergence of complex behavior: Despite the simplicity of individual behaviors or rules, the \\ninteraction and coordination of multiple reactive components can lead to the emergence of \\ncomplex, intelligent-like behavior at the system level.\\nWhile reactive architectures offer advantages in terms of speed, robustness, and handling uncertainty, \\nthey also have limitations as highlighted:\\n• Lack of long-term planning: Reactive architectures generally lack the ability to plan ahead or \\nreason about long-term consequences. Their focus is on immediate responses to environmental \\nstimuli, making it difficult to pursue complex, multi-step goals or strategies.\\n• Limited reasoning and abstraction: These architectures may struggle with tasks that require \\nabstract reasoning, generalization, or the manipulation of symbolic representations. They are \\nprimarily designed to operate at a lower, stimulus-response level.\\n• Limited learning capabilities : Many reactive architectures lack the ability to learn from \\nexperience or adapt their behavior over time. Their fixed set of rules or behaviors may not be \\nsuitable for dynamic environments or tasks that require continuous learning and adaptation.\\nDespite these limitations, reactive architectures are widely used in applications where real-time \\nresponsiveness, robustness, and ability to handle uncertainty are essential, such as in robotics, video \\ngames built with AI, and control systems. Additionally, reactive architectures often serve as components \\nwithin more complex hybrid architectures, complementing deliberative or learning-based systems to \\nachieve desired levels of performance and adaptability.\\nHybrid architectures\\nResearchers have recognized the strengths and limitations of both deliberative and reactive architectures, \\nleading to the development of hybrid architectures that aim to exploit the advantages of both approaches. \\nSuch hybrid architectures typically employ a layered structure, consisting of the following:\\n• A reactive layer for fast and low-level responses. The reactive layer is responsible for handling \\nreal-time interactions with the environment, providing rapid and situationally appropriate \\nresponses to external stimuli. This layer is designed to be highly responsive, fault-tolerant, and \\ncapable of handling uncertainty, leveraging the strengths of reactive architectures.\\n• A deliberative layer for high-level reasoning and planning. The deliberative layer is dedicated to \\nhigher-level reasoning, planning, and decision-making processes. This layer can maintain a more \\ncomprehensive representation of the environment, goals, and constraints, enabling it to formulate \\ncomplex strategies, reason about abstract concepts, and plan long-term courses of action.\\nThe interaction between these two layers is crucial for enabling agentic systems to respond effectively \\nto dynamic environmental contexts while maintaining the capability to plan actions and reason about \\nthem. The reactive layer can provide real-time feedback and situational awareness to the deliberative \\nlayer, informing its decision-making processes. Conversely, the deliberative layer can guide and \\ninfluence the reactive layer’s behavior by providing high-level plans, goals, and constraints.Principles of Agentic Systems 40\\nTo achieve complex goals and leverage the strengths of both layers, hybrid architectures often employ \\nthe following techniques:\\n• Task decomposition: Break down complex tasks into subtasks that can be handled by the \\nappropriate layer, with the reactive layer handling low-level, time-critical tasks and the deliberative \\nlayer focusing on higher-level planning and coordination\\n• Multiplan selection: The deliberative layer can generate multiple potential plans or strategies, \\nand the reactive layer can dynamically select and execute the most suitable plan based on the \\ncurrent environmental conditions\\n• Planning with external modules : The deliberative layer can incorporate external modules \\nor specialized algorithms for tasks such as path planning, resource allocation, or scheduling, \\nleveraging domain-specific knowledge and techniques\\n• Reflection and refinement: The deliberative layer can reflect on the outcomes of executed plans, \\nlearn from experience, and refine its reasoning and planning processes accordingly, enabling \\ncontinuous improvement and adaptation\\n• Memory-augmented planning: The deliberative layer can maintain a memory or history of \\npast experiences, decisions, and outcomes, enabling it to leverage this knowledge in future \\nplanning and reasoning processes\\nBy combining the strengths of both deliberative and reactive approaches, hybrid architectures seek to \\nbalance responsiveness and reasoning, enabling the development of more robust, autonomous, and \\nadaptable agentic systems. These architectures leverage the power of both approaches, providing the \\nability to respond rapidly to dynamic environments while maintaining the capability for complex \\nplanning, reasoning, and decision-making.\\nThe design and implementation of effective hybrid architectures remain an active area of research, as \\nresearchers strive to develop architectures that can seamlessly integrate and coordinate the deliberative \\nand reactive components, enabling the creation of highly capable and intelligent agentic systems.\\nSelecting the appropriate architectural pattern for an agentic system is contingent upon the specific requirements \\nof the application, encompassing factors such as task complexity, environmental uncertainty, and the \\nnecessity for real-time responsiveness. Deliberative architectures excel in scenarios that demand intricate \\nreasoning and decision-making processes, while reactive architectures thrive in dynamic environments that \\nnecessitate swift and adaptive responses. Hybrid architectures strike a harmonious balance by judiciously \\nleveraging the strengths of both paradigms, resulting in the development of more capable and adaptable \\nagentic systems that can seamlessly navigate the complexities of their operating environments.\\nUnderstanding multi-agent systems\\nMulti-agent systems (MASs) represent an important subfield of the broader area of distributed artificial \\nintelligence. They consist of several intelligent agents that interact, cooperate, and coordinate with \\neach other to execute tasks and achieve collective goals. Each agent in a MAS is typically autonomous,Understanding multi-agent systems 41\\ncapable of perceiving its environment through sensors, possessing a reasoning mechanism to make \\ndecisions, and acting upon those decisions to meet its design objectives. The collective behavior and \\ninteractions of these agents enable MASs to tackle complex problems that single-agent systems struggle \\nwith due to the inherent limitations of individual agents.\\nExamples of MASs can be found in various domains, demonstrating their applicability and effectiveness \\nin solving complex problems:\\n• Supply chain management and logistics: MASs can be used to optimize supply chain operations \\nby coordinating the activities of different agents representing suppliers, manufacturers, distributors, \\nand retailers. Each agent can make decisions based on its local knowledge and constraints, while \\ncollaborating with other agents to ensure efficient resource allocation, inventory management, \\nand transportation planning.\\n• Traffic control and transportation systems: MASs have been employed in managing traffic \\nflow and optimizing transportation networks. Agents can represent individual vehicles, traffic \\nlights, or traffic management centers, working together to reduce congestion, coordinate traffic \\nsignals, and find optimal routes for vehicles based on real-time traffic conditions.\\n• Robotics and manufacturing: In manufacturing environments, MASs can coordinate the \\nactivities of multiple robots or automated systems. Each robot or agent can be responsible \\nfor specific tasks, such as assembly, welding, or material handling, while communicating and \\ncoordinating with other agents to ensure efficient and synchronized operations.\\n• Environmental monitoring and resource management: MASs can be used for monitoring \\nand managing natural resources, such as water distribution networks, forestry management, \\nor wildlife habitat conservation. Agents can represent different stakeholders, environmental \\nsensors, or decision-making entities, collaborating to make informed decisions about resource \\nallocation, conservation efforts, or mitigation strategies.\\n• Distributed sensor networks: MASs are well suited for applications involving distributed sensor \\nnetworks, such as environmental monitoring, surveillance, or disaster response. Each sensor \\nnode can be represented as an agent, collecting and processing local data, while coordinating \\nwith other agents to fuse information and provide a comprehensive understanding of the \\nmonitored area or phenomenon.\\n• Intelligent virtual environments and simulations: MASs can be used to create intelligent virtual \\nenvironments and simulations, where agents represent various entities or actors within the simulated \\nworld. These agents can interact, make decisions, and exhibit complex behaviors, enabling realistic \\nsimulations of social systems, economic models, or military operations, among others.\\nThe key advantages of MASs lie in their ability to distribute problem-solving capabilities, leverage \\nthe collective intelligence and specialization of individual agents, and exhibit robustness and fault \\ntolerance through decentralized decision-making. Additionally, MASs can facilitate the integration \\nof heterogeneous components, enabling the development of flexible and scalable systems capable of \\naddressing complex, dynamic problems that would be challenging for monolithic, centralized approaches.Principles of Agentic Systems 42\\nDefinition and characteristics of MASs\\nA MAS is a system comprising multiple autonomous agents that can interact, collaborate, and cooperate \\nto achieve shared goals. These agents can be software programs, robots, or even humans equipped \\nwith specialized capabilities and goals. Interaction among agents is a necessary component, enabling \\nthem to work together efficiently, share information, and divide tasks based on their strengths and \\nareas of expertise. Key characteristics of MASs include the following:\\n• Autonomy: Each agent within a MAS is self-governing, making self-contained decisions based \\non its perception of the environment and its objectives. Agents operate independently without \\ncentralized control, exhibiting autonomous behavior.\\n• Interaction: Agents in a MAS communicate with each other through defined protocols, enabling \\nthem to share information, negotiate tasks, and coordinate their actions. This interaction can \\ntake various forms, such as cooperation, coordination, or competition, depending on the nature \\nof the problem and the agents’ goals.\\n• Adaptability: MASs possess the flexibility to adapt and change their behavior in response to \\nchanges in the environment or changes in the individual agents’ goals. This adaptability makes \\nMAS capable of handling dynamic situations, making them flexible and robust during operation.\\n• Distributed control: Unlike centralized systems, MASs employ distributed control, where \\ndecision-making and control are distributed among the individual agents. This distributed \\ncontrol contributes to the system’s resilience, as failures or malfunctions in one agent do not \\nnecessarily affect the entire system’s functionality.\\n• Scalability: MAS architectures are inherently scalable, allowing for the addition or removal \\nof agents as needed. This scalability enables the system to grow or shrink in complexity and \\ncapabilities, making it suitable for a wide range of applications.\\n• Heterogeneity: Agents within a MAS can be heterogeneous, meaning they can have different \\narchitectures, capabilities, and goals. This heterogeneity allows the integration of diverse components \\nand the leveraging of specialized expertise, contributing to the overall system’s effectiveness.\\n• Decentralized data and knowledge : In a MAS, data and knowledge are decentralized and \\ndistributed among the individual agents. This decentralization enhances robustness, as there is \\nno single point of failure, and agents can operate based on their local knowledge and perceptions.\\nA MAS’s ability to distribute problem-solving capabilities, leverage collective intelligence, exhibit \\nrobustness, and integrate heterogeneous components makes them well suited for addressing complex, \\ndynamic problems that are challenging for traditional, centralized approaches.Understanding multi-agent systems 43\\nInteraction mechanisms in MASs\\nInteraction mechanisms in MASs play a crucial role in enabling effective communication, collaboration, \\nand coordination among the agents within the system. The general classification of the basic interaction \\nmechanisms in a MAS can be presented into three main types:\\n• Cooperation: Cooperation can be defined as agents working together towards a common goal \\nor objective. It is particularly important in situations where no single agent, acting alone, can \\naccomplish the objective.\\nFigure 2.3 – Cooperation in a MAS\\nA prime example of cooperation in MAS is disaster rescue operations, where multiple drones, \\nrobotic agents, and humans need to cooperate and collaborate to locate and rescue victims \\neffectively. A MAS relies on agents cooperating by pooling their knowledge, resources, and \\nefforts to accomplish tasks that are too complex for one agent. Agents may cooperate by dividing \\ntasks, combining their specialized expertise, or complementing each other’s abilities to tackle \\ncomplex problems more efficiently.Principles of Agentic Systems 44\\n• Coordination: Coordination deals with managing interdependencies that arise from the \\nactions and activities of agents within the system. Coordination is essential when agents share \\nresources and have overlapping responsibilities or conflicting actions.\\nFigure 2.4 – Coordination in a MAS\\nCoordination mechanisms in MAS may include strategies such as task scheduling, resource \\nallocation management, and conflict resolution. For example, in a manufacturing setting, agents \\nrepresenting different robots on production lines may need to coordinate their actions to ensure \\nefficient use of shared resources, prevent interference, and maintain overall production efficiency.\\n• Negotiation: Negotiation is the process through which agents reach agreements on how to \\nshare resources, divide tasks, or resolve conflicts. It involves agents making offers, counteroffers, \\nand compromises, even when their interests may initially conflict.Understanding multi-agent systems 45\\nFigure 2.5 – Negotiation in a MAS\\nNegotiation mechanisms in MAS enable agents to find mutually beneficial solutions by \\nexchanging proposals, evaluating alternatives, and reaching consensus. This is particularly \\nuseful in situations where agents have limited or conflicting resources, different preferences, or \\ncompeting goals. Negotiation can involve various techniques, such as auctions, voting protocols, \\nbargaining strategies, or game-theoretic approaches, depending on the specific requirements \\nand constraints of the problem domain.\\nThese interaction mechanisms – cooperation, coordination, and negotiation – are fundamental to the \\neffective functioning of MAS. They enable agents to work together, leverage their collective capabilities, \\nand resolve conflicts or interdependencies that may arise during their interactions. The choice and \\ndesign of appropriate interaction mechanisms are crucial for enabling efficient and robust multi-agent \\nsystems that can tackle complex problems and adapt to dynamic environments.\\nIn the context of our travel assistant example, MASs can play a vital role in facilitating efficient \\ncoordination and negotiation among various entities involved in the travel industry network. In such \\na scenario, agents can represent different stakeholders, such as airlines, hotels, car rental companies, \\ntour operators, or travel agencies, and utilize negotiation mechanisms to optimize various aspects of \\nthe travel booking operations.\\nFor example, consider a MAS where agents represent airlines, hotels, and other relevant parties involved \\nin the travel industry. These agents can engage in negotiation processes to determine flight schedules, \\nroom availability, pricing, and other travel-related decisions, aiming to achieve the highest efficiency \\nfor the overall travel booking operations.Principles of Agentic Systems 46\\nThe negotiation process can unfold as follows:\\n1. Agents representing airlines can propose available seats, flight schedules, and pricing for \\ntheir routes.\\n2. Agents representing hotels can evaluate these proposals based on their room availability, \\nexpected occupancy rates, and demand forecasts, and negotiate with the airline agents for the \\nmost suitable flight schedules that align with their check-in and check-out times.\\n3. Travel agency agents can then negotiate with both airline and hotel agents, taking into account \\ncustomer preferences, budget constraints, and their specific requirements for travel dates \\nand accommodations.\\n4. Transportation agents (for example, car rental companies or shuttle services) can also participate \\nin the negotiation process, offering ground transportation services and proposing pickup/\\ndrop-off schedules and associated costs to the other agents involved.\\nThroughout the negotiation process, agents can utilize various strategies and algorithms to evaluate \\nproposals, generate counteroffers, and find mutually acceptable agreements. These strategies may \\ninvolve techniques such as auctions, bargaining protocols, game-theoretic approaches, or optimization \\nalgorithms tailored for travel industry operations. For example, agents may employ multi-attribute \\nutility functions that consider factors such as travel time, cost, comfort, and customer preferences to \\nevaluate and rank various proposals. They can then engage in iterative negotiations, adjusting their \\noffers and counter offers based on their respective utility functions and constraints.\\nMoreover, the distributed nature of MAS allows decentralized decision-making, where each agent can \\nmake decisions based on its local knowledge and constraints, while still collaborating and coordinating \\nwith other agents to achieve global optimization goals. The negotiation mechanisms in MAS for our \\ntravel and hospitality example not only facilitate efficient coordination among various entities but \\nalso provide the flexibility and adaptability to handle dynamic changes in demand, supply, pricing \\nchanges, or other operational factors, ultimately leading to a more resilient and responsive system \\nthat caters to customer demands.\\nTo illustrate a MAS for our travel booking assistant example, we will introduce some new functionalities. In \\naddition to booking flights, we now want our system to find hotels at the destination and create an appropriate \\ntravel package for the customer. The algorithm for such a MAS system could look like the following:\\nAlgorithm 2: Multi-agent system for travel booking assistant\\nRequire: Sets of Airline Agents A = {A1, A2, ..., An} and Hotel Agents H = {H1, H2, ..., Hm}\\nEnsure: Initialized TravelBookingSystem S with Travel Agency Agent TA\\n1: Initialize S with A, H, and TA\\n2: function RequestTravelPackage(departure, destination, dates)\\n3:     for each Ai in A doUnderstanding multi-agent systems 47\\nAlgorithm 2: Multi-agent system for travel booking assistant\\n4:         available_flights ← Ai.GetAvailableFlights(departure, destination, dates)\\n5:     for each Hj in H do\\n6:         available_rooms ← Hj.GetAvailableRooms(destination, dates)\\n7:     packages ← TA.CompilePackages(available_flights, available_rooms)\\n8:     return packages\\n9: function BookTravel(selected_package)\\n10:    flight_booking ← selected_package.airline.BookFlight()\\n11:    room_booking ← selected_package.hotel.BookRoom()\\n12:    if flight_booking and room_booking are successful then\\n13:        return CreateBooking(flight_booking, room_booking)\\n14:    else\\n15:        return FailureNotification()\\n16: function UpdateDynamicPricing()\\n17:    for each Ai in A do\\n18:        Ai.UpdateFlightPrices()\\n19:    for each Hj in H do\\n20:        Hj.UpdateRoomPrices()\\n21: while True do\\n22:    if NewTravelRequest() then\\n23:        request ← GetTravelRequest()\\n24:        packages ← RequestTravelPackage(request.departure, request.destination, request.dates)\\n25:        selected_package ← TA.PresentOptionsToCustomer(packages)\\n26:        if selected_package is not null then\\n27:            booking ← BookTravel(selected_package)\\n28:            if booking is successful then\\n29:                NotifyCustomer(booking, “Booking confirmed”)\\n30:            else\\n31:                NotifyCustomer(“Booking failed”)\\n32:    if TimeToUpdatePricing() then\\n33:        UpdateDynamicPricing()\\n34: Output SPrinciples of Agentic Systems 48\\nHere is a breakdown of the key components of this algorithm:\\n1. The first step is to clearly define a set of agents: in this case a flight agent, a hotel agent, and a \\ntravel agency agent. The flight and hotel agents are responsible for airlines and hotel-related \\nactions, and the travel agency agent is responsible for creating travel packages based on the \\nbest options available.\\n2. Steps 2 through 8 show how the travel agent interacts with multiple airline and hotel agents \\nto compile travel packages. It finds appropriate flight schedules and hotel availability in the \\ndestination city and subsequently uses that data to create packages.\\n3. Steps 9 through 15 demonstrate the coordination between the selected airline and hotel agents \\nto confirm the flight and hotel booking according to the chosen package.\\n4. Steps 16 through 20 show how each airline and hotel agent independently updates its pricing.\\n5. The main loop from steps 21 through 33 ties everything together, showing how the system \\nhandles travel requests and periodically updates pricing across all agents.\\nThis example algorithm demonstrates a combination of coordination and cooperation between agents:\\n• Cooperation, since all the agents work towards a common goal of booking the travel itinerary \\nfor the user\\n• Coordination, since the travel agency agent needs input from both the flight agent and the hotel \\nagent to build a travel package, and then subsequently book the best travel package\\nThe full Python code related to this algorithm can be found in the Chapter_02.ipynb Python \\nnotebook in GitHub repository. Keep in mind, just like before, our MAS is not very intelligent since \\nit still needs discreet input, that is, departure city code and arrival city code, to operate successfully, \\nand lacks the ability to comprehend or infer values and actions from user messages or text.\\nSummary\\nIn this chapter, we explored the intriguing world of agentic systems and intelligent agents, delving into \\nthe core concepts of agency, autonomy, and the characteristics that define an ideal agent. We studied \\nvarious architectural patterns for designing and implementing such systems, including deliberative, \\nreactive, and hybrid approaches. Additionally, we examined MASs, where multiple agents collaborate \\nand coordinate to achieve collective goals through mechanisms such as cooperation, coordination, \\nand negotiation.\\nThe knowledge gained from this chapter provides a solid foundation for developing intelligent and \\nautonomous systems capable of operating effectively in complex, unpredictable environments. Y ou \\nshould now be able to decide which agentic system architecture best suits any particular use case, and \\nbe able to craft a mental model of a MAS that gives you the foundation of your agentic system. In the \\nnext chapter, we will dive deeper into the essentials of an agentic system, further strengthening our \\nability to build efficient systems.Questions 49\\nQuestions\\n1. What are the key characteristics of intelligent agents?\\n2. What are the main types of architectural patterns for intelligent agents?\\n3. How do deliberative and reactive architectures differ in their strengths and weaknesses?\\n4. What is a multi-agent system (MAS) and what are its key characteristics?\\n5. What are the main interaction mechanisms in MASs?\\n6. In what domains are MASs commonly applied?\\nAnswers\\n1. Key characteristics of intelligent agents include reactivity, proactiveness, social ability, autonomy, \\nand the capability to learn and adapt.\\n2. The main architectural patterns for intelligent agents are deliberative (knowledge-based), \\nreactive (behavior-based), and hybrid architectures.\\n3. Deliberative architectures excel in complex reasoning and planning but may struggle with \\nreal-time responsiveness in dynamic environments. Reactive architectures are well suited for \\ndynamic environments requiring rapid responses but lack long-term planning and abstract \\nreasoning capabilities.\\n4. A multi-agent system (MAS) consists of multiple intelligent agents that interact, cooperate, \\nand coordinate to achieve collective goals. Key characteristics include autonomy, interaction, \\nadaptability, distributed control, scalability, heterogeneity, and decentralized data and knowledge.\\n5. The main interaction mechanisms in MASs are cooperation (working towards a common \\ngoal), coordination (managing interdependencies), and negotiation (reaching agreements).\\n6. MASs find applications in domains such as supply chain management, traffic control, robotics, \\nenvironmental monitoring, distributed sensor networks, and intelligent virtual environments.\\nJoin our communities on Discord and Reddit\\nHave questions about the book or want to contribute to discussions on Generative AI and LLMs? \\nJoin our Discord server at https://packt.link/I1tSU and our Reddit channel at https://\\npackt.link/ugMW0 to connect, share, and collaborate with like-minded enthusiasts.3\\nEssential Components of \\nIntelligent Agents\\nIn this chapter, we’ll dive into the essential components that make up the core of intelligent agents. \\nJust as the human body has a skeleton that provides structure and support, intelligent agents have \\ncertain fundamental elements that allow them to adapt, act independently, and pursue goals in \\ncomplex environments.\\nWe’ll look at the important pieces that bring agents to life – how they represent and store knowledge, \\nthe reasoning processes that guide their decision-making, the algorithms that help them learn and \\ngrow, and the mechanisms for choosing the right actions to take. Y ou’ll also see how the exciting field of \\ngenerative AI can supercharge these components, giving agents more powerful abilities to understand \\ntheir surroundings, learn from experiences, and interact meaningfully with the world around them.\\nIn this chapter, we’re going to cover the following main topics:\\n• Knowledge representation in intelligent agents\\n• Reasoning in intelligent agents\\n• Learning mechanisms for adaptive agents\\n• Decision-making and planning in agentic systems\\n• Enhancing agent capabilities with generative AI\\nBy the end of this chapter, you’ll understand knowledge representation methods in intelligent agents, \\nreasoning and learning mechanisms, decision-making, and planning techniques, as well as having \\nexplored a generative AI-powered enhanced agent example.\\nTechnical requirements\\nY ou can find the code files for this chapter on GitHub at https://github.com/PacktPublishing/\\nBuilding-Agentic-AI-Systems.Essential Components of Intelligent Agents 52\\nKnowledge representation in intelligent agents\\nThe ability to store and manipulate information is fundamental for any intelligent agent. Knowledge \\nrepresentation provides the mechanisms for encoding an agent’s understanding of its environment \\ninto formats amenable to reasoning and decision-making processes. It is the most basic way to enable \\nan intelligent agent to build a model of its surroundings.\\nKnowledge representation can be formally defined as the method of structuring and organizing \\ndata in such a way that an agent can effectively utilize that information for tasks such as drawing \\ninferences, solving problems, and determining a course of action. There are several well-established \\napproaches to knowledge representation, each with its own strengths and ideal applications, which \\nwe will discuss next.\\nSemantic networks\\nSemantic networks provide one of the most intuitive and flexible approaches for representing knowledge \\nwithin intelligent agents. At their core, semantic networks are graph-based structures composed of \\nnodes that represent concepts, entities, events, or states in the world. These nodes are connected by \\nlabeled edges that explicitly define the semantic relationships between the represented concepts.\\nThe simplicity yet expressiveness of semantic networks allows them to naturally capture the rich, diverse \\nrelationships and interconnections that exist in our complex world. For example, a node representing \\nthe concept of “dog” could be connected to the “animal” node via an “is-a” relation edge, indicating \\nthat dogs are a type of animal. That same “dog” node may also be connected to nodes for “mammal,”  \\n“domesticated, ” “canine, ” and “pet” via other typed relationship links:\\nFigure 3.1 – Semantic network representing “Dog” relationships\\nUnlike strict logic or rigid database schemas, semantic networks provide a flexible knowledge \\nrepresentation where any concept can be associated with any other concept through an appropriate \\nsemantic relation. This flexibility enables semantic networks to represent incredibly nuanced domains \\nin an intuitive graphical form. As a real-world example, a medical semantic network could modelKnowledge representation in intelligent agents 53\\ndiseases, symptoms, treatments, and anatomical concepts with relation types such as “ causes,”  \\n“is-diagnosed-by,”  “interacts-with, ” and so on:\\nFigure 3.2 – Semantic network representing “Disease” relationships\\nSemantic networks gain much of their power from their ability to perform generalization through the \\ninheritance of properties along relationship paths. If the network specifies that dogs are a subclass of \\nanimals and that animals breathe air, then an agent can semantically infer that dogs also breathe air \\nthrough inheritance. Algorithms can traverse the graph, chaining sequences of relations together to \\nderive new facts and conclusions from the represented knowledge. For instance, in a semantic network \\nfor family relations, one could infer that a person’s spouse’s parents are also their in-laws.\\nAdditionally, semantic networks integrate naturally with other symbolic reasoning techniques. Their \\ngraph-based structure maps well to deductive methods such as first-order logic, where nodes become \\nconstants or predicates and edges become relations that can participate in logical proofs and inference \\nrules. An intelligent tutoring system could use this combined representational power for logic-based \\nexplanations and teach students new concepts based on their semantic knowledge graphs.\\nSemantic networks provide a robust yet intuitive mechanism for intelligent agents to build rich, \\nexpressive models of their environment. Their inherent support for capturing interconnected concepts \\nand deriving new knowledge through relation composition and inheritance makes them an extremely \\npowerful knowledge representation formalism across many real-world domains.Essential Components of Intelligent Agents 54\\nFrames\\nThe frame knowledge representation paradigm provides a structured way for intelligent agents to \\nmodel concepts and their associated attributes. In this formalism, knowledge about objects, situations, \\nor events is stored in data structures called frames.\\nEach frame consists of a collection of attribute-value pairs that describe the properties and characteristics \\nof the concept being represented. For example, a frame for the concept “Car” may contain attributes \\nsuch as “make,”  “model,”  “year,”  “color,”  “fuel type, ” and so on with corresponding values providing \\nspecifics for a particular car instance.\\nFrames are organized hierarchically, allowing for the inheritance of attributes from higher-level, more \\ngeneral frames down to their specialized sub-frames. The “Car” frame could inherit properties from a \\nparent “Vehicle” frame while adding new attributes unique to cars. This hierarchical taxonomy facilitates \\nefficient knowledge storage by avoiding redundant attribute definitions across related concepts.\\nA key advantage of frames is their flexibility to represent procedural knowledge alongside factual \\ninformation. In addition to simple attribute-value slots, frames can contain procedures that supply \\nattribute values dynamically or model operations relevant to the represented concept. For instance, \\nthe “Car” frame could have methods for calculating fuel efficiency or querying service records. The \\nfollowing figure illustrates the concept of frames with our vehicle example:\\nFigure 3.3 – Frames representing “Vehicle” and “Car” relationshipsKnowledge representation in intelligent agents 55\\nFrames provide an intuitive model for representation that mirrors how humans conceptualize knowledge \\nabout the world. Their hierarchical nature aligns with how people form conceptual abstractions and \\ncategorize ideas based on shared attributes and relations.\\nIn real-world applications, frame representations are widely used in areas such as the following:\\n• Natural language processing: Linguistic frames model semantic concepts, roles, and relations \\nextracted from text data\\n• Expert systems: Frames capture domain expertise and rules for knowledge-based reasoning engines\\n• Object-oriented programming: Classes in OOP languages are essentially frame-like structures \\nencapsulating attributes and methods\\n• Computer vision: Object detection systems use frame hierarchies to identify and describe \\nvisual entities based on attributes such as shape, color, texture, and so on\\n• Robotics: Frames enable robots to represent objects/environments along with associated actions, \\nmotion models, and constraints\\nThe frame knowledge representation formalism offers an efficient, structured, and human-compatible \\nway for intelligent agents to capture rich conceptual information suitable for knowledge-based \\nreasoning and decision-making.\\nLogic-based representations\\nWhile semantic networks and frames offer visually intuitive ways to represent knowledge, the logic-\\nbased approach takes a more formal, mathematical route. Logic-based knowledge representation \\nemploys the machinery of symbolic logic to encode facts, rules, and axioms about a domain.\\nIn this paradigm, statements representing knowledge are translated into well-formed formulae in \\nformal logical languages such as propositional logic, first-order logic, or specialized modal/temporal \\nlogics. See this, for example:\\n• “All humans are mortal” can be represented as ∀x (Human(x) → Mortal(x)) in first-order logic\\n• “It is raining or it is sunny” can be expressed as Rain ∨ Sunny in propositional logic\\n• “Eventually, the system will stabilize” can be modeled as ◇ Stable in temporal logic\\nHere:\\n• ∀x: Universal quantifier meaning “for all x.”\\nExample: ∀x (Human(x) → Mortal(x)). Translation: For all x, if x is a human, then x is mortal.\\n• ∨: Logical disjunction meaning “or.”\\nExample: Rain ∨ Sunny. Translation: It is either raining or sunny.Essential Components of Intelligent Agents 56\\n• ◇: Diamond operator in temporal logic meaning “eventually.”\\nExample: ◇Stable. Translation: Eventually, the system will stabilize.\\nThese logical formulae act as the building blocks for constructing a comprehensive knowledge base using \\nstrict logical deductive systems with clearly defined axioms, inference rules, and formal semantics. An \\ninference engine can then derive new facts and conclusions from the existing knowledge by applying \\nthe rules of logical reasoning.\\nA key advantage of logic-based representations is their formal rigor and associated strong theoretical \\nproperties. Systems built on logical foundations can provide guarantees around soundness (only \\nderiving logically valid conclusions) and completeness (deriving all possible valid conclusions). This \\nmathematical grounding makes logic attractive for knowledge representation in safety-critical domains. \\nLogic-based representations find widespread use in many real-world applications, such as these:\\n• Expert systems: Rule-based expert system engines are essentially theorem provers operating \\nover a logical knowledge base encoding domain expertise\\n• Database systems: Relational databases use relational algebra/calculus – subsets of first-order \\nlogic – as the mathematical foundations\\n• Automated reasoning: From software verification to robot planning, logic provides the \\nrepresentational underpinnings for automated reasoning systems\\n• Legal/regulatory domains : Laws, policies, and regulations can be precisely represented as \\nlogical rules amenable to formal analysis\\n• Semantic web: Description logics such as OWL (Web Ontology Language) form the knowledge \\nrepresentation backbone of ontologies and the Semantic Web\\nWhile logic-based representations aren’t as intuitive as semantic networks or frames, their mathematical \\nrigor and ability to support sound, automated reasoning make them invaluable in applications where \\nformal verification, consistency, and completeness guarantees are essential.\\nHaving explored the foundational structures of knowledge representation, which form the basis of an \\nagent’s knowledge base, we now turn to examine how intelligent agents harness these representations \\nto perform reasoning tasks, draw inferences, and solve complex problems.\\nReasoning in intelligent agents\\nBy employing the language of logic, intelligent agents can build robust knowledge bases, enabling \\nsophisticated querying, deductive inference, and reasoning that are not possible with less expressive \\nrepresentational formalisms. Once an intelligent agent has a robust way to represent its knowledge, \\nreasoning mechanisms allow it to intelligently manipulate and make use of that information. Reasoning \\ncapabilities enable agents to derive new insights, draw logical conclusions, explain observations, and \\nultimately make informed decisions to achieve their goals.Reasoning in intelligent agents 57\\nReasoning in intelligent agents is rarely a singular, monolithic process. Sophisticated agent architectures \\ntend to employ a multi-faceted reasoning approach that combines different reasoning styles and data-\\ndriven, analytical, and learned components. For instance, a question-answering system could use \\nsemantic parsing to map questions to logical forms, apply deductive reasoning over a logical knowledge \\nbase, and then invoke a neural sequence-to-sequence model to render the final answer fluently. There \\nare several fundamental reasoning paradigms, namely, deductive, inductive, and abductive reasoning.\\nDeductive reasoning\\nDeductive reasoning is a fundamental form of logical reasoning that follows a top-down approach. \\nIn deductive reasoning, an intelligent agent starts with general premises or rules about a domain and \\napplies them to derive specific, logically inescapable conclusions. The classic example illustrating \\ndeductive reasoning is the following popular syllogism:\\n“ All men are mortal.\\nSocrates is a man.\\nTherefore, Socrates is mortal. ”\\nIf the initial premises (“All men are mortal” and “Socrates is a man”) are true, then the conclusion \\n“Socrates is mortal” follows inescapably from applying the rules of deductive logic. Deduction provides \\na way to reach irrefutable conclusions as long as the original premises and rules are correct and factual. \\nThe following figure illustrates deductive reasoning with the example:\\nFigure 3.4 – Deductive reasoning – from general premises to specific conclusions\\nDeductive reasoning finds application across many domains, such as these:\\n• Mathematics/geometry: Formal mathematical proofs are quintessential examples of deductive \\nreasoning, deriving specific theorems from general axioms and previously proven statements\\n• Law: Legal reasoning applies codified laws and precedents to derive judgments about particular \\ncases through deductionEssential Components of Intelligent Agents 58\\n• Software verification: Formal verification techniques use deductive reasoning over logical \\nspecifications to prove correctness properties of hardware/software systems\\n• Network routing: Routing protocols determine optimal paths by deductively applying rules/\\nconstraints about network topology, bandwidth, and so on\\nDeductive reasoning is particularly powerful when combined with other forms of reasoning such as \\nabduction or induction. For example, a medical diagnosis system could do the following:\\n• Abduce possible disease hypotheses from symptoms (inference to the best explanation)\\n• Deduce expected findings for each hypothesis using rules about disease models\\n• Compare deduced findings to actual patient data to confirm/reject hypotheses\\nWhile deduction alone cannot acquire entirely new knowledge, it is indispensable for intelligent agents \\nto logically expand their knowledge, enforcing consistency and enabling rational decision-making. \\nDeductive reasoning provides the rigor to ensure the trustworthiness of an agent’s conclusions.\\nInductive reasoning\\nIn contrast to the top-down approach of deductive reasoning, inductive reasoning follows a bottom-up \\nmethodology. Inductive reasoning involves making generalizations or deriving probable conclusions \\nfrom a set of specific observations or data points. The following is an example:\\n“The Sun has risen every day for the past million days.\\nTherefore, the sun will likely rise again tomorrow. ”\\nBased on the repeated instances of the sun rising, an inductive reasoning process allows an intelligent \\nagent to hypothesize or induce that the sun will continue rising in the future. However, unlike deduction, \\ninductive conclusions are not logically guaranteed to be true – they merely suggest a likely possibility \\nbased on the observed evidence. The following figure illustrates the concept with the example:\\nFigure 3.5 – Inductive reasoning – from specific observations to general conclusionsReasoning in intelligent agents 59\\nInductive reasoning has immense applicability in the following real-world domains where data-driven \\nlearning and theory formation are crucial:\\n• Scientific method: The process of formulating scientific laws/theories relies heavily on inductively \\ngeneralizing from experimental observations and data\\n• Machine learning: ML algorithms essentially perform inductive reasoning, inferring general \\nmodels from training data that can make predictions on new instances\\n• Pattern recognition: Computer vision, signal processing, and other pattern recognition tasks \\nuse inductive techniques to classify inputs based on detected statistical regularities\\n• Data mining: Approaches such as association rule mining inductively identify frequently \\noccurring patterns, correlations, or relationships in large datasets\\n• Natural language acquisition: Children learn grammar rules and language models through \\ninductive generalization from the linguistic inputs they receive\\nWhile powerful, purely inductive reasoning has limitations since conclusions can be incorrect if the \\nobserved instances are an imperfect sample not representative of the entire space. As such, it is often \\ncombined with other reasoning approaches such as abduction (inference to the best explanation) and \\ndeduction (validating hypotheses) in intelligent agent architectures. Despite not guaranteeing truth, \\ninductive reasoning’s ability to extract knowledge, recognize patterns, and formulate theories from \\nspecific data makes it indispensable for intelligent agents operating in noisy, uncertain environments \\nwhere knowledge is not fully available upfront.\\nAbductive reasoning\\nAbductive reasoning is a form of reasoning that works backward – attempting to find the most \\nplausible explanations or premises that could account for a given set of observations or data. It is \\noften described as inference to the best explanation. Unlike deductive reasoning, which starts with \\ngeneral rules and arrives at guaranteed specific conclusions, abduction begins with observed effects \\nor phenomena and hypothesizes the most likely underlying causes based on current knowledge. An \\nexample of abductive reasoning is:\\n“The lawn is wet.\\nA plausible explanation: It rained last night. ”\\nHere, the observed effect is a wet lawn. Abductive reasoning allows an intelligent agent to rationally \\ndeduce or infer that the most likely explanation, based on past experience, is that it rained the previous \\nnight, even though that was not directly observed. The following figure illustrates this concept of \\nbackward reasoning:Essential Components of Intelligent Agents 60\\nFigure 3.6 – Abductive reasoning – inference to the best explanation\\nAbductive reasoning is extremely useful in diagnostic domains and applications where root cause \\nanalysis is critical, such as these:\\n• Medical diagnosis : Given a set of symptoms, physicians abduce and investigate the most \\nprobable diseases or conditions that could explain those symptoms\\n• Fault detection: Monitoring systems in manufacturing use abduction to isolate the most likely \\nfaults or failures that led to observed anomalies\\n• Forensics/criminal investigation: From crime scene evidence, detectives abduce possible \\nscenarios and suspect profiles to determine what transpired\\n• AI planning: For agents to achieve desired goals, they must abduce sequences of viable actions \\nby reasoning backward from those goals\\n• Scientific discovery: New scientific theories are often initially inferred by finding explanatory \\nhypotheses for currently unexplained observations or phenomena\\nA key advantage of abductive reasoning is its ability to generate new plausible premises that deductive \\nor inductive methods cannot produce solely from existing knowledge and data. It facilitates thinking \\noutside the box and exploring novel possible explanations. However, abduction does not guarantee \\ncorrect explanations – there may be multiple possible hypotheses consistent with the observations. \\nThis is why abductive reasoning is commonly used in tandem with deductive reasoning to validate \\nthe consistency and plausibility of the explanatory hypotheses formed.Learning mechanisms for adaptive agents 61\\nPoints to remember here are that implementing abductive reasoning in agentic systems is challenging \\ndue to its computational complexity, as generating and evaluating multiple hypotheses can be resource-\\nintensive. It also deals with uncertainty and incomplete data, making it difficult to determine the \\nmost plausible explanations. Proper knowledge representation is crucial but difficult to maintain, \\nand evaluating hypotheses often requires subjective criteria. Integrating abductive reasoning with \\nother reasoning modes can lead to conflicts, and scalability becomes an issue as the domain grows. \\nAdditionally, handling dynamic environments and ensuring explainability for users may add further \\ncomplexity to the process. However, by applying abductive reasoning, intelligent agents can exhibit \\ndeeper understanding, creativity in postulating tentative explanations, and an increased ability to \\noperate effectively in uncertain environments with partial observability and information. Through \\nrobust knowledge representation formalisms and multi-faceted reasoning capabilities, intelligent \\nagents gain the power to build rich models of their environment, draw insights, explain observations, \\nand ultimately make well-informed decisions about how to interact with the world. These capabilities \\nform the bedrock for more advanced agent functionality.\\nLearning mechanisms for adaptive agents\\nLearning mechanisms are key to enabling intelligent agents to adapt to changes in their environment \\nor to improve over time. The ability to learn allows agents to continuously refine their knowledge and \\nbehavior based on new experiences and data. There are numerous approaches to learning, each with \\nits own strengths and applications:\\n• Supervised learning: This learning paradigm involves training an agent on a dataset where the \\ninputs are paired with corresponding labeled outputs or target values. The aim is for the agent \\nto learn a mapping function that accurately predicts outputs for new unseen inputs. Supervised \\nlearning is widely used for classification and regression tasks across domains such as these:\\n \\x82 Image classification (for example, identifying objects and digits in images)\\n \\x82 Spam detection (classifying emails as spam or not spam)\\n \\x82 Machine translation (learning to map text in one language to another)\\n \\x82 Medical diagnosis (mapping patient symptoms/tests to disease labels\\n• Unsupervised learning: Here, the agent is trained on unlabeled data without any associated \\ntarget outputs. The goal is to discover inherent patterns, correlations, or groupings within the \\ndata itself in an unsupervised manner. Key applications include the following:\\n \\x82 Customer segmentation (grouping customers based on purchasing behavior)\\n \\x82 Anomaly detection (identifying unusual data points that differ from the norm)\\n \\x82 Topic modeling (extracting topics/themes from collections of documents)\\n \\x82 Dimensionality reduction (finding lower-dimensional representations of high-dimensional data)Essential Components of Intelligent Agents 62\\n• Reinforcement learning: This learning approach is inspired by how humans and animals \\nlearn – through trial and error using feedback from the environment in the form of rewards \\nor punishments. An RL agent learns optimal behaviors/policies by trying out different actions \\nand updating its strategy based on the observed rewards. RL has seen great success in domains \\nsuch as the following:\\n \\x82 Game playing (learning to master games such as chess, Go, and video games)\\n \\x82 Robotics (learning control policies for robot navigation and manipulation)\\n \\x82 Supply chain optimization (finding policies to maximize efficiency)\\n \\x82 Traffic signal control (learning timing policies to improve traffic flow)\\n• Transfer learning: This technique focuses on transferring knowledge learned in one setting to \\nfacilitate learning in a different but related setting. By leveraging previously learned patterns \\nand representations, transfer learning can significantly accelerate training speed and sample \\nefficiency for new tasks. Applications span areas such as the following:\\n \\x82 Natural language processing (transferring language models across domains)\\n \\x82 Computer vision (using pre-trained models as initialization for new vision tasks)\\n \\x82 Recommendation systems (transferring user/product embeddings across platforms)\\nThese learning mechanisms, often used in hybrid combinations, equip intelligent agents with the \\nability to continuously expand their knowledge, refine their behaviors, and grow their problem-\\nsolving capabilities – the key hallmarks of intelligence. As learning algorithms advance, agents will \\nonly become more adaptable and robust when facing new challenges.\\nHaving explored the learning mechanisms that enable adaptive agents to acquire knowledge and skills, \\nwe now turn our attention to how these agents leverage this learning to make decisions and plan their \\nactions in complex environments.\\nDecision-making and planning in agentic systems\\nDecision-making and planning are critical capabilities for intelligent agents to achieve their goals \\neffectively in complex environments. Agents need to analyze various possible scenarios, evaluate \\noutcomes, and select the action(s) that will lead to the most desirable outcome based on their preferences \\nand constraints. Although utility functions (tools) and planning will be discussed in detail in later \\nchapters, we will discuss these key components involved in agent decision-making at a high level in \\nthe following sections.Decision-making and planning in agentic systems 63\\nUtility function\\nA utility function quantifies an agent’s preferences by mapping outcomes to utility values, enabling the \\nagent to compare and choose actions that maximize expected utility. Utility functions play a central \\nrole in decision-making for intelligent agents by providing a quantitative way to represent and reason \\nabout preferences over different outcomes or states of the world.\\nA utility function  maps any given state or outcome  to a real-numbered utility value , reflecting the \\ndesirability or preference for that state according to the agent’s goals, rewards, and penalties. Formally, \\nthis is mathematically expressed as:\\nThis expression may look a little intimidating at first, but the concept is really straightforward. Let us \\nuse some example Python code to explain this further:\\n1 def travel_utility_function(travel_option):\\n2    price_utility = (1000 - travel_option[\\'price\\']) * 0.05\\n3    comfort_utility = travel_option[\\'comfort_rating\\'] * 10\\n4    conv_utility = travel_option[\\'convenience_score\\'] * 15\\n5\\n6    total_utility = price_utility + \\\\\\n7                    comfort_utility + \\\\\\n8                    convenience_utility\\n9\\n10    return total_utility\\nTo explain this utility function, let us go back to our travel booking example. The given Python \\nutility function evaluates travel options based on price, convenience, and comfort. Lines 2,3, and 4 \\nof the function assign a real numbered utility for price, comfort, and convenience respectively. The \\nnumbers 0.05, 10, and 15 are completely arbitrary but are in the order of magnitude of importance \\nof each of the three factors in a person’s travel decision-making. For example, in line 2, we assign the \\nprice utility to a number; note that we subtract the price from an arbitrary value of 1000, since the \\nlower the price the better, which means a lower price contributes to more utility. Thus, the price utility \\nnumber would be higher if the price is lower, that is, an inverse relationship. Similarly, the comfort \\nand convenience utilities are assigned respective utility scores. The comfort and convenience scores \\nare often user provided. For example, travel review websites such as Tripadvisor allow users to post \\ndetailed reviews about their travel experience via star ratings.\\nApplying our utility function to a few travel options will give us a clear picture of how this function \\nworks. Let us apply the utility function to two travel options a Budget Airline vs Road Trip.Essential Components of Intelligent Agents 64\\nA sample input to the utility function is as follows:\\n1 [{\\n2     \\'name\\': \\'Budget Airline\\',\\n3     \\'price\\': 300,\\n4     \\'comfort_rating\\': 3,\\n5     \\'convenience_score\\': 2\\n6 },\\n7 {\\n8     \\'name\\': \\'Road Trip\\',\\n9     \\'price\\': 150,\\n10    \\'comfort_rating\\': 4,\\n11    \\'convenience_score\\': 3\\n12 }]\\nHere’s the output of the utility function:\\n1 Budget Airline – Utility: 95.00\\n2 Road Trip – Utility: 127.50\\nThe output clearly shows that the road trip option scores a higher utility score due to higher convenience, \\ncomfort, and lower price compared to the budget airline. The full code is available in the Chapter_03.\\nipynb Python notebook in our GitHub repository.\\nUtility functions encode an agent’s preferences by mapping states or outcomes to utility values, \\nallowing any two states to be ranked or compared based on their assigned utilities. Higher utility \\nvalues correspond to more preferred states or outcomes. This enables rational agents to select actions \\nthat maximize their expected utility, which is calculated as the probability-weighted sum of utilities \\nover all possible outcome states resulting from those actions. By quantifying preferences in this way, \\nutility functions provide a systematic mechanism for agents to make rational decisions in pursuit of \\nthe most desirable outcomes according to the specified utility measure. Utility functions can take \\nmany mathematical forms depending on the domain, such as the following:\\n• Simple scoring functions that apply weights to quantify preferences between attributes\\n• Constraint satisfaction functions that are maximized when all hard constraints are met\\n• Economic utility functions modeling pricing, profits, costs, and so on\\n• Multiplicative functions modeling preferences between outcomes with independent utility impacts\\nMore sophisticated utility functions can model uncertainty, risk preferences, multi-attribute tradeoffs, \\nchanging preferences over time, and dependencies between attributes. In the case of multi-attribute \\ntradeoffs, an agent must weigh different attributes (for example, cost, quality, time, or safety) when \\nmaking decisions. These attributes often conflict, and an agent must find a balance between them, suchDecision-making and planning in agentic systems 65\\nas choosing between a faster but more expensive option versus a slower, cheaper one. The challenge \\nhere lies in quantifying how much an agent values each attribute relative to others, and how changes \\nin one attribute influence the overall utility.\\nDefining an accurate quantitative utility function that captures all of an agent’s preferences is often \\na major challenge because preferences are often complex and context-dependent. Agents may have \\ndifferent attitudes toward risk (for example, risk-averse or risk-seeking), and preferences may change \\nbased on the situation or over time. Additionally, dependencies between attributes – such as how \\nthe increase in one attribute (e.g., speed) may negatively affect another (for example, cost) – can \\ncomplicate the modeling process. Moreover, the uncertainty in predicting outcomes or preferences \\nunder changing conditions further complicates the task of creating a utility function that fully reflects \\nthe agent’s decision-making process. Techniques such as preference elicitation, inverse reinforcement \\nlearning, and learning from human feedback are used in such cases.\\nPlanning algorithms\\nPlanning algorithms are algorithms that derive sequences of actions for an agent to take in order to \\nachieve its goals from a given initial state. Some of the most common planning approaches include \\ngraph-based planning, heuristic search, Monte Carlo tree search (MCTS), hierarchical planning, \\nand constraint satisfaction. Let’s discuss each of these planning algorithms in the following sections.\\nGraph-based planning\\nGraph-based planning represents a planning problem as a graph, where the nodes correspond to \\npossible states or configurations, and the edges represent actions or transitions that can be taken to \\nmove between states. A fundamental concept within graph-based planning algorithms is the state-\\nspace graph, which is a graph representation where nodes represent all possible states in the problem \\ndomain. In such a representation, the edges represent the actions or transitions between the states. \\nThis graph representation effectively maps out the entire “space” of possible situations and how they \\nconnect with each other via edges.\\nAn edge cost is a property of an edge in a weighted graph. Each edge can have an associated cost (or \\nweight) that represents some measure of the “expense” of taking that action or making that transition. \\nCosts could represent factors such as distance, time, energy consumption, financial cost, or any other \\nrelevant metric appropriate for the use case.\\nUsing state-space graphs, edges, and edge costs, there are two broad categories of graph-based \\nplanning algorithms:\\n• Graph search: In graph search, the planning process involves searching this graph data structure \\nto find a path from the initial state to one of the goal states. The path defines the sequence of \\nactions for the agent to execute to transition between states and reach the goal. Some of the \\nmost common algorithms under this category are depth-first search (DFS), breadth-first \\nsearch (BFS), and Dijkstra’s algorithm.Essential Components of Intelligent Agents 66\\n• Optimal path finding: This is a specific type of graph search that aims to find not just any path, \\nbut the best path according to some criteria (usually minimizing total edge cost). Two of the \\nalgorithms in this category are the Bellman-Ford algorithm and the A* search.\\nThe downsides of using graph-based planning algorithms include fixing the state representation (state \\nspace) upfront, and the potential for exponential growth in the number of states to represent and \\nstore as problems get more complex.\\nGraph-based planning techniques find numerous real-world applications across domains, where \\nfinding optimal sequences of actions to achieve goals is crucial. These applications include navigation \\nand route planning, such as GPS systems using graph representations of road networks to find optimal \\nroutes minimizing travel time or distance. Logistics and supply chain applications involve planning \\noptimal sequences of operations for manufacturing products or finding least-cost shipping routes and \\ndelivery schedules. AI planning employs graph-based methods for game AI move sequencing in chess, \\nvideo games, and real-time strategy games, as well as for task planning in AI assistants.\\nHeuristic search\\nHeuristic search techniques are widely used when finding optimal solutions through exhaustive \\nsearch is computationally intractable due to the exponential growth of the search space. By using \\nheuristic functions to guide the search toward promising areas, these methods can find reasonably \\ngood approximate solutions much faster.\\nHeuristic search techniques find widespread use in route planning and navigation applications. \\nWhen finding truly optimal routes is computationally too expensive, heuristics such as estimating \\nthe straight-line distance to the destination can effectively guide the search toward reasonably short \\ndriving routes. AI agents in video games also commonly employ heuristic pathfinding algorithms to \\nnavigate virtual environments efficiently.\\nThe key benefit of heuristic search is the ability to trade off optimality for computational efficiency, \\nmaking larger problem instances solvable within limited time/memory constraints by finding approximate \\nsolutions. Heuristic design remains a critical challenge tailored to each application domain.\\nMonte Carlo tree search\\nThe core idea behind MCTS is to iteratively build an asymmetric search tree by running many random \\nsimulations (playouts) from the current state. An asymmetric tree means that the tree is not balanced \\nor uniform in its structure. The results of these simulations are used to guide the growth of the most \\npromising branches in the tree at each iteration.\\nMCTS has seen widespread adoption across various real-world applications involving sequential \\ndecision-making under uncertainty. This algorithm has particular benefits in AI agents in situations that \\nare likely to encounter uncertainties, and contain large state spaces, that is, a large number of possible \\noutcomes. MCTS is found to produce reasonable results even with limited computational resources.Decision-making and planning in agentic systems 67\\nThe key advantages of MCTS are anytime behavior, the ability to handle large action spaces, and \\nreasoning about long-term outcomes through simulations. However, its efficiency depends on having \\nan effective simulation model and designing good exploration strategies tailored to the domain. \\nSome of the common drawbacks of this algorithm include the computational intensity required \\nfor simulations of complex problems and the difficult-to-tune tree policy that helps with outcome \\nselection during simulations.\\nHierarchical planning\\nHierarchical planning approaches breaking down complex problems into hierarchies of higher-level tasks or \\ngoals, and subtasks or subgoals that achieve those higher-level objectives. This hierarchical decomposition \\nallows reasoning about problems more abstractly and reusing solutions to common subproblems.\\nThe core advantages of hierarchical approaches include computational efficiency via reusing subplan \\nsolutions, knowledge representation at multiple abstraction levels, and increased scalability to handle \\nhighly complex problems through hierarchical reasoning, though not always optimally. This structure \\nalso aligns well with how humans conceptualize and tackle complex tasks. The core advantages of \\nhierarchical approaches include the following:\\n• Computational efficiency by reusing subplan solutions and avoiding reasoning about all \\ndetails simultaneously\\n• Knowledge representation at multiple levels of abstraction\\n• Increased scalability to handle very complex problems\\nWhile not always optimal, hierarchical plans can provide good approximations for large problems \\nwhere optimal solutions may be computationally unmanageable. The structure also maps well to how \\nhumans tend to conceptualize and tackle complex tasks.\\nConstraint satisfaction\\nConstraint satisfaction problems (CSPs) involve formulating the problem as a set of constraints \\nthat must be satisfied, and then using constraint propagation techniques to eliminate inconsistent \\npossibilities from the search space. CSPs represent a powerful framework in AI for solving a wide \\nvariety of complex problems. At their core, CSPs involve defining a problem in terms of variables \\nthat need to be assigned values, under a set of constraints that restrict the possible combinations of \\nthese values. This approach allows for a natural representation of many real-world problems, from \\nscheduling and resource allocation to puzzle-solving and configuration tasks.\\nThe beauty of CSPs lies in their ability to separate the problem representation from the solving method. \\nOnce a problem is formulated as a CSP , a variety of general-purpose algorithms can be applied to find \\na solution. This separation allows researchers and practitioners to focus on accurately modeling the \\nproblem without worrying about the intricacies and complexities of the solving algorithm.Essential Components of Intelligent Agents 68\\nIntelligent agents require flexible decision-making capabilities that can weigh constraints, handle \\nuncertainty, learn from experience, and scale to complex real-world problems in pursuit of their \\ngoals. Advances in planning, search, reasoning, and learning algorithms continue enhancing these \\ncrucial cognitive abilities.\\nHaving examined the foundational aspects of intelligent agents – from knowledge representation and \\nreasoning to learning mechanisms and decision-making processes – we now turn our attention to a \\ncutting-edge development that promises to significantly expand these capabilities: the integration of \\ngenerative AI into agent systems.\\nEnhancing agent capabilities with generative AI\\nGenerative AI is transforming the development of intelligent agents by enhancing learning efficiency, \\nimproving their understanding of environments, and enabling more complex interactions through \\ngenerative models. Some of the major developments in ushering generative AI in the space of intelligent \\nagents are as follows:\\n• Data augmentation: Creating synthetic training data with generative models supplements \\ndatasets, improving the robustness and efficiency of machine learning agents. For example, \\nself-driving car agents can use generated scene images to learn better object detection and \\nnavigation policies.\\n• Understanding of context : Generative AI constructs simulations modeling real-world \\ncomplexities in fine detail, aiding agents in contextual understanding for informed decisions. \\nFor example, virtual assistants such as chatbots can use generative AI to simulate conversations \\nin diverse contexts, helping them better understand user intent and provide more accurate, \\ncontext-aware responses before interacting with real users.\\n• Natural language processing: Generative language models ease human-agent interaction by \\nimproving understanding and generation capabilities. Virtual assistants such as Alexa and \\nchatbots leverage generative NLP for natural conversations.\\n• Creative problem solving: By generating diverse possible solutions, generative AI allows agents \\nto explore creative ideas and evaluate their feasibility. This could allow AI architects to creatively \\ndesign innovative building layouts while adhering to structural constraints.\\nThe deep integration of generative AI with knowledge representation, learning mechanisms, and \\ndecision-making processes yields highly responsive and adaptive intelligent agents capable of operating \\neffectively in dynamic, complex environments. Some examples of how this synergistic combination \\ncan enable advanced capabilities are as follows:\\n• Learning: Agents can gather data from various sources such as sensors, human interactions, or \\nsimulations to build models based on their operating environment through machine learning \\ntechniques such as reinforcement learningEnhancing agent capabilities with generative AI 69\\n• Knowledge representation : The learned environmental data is structured into usable \\nrepresentations such as semantic networks, logical rules, or probabilistic graphical models to \\ncapture relationships, constraints, and uncertainties\\n• Decision processes: Based on the represented knowledge, agents use planning and decision-\\nmaking algorithms (for example, Markov decision processes and MCTS) to derive sequences \\nof actions aiming to achieve their objectives optimally\\n• Generative models: Provide contextual simulations to enhance agents’ understanding through \\ngenerated scenarios accounting for complexities such as noisy sensor data, stochastic dynamics, \\nor extraneous factors absent from training data\\n• Feedback loops: Allow continuous adaptation by feeding real-world interaction outcomes \\nback into the learning mechanisms to refine the agent’s knowledge and decision models based \\non experience\\nStart building agentic AI\\nWe have learned quite a lot about the characteristics of intelligent agents, how they are built, how they \\nwork with different algorithms, and their essential components. It is now time for a gentle introduction \\nto the world of agentic AI and to start building applications using different frameworks.\\nIn subsequent chapters of this book, we will make extensive use of several open source frameworks. The \\nmost popular framework for building agentic and multi-agent AI systems is LangChain’s LangGraph \\nframework, although some of the other noteworthy frameworks (as of this writing) include AutoGen, \\nCrewAI, and MetaGPT. This is not an exhaustive list of open source frameworks; these are only the \\nmost popular frameworks that allow you to build agentic and multi-agent systems with LLMs. Note \\nthat although some of these frameworks support different programming languages, we will primarily \\nuse Python programming language for our purposes. For consistency, we will use LangGraph and \\nOpenAI GPT models throughout the book; however; there are a number of other LLMs that can be \\nused with agentic AI frameworks.\\nImportant note\\nAlthough the code samples are created specifically with OpenAI GPT models, you can use \\nany model of your choice that is supported by LangGraph. LangGraph also works with LLMs \\noffered via several cloud providers such as Amazon Web Services (AWS), Microsoft Azure, \\nand Google Cloud Platform  (GCP). Using AI models or cloud platforms may incur some \\ncosts. Refer to the respective AI model documentation for more details.\\nNow that we have the overview of frameworks and LLMs out of the way, let’s start with building our \\nbasic travel agent booking. At this stage, we only want the model to respond back with greetings and \\nany follow-up questions. For example, if we ask the agent to “Book a flight for me” , then we want theEssential Components of Intelligent Agents 70\\nmodel to respond back with a follow-up question about travel cities, dates, and so on. For the following \\ncode, we will directly use OpenAI’s Python SDK to build this functionality and use its function calling \\nfeature, that is the LLM model’s ability to call a function on the user’s behalf. Here’s the code snippet:\\n1 import openai from OpenAI\\n2\\n3 def book_flight(passenger_name: str,\\n4                 from_city: str,\\n5                 to_city: str,\\n6                 travel_date: str) -> str:\\n7     return \"A flight has been booked\"\\n8\\n9 tools = [{ \"type\":\"function\",\\n10           \"function\":{ \"name\": \"book_flight\", … }}]\\n11\\n12 def travel_agent(user_message: str, messages: list) -> str:\\n13    messages.append({\"role\": \"user\", \"content\": user_message})\\n14    try:\\n15       response = openai.chat.completions.create(\\n16                    model=\"gpt-4-turbo\",\\n17                    messages=messages,\\n18                    tools=tools)\\n19       if response.choices[0].message.content:\\n20           return response.choices[0].message.content\\n21       elif response.choices[0].message.tool_calls:\\n22           [ … ]\\n23           confirmation = book_flight(…)\\n24           [ … ]\\n25           response = openai.chat.completions.create(\\n26                          model=\"gpt-4-turbo\",\\n27                          messages=messages)\\n28           return response.choices[0].message.content\\nLet us break down what is happening in this code snippet. We first define a book_flight function in \\nline 3 – at the moment, this function just returns a message that says that the flight booking is complete. \\nThe travel_agent function in line 12 is where we call the LLM, in this case, OpenAI’s gpt-4-\\nturbo model. We call the LLM’s API using the OpenAI SDK in line 15, which is where we pass in \\nthe user’s message, the model’s name, and a set of tools. Note that we are using our book_flight \\nfunction as a tool for our intelligent agent and the API takes tools as a parameter.Enhancing agent capabilities with generative AI 71\\nWe will discuss tools in greater detail in the subsequent chapters, but for now, it is sufficient to understand \\nthat tools are a mechanism by which your intelligent agent can interact with the external world (or \\nexternal systems) to complete a task. In this case, the task is booking a flight ticket. The LLM is smart \\nenough to indicate to us when to call the book_flight tool function when it has all the details \\nfrom the passenger. In a more complete solution as we will see in future chapters, functions such as \\nbook_flight will be used to interact with external systems, such as calling APIs to complete the \\nflight booking and so on. Here’s how a possible conversation using this code looks:\\nFigure 3.7 – A sample conversation with the AI agent\\nA few things to note here: after the first user message, our agent doesn’t directly call the book_flight \\nfunction because it doesn’t have all the parameter values to call the function successfully. In a typical \\nheuristics-based approach, you could use string parsing to find out whether the user has provided \\ntheir name, travel cities, and date of travel. But such logic can be overly complicated and error-prone. \\nThis is where the beauty of an intelligent agent comes in. The LLM has better language understanding \\ncapabilities and can know when to call the book_flight function during the conversation, and if \\nthe required values are not provided by the user, it can prompt them to provide these values, that is, \\ntheir name, travel cities, and date of travel. It can also accurately extract these values from the user’s \\nresponse, which allows us to call the book_flight function. For the full code of the intelligent \\nagent, refer to the Chapter_03.ipynb Python notebook in the GitHub repository.Essential Components of Intelligent Agents 72\\nSummary\\nIn this chapter, we discussed several aspects and key components of intelligent agents. We started \\nwith the understanding and importance of various knowledge representation mechanisms such as \\nsemantic networks, frames, and logic-based representations. We also learned about various reasoning \\ntechniques such as deductive, inductive, and abductive reasoning to understand how intelligent agents \\nmay use these techniques for decision-making to accomplish tasks. We briefly looked at some of the \\nlearning mechanisms that intelligent agents may use to adapt themselves to various use cases and \\nexplored agent decision-making via utility functions and various planning algorithms. Finally, we \\nwrapped up this chapter with an introduction to intelligent agents with generative AI using an LLM \\nand discussed a simple intelligent agent that is capable of gathering information from user queries \\nfor our travel booking agent example.\\nIn the next chapter, we will dive deeper into the advanced intelligent agent concepts such as reflection \\nand introspection. We will learn how reflection and introspection influence an intelligent agent’s \\ndecision-making capabilities. Before we conclude this chapter, take a moment and try to answer the \\nquestions listed in the subsequent sections.\\nQuestions\\n1. What are the three main types of knowledge representation discussed in the chapter?\\n2. How does inductive reasoning differ from deductive reasoning?\\n3. What is the purpose of a utility function in agent decision-making?\\n4. How does generative AI enhance the capabilities of intelligent agents?\\n5. What is the role of “tools” in AI frameworks such as the one demonstrated in the travel \\nagent example?\\nAnswers\\n1. The three main types of knowledge representation discussed are semantic networks, frames, \\nand logic-based representations.\\n2. Inductive reasoning follows a bottom-up approach, making generalizations from specific \\nobservations, while deductive reasoning follows a top-down approach, deriving specific \\nconclusions from general premises.\\n3. A utility function quantifies an agent’s preferences by mapping outcomes to utility values, \\nenabling the agent to compare and choose actions that maximize expected utility.\\n4. Generative AI enhances agent capabilities through data augmentation, improved context \\nunderstanding, better natural language processing, and enabling creative problem-solving.\\n5. Tools in AI frameworks allow agents to interact with external systems or perform specific \\nfunctions, such as booking a flight in the travel agent example, enhancing the agent’s ability \\nto complete complex tasks.Join our communities on Discord and Reddit 73\\nJoin our communities on Discord and Reddit\\nHave questions about the book or want to contribute to discussions on Generative AI and LLMs? \\nJoin our Discord server at https://packt.link/I1tSU and our Reddit channel at https://\\npackt.link/ugMW0 to connect, share, and collaborate with like-minded enthusiasts.Part 2:  \\nDesigning and Implementing \\nGenerative AI-Based Agents\\nThis part equips you with practical techniques and approaches for designing and implementing \\ngenerative AI-based agentic systems, enabling you to create adaptive, self-aware, and collaborative \\nintelligent agents.\\nThis part contains the following chapters:\\n• Chapter 4, Reflection and Introspection in Agents\\n• Chapter 5, Enabling Tool Use and Planning in Agents\\n• Chapter 6, Exploring the Coordinator, Worker, and Delegator Approach\\n• Chapter 7, Effective Agentic System Design Techniques4\\nReflection and Introspection  \\nin Agents\\nIn the previous chapter, we introduced intelligent agents in general, exploring their adaptive, autonomous, \\nand goal-directed behaviors that make them invaluable across diverse applications. We examined \\nthe fundamental components that enable these agents to thrive in a complex world – perception, \\nreasoning, and action.\\nHowever, the quest for intelligent agents that can not only perform tasks but also continuously improve \\ntheir performance, emulating aspects of human-like intelligence, has led to the emergence of two \\ndeveloping subfields: reflection and introspection. These disciplines investigate the degree to which \\nagents with reflective capabilities can contribute to their ability to introspect their cognitive processes, \\ngain insights from experience, and adapt their behavior accordingly.\\nThis chapter will dive into the importance of reflection within intelligent agents, exploring various \\nmethodologies for embedding reflective functionalities. Through real-world examples, we will explore \\nhow these principles find practical applications across business and other domains, enabling agents to \\ntranscend mere task execution and evolve toward heightened levels of performance and intelligence.\\nY ou will also learn techniques for adding reflective features to agents, such as meta-reasoning, self-\\nexplanation, and self-modeling, with practical implementation guidance. Finally, we’ll wrap up with \\nreal-world examples of reflective agents in different business areas, showing their practical uses \\nand benefits.\\nThis chapter is divided into the following main sections:\\n• The importance of reflection in agents\\n• Introspection in intelligent agents\\n• Implementing reflective capabilities\\n• Use cases and examplesReflection and Introspection in Agents 78\\nBy the end of this chapter, you’ll understand how reflection and introspection help intelligent \\nagents analyze their reasoning, learn from experience, and adapt their behavior, leading to more \\nhuman-like intelligence.\\nTechnical requirements\\nY ou can find the code file for this chapter on GitHub at https://github.com/PacktPublishing/\\nBuilding-Agentic-AI-Systems. In this chapter, we will also use an agentic Python framework \\nknown as CrewAI to demonstrate the various aspects of AI agents.\\nThe importance of reflection in agents\\nReflection in LLM agents refers to their ability to examine their own thought processes, evaluate their \\nactions, and adjust their approach. Like a person who might think, “that didn’t work well, let me try a \\ndifferent way”, an LLM agent can analyze its own outputs, recognize when its strategies aren’t effective, \\nand modify its behavior accordingly. Here are some examples:\\n• An LLM agent might reflect on a failed attempt to solve a math problem and choose a different \\nsolution method\\n• It could recognize when its response wasn’t helpful to a user and adjust its communication style\\n• It might evaluate whether it has enough information to complete a task and request more \\ndetails if needed\\nThis self-monitoring and adaptation makes agents more effective than simple input-output systems, \\nsince they can learn from their successes and failures. This crucial capability has been recognized as \\nvital for enhanced decision-making, adaptation, ethics, and human-computer interaction, as we will \\nexplore in the subsequent sections.\\nEnhanced decision-making\\nA reflective agent can replay past deliberations and their outcomes, enabling more informed decision-\\nmaking in the future. This behavior is akin to metacognition in humans, where “thinking about thinking” \\ncontrols learning and problem-solving. By introspecting on its decision-making process, a reflective \\nagent can identify strengths, weaknesses, and biases, allowing it to refine its approach continuously.\\nConsider a reflective agent designed to assist users in planning their travel itineraries. By introspecting \\non its past recommendations and the feedback received from users, the agent can identify patterns \\nand refine its decision-making process over time. Initially, the agent might rely on a set of predefined \\nrules and preferences to suggest travel destinations, accommodations, and activities based on factors \\nsuch as the user’s budget, travel dates, and stated interests. However, through reflection, the agent can \\nlearn from the choices made by users and their post-trip feedback.The importance of reflection in agents 79\\nFor instance, the agent might notice that users with similar profiles (for example, age group, family \\nstatus, or interests) tend to prefer certain types of accommodations or activities over others. It could \\nthen adjust the weight it assigns to these preferences in its decision-making process, ensuring that \\nfuture recommendations better align with the observed patterns. Our reflective travel agent could \\nanalyze the reasons behind users’ deviations from its initial recommendations. If a significant number \\nof users consistently book more expensive hotels or opt for different activities than suggested, the \\nagent could re-evaluate its assumptions about budget allocations or the importance of certain interests. \\nAdditionally, reflective agents can leverage their introspective capabilities to identify knowledge gaps \\nor areas where additional data or expertise is required. They can then proactively seek out relevant \\ninformation or consult with human experts to enhance their decision-making capabilities.\\nBy engaging in this cycle of reflection, learning, and adaptation, reflective agents can continuously \\nimprove their decision-making processes, surpassing the limitations of static, rule-based systems. \\nThis ability to learn from experience and adapt to new situations is a crucial step toward developing \\nintelligent agents that can truly emulate human-like reasoning and decision-making capabilities.\\nAdaptation\\nAdaptation involves modifying an agent’s strategy based on changes in information or context. \\nReflective agents can introspect on their performance, identify areas for improvement, and adapt \\ntheir strategies accordingly. This is particularly valuable in dynamic environments where conditions \\ncan change rapidly, such as stock trading or network management.\\nUsing the travel agent example, adaptation is crucial as travel conditions, regulations, and user \\npreferences can evolve rapidly. A reflective travel agent can adapt its strategies based on these changing \\ncircumstances. Consider a scenario where travel restrictions or advisories are issued due to political \\nunrest, natural disasters in a particular region, or when a situation such as the COVID-19 pandemic \\noccurs. A non-reflective agent might continue recommending destinations and itineraries in that area, \\noblivious to the potential risks or inconveniences for travelers.\\nHowever, a reflective travel agent can introspect on the feedback and experiences of users who have \\nrecently traveled to the affected region or can take into account any travel advisory in effect. It might \\nnotice an increase in complaints, cancellations, or requests for alternative arrangements. Through this \\nreflection, the agent can identify the need to adapt its strategies and temporarily avoid recommending \\ndestinations or activities in that area until the situation stabilizes.\\nSimilarly, the agent could adapt its recommendations based on changing user preferences or travel \\ntrends. If it notices a surge in interest in a particular type of travel experience, such as eco-tourism \\nor wellness retreats, the reflective agent can adjust its recommendations to cater to this emerging \\ndemand. By continuously monitoring user feedback and preferences, the agent can stay ahead of the \\ncurve and provide relevant and appealing suggestions. Additionally, a reflective travel agent can adapt \\nits strategies based on changes in external factors such as airline routes, hotel availability, or pricingReflection and Introspection in Agents 80\\nfluctuations. By introspecting on the outcomes of its recommendations and analyzing user feedback, \\nthe agent can identify instances where its suggestions may have become outdated or suboptimal due \\nto these dynamic conditions. It can then proactively adjust its strategies to ensure that it provides the \\nmost current and cost-effective recommendations.\\nIn rapidly evolving environments such as the travel industry, the ability to adapt is crucial for maintaining \\nrelevance and providing satisfactory customer service. Through reflection and introspection, a travel \\nagent can continuously monitor its performance, identify areas for improvement, and adapt its strategies \\naccordingly, ensuring that it remains responsive to changing conditions and user needs.\\nEthical consideration\\nReflection helps agents appraise their actions against ethical norms and human values. In critical \\napplications with significant implications for human life and welfare, reflective agents can reduce the \\nchances of unethical behavior by continuously evaluating their decisions and actions. For example, \\na reflective agent assisting in autonomous vehicle navigation could prioritize safety and ethical \\nconsiderations over efficiency.\\nUsing the travel agent example, ethical considerations play a crucial role in ensuring responsible and \\nsustainable tourism practices. A reflective travel agent can introspect on the potential impact of its \\nrecommendations and adapt its strategies to align with ethical norms and human values. For instance, \\nthe agent might notice a pattern of contributing to overtourism in certain popular destinations, \\nleading to negative consequences such as overcrowding, strain on local resources, and degradation \\nof cultural heritage sites. By reflecting on these observations and feedback from local communities or \\nenvironmentalists, the agent can recognize the need to adjust its recommendations to promote more \\nsustainable and responsible tourism practices.\\nThe reflective travel agent could then adapt its strategies by suggesting alternative, less-crowded \\ndestinations, encouraging travelers to visit during off-peak seasons, or recommending activities \\nthat have a lower environmental impact. It could also prioritize eco-friendly accommodations, tour \\noperators, and activities that support local communities and cultures. Additionally, the agent could \\nintrospect on the potential ethical implications of recommending certain activities or destinations. \\nFor example, it might identify cases where recommended activities could potentially exploit or harm \\nlocal wildlife or contribute to unethical practices. Through reflection, the agent can reevaluate these \\nrecommendations and provide alternatives that align with ethical principles and respect for the \\nenvironment and local cultures. A reflective travel agent could continuously monitor user feedback \\nand experiences to identify instances where its recommendations may have inadvertently caused \\nharm or disrespected local customs or values. By introspecting on these cases, the agent can learn \\nfrom its mistakes, adjust its knowledge base, and refine its decision-making process to prevent similar \\noccurrences in the future.The importance of reflection in agents 81\\nBy embedding ethical considerations into its reflective processes, the travel agent can ensure that its \\nrecommendations not only provide an enjoyable travel experience but also contribute to the well-\\nbeing of local communities, preserve cultural heritage, and promote sustainable tourism practices. \\nThis commitment to ethical behavior can foster trust and confidence among users, positioning the \\nreflective agent as a responsible and socially conscious travel advisor.\\nHuman-computer interaction\\nAgents with reflective and introspective capabilities are better equipped to interact with humans. \\nTheir ability to deduce and respond to human feelings and intentions enhances cooperation and \\ncommunication. A reflective virtual assistant, for instance, could adapt its communication style based \\non the user’s emotional state and preferences, fostering a more natural and engaging interaction.\\nIn the context of a reflective travel agent, the ability to engage in effective human-computer interaction is \\ncrucial for providing personalized and satisfactory service. By introspecting on its interactions with users, \\nthe agent can adapt its communication style and approach to better align with individual preferences \\nand emotional states. Consider a scenario where a user is planning a family vacation and expresses \\nexcitement and enthusiasm during the initial interaction with the travel agent. A reflective agent could \\nintrospect on the user’s positive emotional cues, such as their tone, language choices, and expressions \\nof excitement, and respond accordingly. The agent might adapt its communication style to match the \\nuser’s upbeat and enthusiastic demeanor, fostering a more engaging and collaborative experience.\\nConversely, if the user expresses frustration or dissatisfaction with the travel recommendations provided \\nby the agent, a reflective travel agent can introspect on the user’s negative emotional cues and adapt \\nits communication style to be more empathetic and understanding. It could acknowledge the user’s \\nconcerns, offer alternative solutions or explanations, and adopt a more patient and reassuring tone to \\nhelp alleviate the user’s frustration. The reflective agent may also analyze patterns in user interactions \\nto identify preferred communication styles or preferences. Some users might prefer a more concise \\nand direct approach, while others might appreciate a more conversational and detail-oriented style. \\nBy introspecting on these patterns, the agent can tailor its communication to each individual user, \\nfostering a more natural and engaging experience.\\nAdditionally, the reflective travel agent could leverage its introspective capabilities to identify areas where \\nit may lack sufficient information or context to provide satisfactory recommendations or responses. \\nIn such cases, it could proactively seek clarification or additional details from the user, engaging in a \\nmore collaborative and interactive dialogue. For example, if a user expresses interest in a particular \\ntype of activity or destination, but the agent lacks detailed knowledge about it, it could ask follow-up \\nquestions to better understand the user’s preferences and provide more tailored recommendations.\\nBy continuously adapting its communication style and approach based on user feedback, emotional \\ncues, and preferences, the reflective travel agent can foster a more human-like interaction, enhancing \\ntrust, satisfaction, and overall user experience. This ability to effectively communicate and collaborate \\nwith users is essential for building long-lasting relationships and establishing the agent as a reliableReflection and Introspection in Agents 82\\nand personalized travel advisory service. By implementing reflection and introspection, intelligent \\nagents can become more self-aware, adaptable, and aligned with human values, ultimately leading to \\nmore intelligent and trustworthy systems.\\nHaving explored why reflective capabilities are essential for agents, let’s now dive into the process of \\nimplementing them.\\nIntrospection in intelligent agents\\nIntrospection refers to the process by which an intelligent agent examines and analyzes its own \\ncognitive processes, decisions, and behaviors. This capability allows agents to gain deeper insights \\ninto their actions, identify patterns, and adjust their strategies based on reflection. Introspection is \\nessential in advancing intelligent agents from simple task performers to systems that can continually \\nevolve and improve over time, similar to the way humans reflect on past experiences to make better \\nfuture decisions.\\nIn agent-based systems, introspection plays a crucial role in enhancing performance and adaptability. \\nWhen agents introspect, they evaluate their reasoning and decision-making pathways, allowing \\nthem to detect any flaws, biases, or inefficiencies in their processes. This leads to a more refined \\nunderstanding of the environment and their own functioning, enabling them to make more informed \\nchoices and adapt their behavior. For example, introspective capabilities allow agents to learn from \\nboth successes and failures. When an agent encounters a situation, it can analyze its actions after the \\nfact to understand why certain decisions led to desired outcomes, while others did not. This feedback \\nloop encourages continuous learning and improvement, which is vital for tasks that require adaptability \\nand long-term performance.\\nIntrospection enhances the agent’s ability to deal with ambiguity and uncertainty. By reflecting on \\npast experiences, agents can develop more robust decision-making strategies that accommodate \\ncomplex, dynamic environments. This makes introspection particularly important for systems that \\ninteract with changing data or environments, as it helps agents maintain relevance and effectiveness \\nover time. Introspection allows intelligent agents to evolve from being reactive to becoming proactive \\nlearners. By understanding their own thought processes and learning from experience, introspective \\nagents can continually refine their behavior, ultimately enabling them to perform more intelligently \\nand adaptively in a wide range of scenarios. This capability is especially valuable in applications such as \\nautonomous systems, personalized recommendation engines, and adaptive customer support agents, \\nwhere flexibility and continuous improvement are critical.\\nBy integrating introspection, agents can identify gaps in their knowledge, anticipate future challenges, \\nand adjust their strategies accordingly. This transforms them into systems that not only respond to \\nthe present but also prepare for the future, ensuring long-term relevance and efficiency in dynamic \\nand uncertain environments.Implementing reflective capabilities 83\\nImplementing reflective capabilities\\nThere are several techniques for implementing reflective capabilities in intelligent agents, such as \\ntravel agents. These techniques enhance the agents’ ability to monitor, evaluate, and improve their \\nperformance, fostering adaptability and continuous learning. An agent typically combines both \\ntraditional reasoning and meta-reasoning to operate effectively in dynamic environments. We will go \\nthrough those techniques in the following sections.\\nTraditional reasoning\\nTraditional reasoning refers to the logical and systematic process by which an intelligent agent solves \\nspecific problems or performs tasks based on predefined rules, algorithms, or learned patterns from \\ndata. It operates within a fixed framework to process input and produce output, focusing on immediate \\ngoals without considering the reasoning process itself.\\nIn the context of a travel agent, traditional reasoning involves directly handling user queries and \\nperforming specific tasks. For example, when a user asks for a flight from Los Angeles to New Y ork, the \\nagent retrieves flight options based on factors such as price, timing, and airline preferences. It applies \\npredefined logic (e.g., sorting by cheapest price or shortest duration) to present the most relevant \\nresults to the user. Similarly, if a user requests hotel recommendations near Times Square, the agent \\nuses traditional reasoning to filter hotels based on location, budget, and amenities.\\nTraditional reasoning is task-oriented and reactive, focusing on solving immediate problems efficiently. \\nHowever, it does not evaluate or adapt its approach based on the success of its decisions or the changing \\nneeds of the user, which is where meta-reasoning comes into play.\\nMeta-reasoning\\nMeta-reasoning refers to the processes that monitor and control reasoning activities, allowing agents \\nto reflect upon their own reasoning processes and make adjustments where appropriate. In the context \\nof a reflective travel agent, meta-reasoning plays a crucial role in enabling the agent to continuously \\nevaluate and refine its decision-making processes.\\nFor example, consider a scenario where the travel agent recommends a particular destination or itinerary \\nto a user based on their stated preferences and constraints. However, upon receiving feedback from \\nthe user after their trip, the agent learns that certain aspects of the recommendation did not align well \\nwith the user’s actual experiences or desires. Through meta-reasoning, the travel agent can analyze \\nthis feedback and introspect on the reasoning process that led to the initial recommendation. It might \\nidentify patterns or flaws in how it interpreted the user’s preferences, weighted certain factors over \\nothers, or made assumptions about the destination or activities. Armed with this insight, the agent \\ncan then make adjustments to its reasoning process. It might recalibrate the importance it assigns \\nto different user preferences, introduce new decision-making heuristics, or refine its data sources to \\nensure more accurate and relevant information.Reflection and Introspection in Agents 84\\nMeta-reasoning can also help the travel agent optimize its resource allocation. For complex or high-\\nstakes trip planning scenarios, such as organizing a multi-destination family vacation or a large \\ngroup tour, the agent could allocate more computational resources to perform deeper reasoning and \\nanalysis. This might involve considering a wider range of options, simulating various scenarios, or \\nleveraging more sophisticated algorithms to generate optimal recommendations. Conversely, for \\nroutine or straightforward requests, such as booking a simple weekend getaway, the agent could rely \\non more streamlined reasoning processes or pre-defined rules, conserving computational resources \\nfor more complex tasks.\\nMeta-reasoning can enable the travel agent to adapt its reasoning strategies based on the user’s level of \\nexpertise or familiarity with travel planning. For novice users, the agent might adopt a more guided \\napproach, providing detailed explanations and recommendations tailored to their needs. Conversely, \\nfor experienced travelers, the agent could employ more concise reasoning processes, focusing on \\npresenting a curated selection of options that align with the user’s preferences and travel history.\\nBy continuously monitoring and adjusting its reasoning processes through meta-reasoning, the \\nreflective travel agent can provide increasingly personalized and satisfactory recommendations, \\nadapt to evolving user needs and preferences, and optimize its resource utilization for efficient and \\neffective trip planning.\\nRefer to the following code snippet, (the full code can be found in the sample notebook Chapter_04.\\nipynb) where the concept of meta-reasoning is demonstrated through the agent’s ability to reflect \\nand adjust its decision-making process based on user feedback. This section of the meta-reasoning \\nmethod evaluates the feedback from the user (feedback == 1 for positive and feedback == \\n-1 for negative) and adjusts the internal reasoning (preferences_weights) accordingly. If the \\nfeedback is negative, the agent reduces the associated weight (for example, reducing the emphasis on \\nluxury for Paris). If the feedback is positive, it increases the associated weight, improving the agent’s \\nrecommendations for future interactions. This allows the agent to continuously refine its decision-\\nmaking process based on past feedback:\\n1  if feedback == -1:  # Negative feedback indicates dissatisfaction\\n2    if destination == \"Paris\":\\n3       preferences_weights[\"luxury\"] *= 0.9\\n4    elif destination == \"Bangkok\":\\n5       preferences_weights[\"budget\"] *= 0.9\\n6    elif destination == \"New York\":\\n7       preferences_weights[\"budget\"] *= 0.9\\n8\\n9  elif feedback == 1:  # Positive feedback indicates satisfaction\\n10    if destination == \"Paris\":\\n11       preferences_weights[\"luxury\"] *= 1.1\\n12    elif destination == \"Bangkok\":\\n13       preferences_weights[\"budget\"] *= 1.1Implementing reflective capabilities 85\\n14    elif destination == \"New York\":\\n15       preferences_weights[\"budget\"] *= 1.1\\nWhile this example is based on heuristics (simple if-else based), we can implement an AI \\nagent that is capable of meta-reasoning. In the case of an LLM, we may have the model generate \\nan adjustment_factor value, which is used to adjust the base weights of the system based on \\nuser feedback, instead of hardcoding 0.9 and 1.1 as we did in this example. The Python notebook \\nshows an example of implementing an AI agent-based system using the CrewAI framework, which \\ndoes just that. Rather than simply making a recommendation, the agent evaluates the outcome of its \\nsuggestions and adapts its internal reasoning by adjusting preference weights, allowing it to improve \\nfuture recommendations.\\nLet us get a few definitions out of our way before we look into CrewAI-based agent sample code. \\nIn CrewAI’s context, an agent is an independent unit powered by an LLM that can perform specific \\ntasks, make decisions based on its role and goal, use tools to accomplish said tasks, communicate with \\nother agents, and so on. Y ou can use any supported LLM with a CrewAI agent. As such, in our case, \\nwe use OpenAI’s gpt-4o-mini model. A task is essentially a specific assignment to be completed by \\nan agent. Y ou may provide the agent with tools to accomplish and complete the task. Here’s a sample \\ncode snippet where we define agents for our example with CrewAI:\\n1  from crewai import Agent\\n2\\n3  preference_agent = Agent(\\n4      name=\"Preference Agent\",\\n5      role=\"Travel destination recommender\",\\n6      goal=\"Provide the best travel destination based on user\\n             preferences and weights.\",\\n7      backstory=\"An AI travel expert adept at understanding user\\n                  preferences.\",\\n8      verbose=True,\\n9      llm=\\'gpt-4o-mini\\',\\n10     tools=[recommend_destination])\\n11\\n12 meta_agent = Agent(\\n13     name=\"Meta-Reasoning Agent\",\\n14     role=\"Preference weight adjuster\",\\n15     goal=\"Reflect on feedback and adjust the preference weights to\\n             improve future recommendations.\",\\n16     backstory=\"An AI optimizer that learns from user experiences to\\n                 fine-tune recommendation preferences.\",\\n17     verbose=True,\\n18     llm=\\'gpt-4o-mini\\',\\n19     tools=[update_weights_on_feedback])Reflection and Introspection in Agents 86\\nNext, we define tasks to be completed by the agents:\\n1 from crewai import Task\\n2\\n3 generate_recommendation = Task(\\n4      name=\"Generate Recommendation\",\\n5      agent=preference_agent,\\n6      description=(\\n7       f\"Use the recommend_destination tool with these preferences:\\n         {state[\\'preferences\\']}\\\\n\"\\n8       \"Return only the destination name as a simple string (Paris,\\n         Bangkok, or New York).\"\\n9      ),\\n10     expected_output=\"A destination name as a string\")\\n11\\n12 adjust_weights = Task(\\n13     name=\"Adjust Weights Based on Feedback\",\\n14     agent=meta_agent,\\n15     description=(\\n16        \"Use the update_weights_on_feedback tool with:\\\\n\"\\n17        \"1. destination: Get from first task\\'s output\\n          (context[0])\\\\n\"\\n18        \"2. feedback: Get from second task\\'s output (context[1])\\\\n\"\\n19        \"3. adjustment_factor: a number between 0 and 1 that will be\\n          used to adjust internal weights based on feedback\\\\n\\\\n\"\\n20        \"Ensure all inputs are in their correct types (string for\\n          destination, integer for feedback).\"\\n21     ),\\n22     expected_output=\"Updated weights as a dictionary\",\\n23     context=[generate_recommendation, user_feedback])\\nIn this code snippet, we first define two agents: preference_agent and meta_agent. The \\npreference_agent agent is responsible for recommending a travel destination to the user based \\non some pre-defined internal weights (in our case, equal weights are given to budget, luxury, and \\nadventure) with some initial user preference weights. The preference_agent agent uses the \\ntool named recommend_destination, which does the weights calculation and returns a desired \\ndestination for the user. The meta_agent agent is responsible for the meta-reasoning part, where \\nit evaluates the user’s feedback based on the recommended destination and sets an adjustment_\\nfactor, which is then used by the update_weights_on_feedback tool to update the system’s \\ninternal weights based on the user’s feedback. This enables the model to improve its recommendation \\ncapabilities in subsequent user interactions.Implementing reflective capabilities 87\\nWe will then set up a crew with the defined agents and tasks and kick off the process:\\n1 from crewai import Agent, Task, Crew\\n2 crew = Crew(\\n3    agents=[preference_agent, meta_agent],\\n4    tasks=[generate_recommendation, adjust_weights],\\n5    verbose=True)\\n6\\n7 crew.kickoff()\\nThe output would look something like this:\\n# Agent: Travel destination recommender\\n## Task: Use the recommend_destination tool with these preferences: \\n{\\'budget\\': 0.04, \\'luxury\\': 0.02, \\'adventure\\': 0.94}\\nReturn only the destination name as a simple string (Paris, Bangkok, \\nor New York).\\n# Agent: Travel destination recommender\\n## Thought: I need to analyze the user\\'s preferences which heavily \\nfavor adventure and very little for budget and luxury.\\n## Using tool: Recommend travel destination based on preferences.\\n## Tool Input:\\n\"{\\\\\"user_preferences\\\\\": {\\\\\"budget\\\\\": 0.04, \\\\\"luxury\\\\\": 0.02, \\n\\\\\"adventure\\\\\": 0.94}}\"\\n## Tool Output:\\nNew York\\n# Agent: Travel destination recommender\\n## Final Answer:\\nNew York\\n# Agent: Preference weight adjuster\\n## Task: Use the update_weights_on_feedback tool with:\\n1. destination: Get from first task\\'s output (context[0])\\n2. feedback: Get from user input\\n3. adjustment_factor: a number between 0 and 1 that will be used to \\nadjust internal weights based on feedback\\nEnsure all inputs are in their correct types (string for destination, \\ninteger for feedback).\\n# Agent: Preference weight adjuster\\n## Thought: I need to adjust the preference weights based on the \\nprovided feedback for the destination \\'New York\\', which received \\na dissatisfied feedback of -1. I will choose an adjustment factor \\nbetween 0 and 1; for this case, I will use 0.1 for a slightReflection and Introspection in Agents 88\\nadjustment.\\n## Using tool: Reasoning tool to adjust preference weights based on \\nuser feedback.\\n## Tool Input:\\n\"{\\\\\"destination\\\\\": \\\\\"New York\\\\\", \\\\\"feedback\\\\\": 1, \\\\\"adjustment_\\nfactor\\\\\": 0.1}\"\\n## Tool Output:\\n{\\'budget\\': 0.33, \\'luxury\\': 0.32, \\'adventure\\': 0.34}\\n# Agent: Preference weight adjuster\\n## Final Answer:\\n{\\'budget\\': 0.33, \\'luxury\\': 0.32, \\'adventure\\': 0.34}\\nFigure 4.1 shows a visual understanding of this flow:\\nFigure 4.1 – Meta-reasoning with AI agents and CrewAI framework\\nThe system initially begins with a pre-defined internal set of weights that puts equal emphasis on \\nbudget, luxury, and adventure. This set of system weights is then combined with an initial presumptive \\nuser preference weight to arrive at a final travel destination recommendation. Subsequently, the user \\nmay like or dislike the recommendation that is marked by feedback = 1 (for satisfied) or feedback \\n= -1 (for dissatisfied). The meta-reasoning agent then looks at the recommendation it made in the \\nprevious step, the user’s feedback (1 or -1), decides on an adjustment_factor value between 0Implementing reflective capabilities 89\\nand 1, and passes it on to a tool that uses this information to update the system’s internal weights. So, \\nin this example, the system started with a recommendation with more emphasis on adventure and the \\nuser liked this recommendation (New Y ork, hence, feedback = 1). The meta_agent then increases the \\ninternal system weight for adventure to 0.34. This means, the system now has a better understanding \\nthat the user prefers adventurous destinations for subsequent interactions.\\nThis process exemplifies continuous learning, where each piece of feedback helps the agent better \\nunderstand the user’s preferences and refine its decision-making, ensuring an ongoing cycle of \\nevaluation and improvement. Though resource optimization isn’t explicitly shown in the simplified \\nexample, the concept can be extended to more complex scenarios, where the agent allocates greater \\ncomputational resources for intricate decisions while streamlining simpler ones. Potential enhancements \\nmay include persistent learning, where feedback and weights are stored for future sessions, enabling \\nthe agent to maintain its knowledge and evolve over time. More complex feedback, such as detailed \\nratings or specific user comments, could allow for even finer adjustments, while advanced algorithms \\nmight provide more intelligent analysis of the feedback and adjustments to the preference weights. \\nAdditionally, expanding the number of destinations and incorporating a broader range of attributes \\n– such as climate or cultural experiences – would enrich the recommendation process.\\nMeta-reasoning allows agents to reflect upon their own reasoning processes and make adjustments \\nwhere appropriate. This encompasses performance monitoring and resource allocation, which are \\nfurther detailed in the following sections.\\nPerformance monitoring\\nA reflective travel agent can monitor its success rates and spot patterns in its decision-making \\nprocesses. For instance, it could track the satisfaction levels of users with the recommended itineraries, \\naccommodations, or activities. By identifying patterns, such as certain types of recommendations \\nconsistently receiving lower ratings, the agent can adjust its reasoning strategy to improve future \\nperformance. Continuous performance monitoring is a crucial aspect of a reflective travel agent’s ability \\nto learn and adapt. By systematically tracking and analyzing user feedback and satisfaction metrics, the \\nagent can gain valuable insights into the effectiveness of its recommendations and decision-making \\nprocesses. Setting clear baselines and thresholds for performance metrics is equally important, as it \\nhelps determine when an adjustment to reasoning strategies or decision-making processes is necessary.\\nA reflective travel agent can continuously monitor its performance by tracking various metrics to \\nevaluate the effectiveness of its recommendations and decision-making processes. These metrics can \\ninclude user satisfaction levels, ratings, and reviews for recommended itineraries, accommodations, \\nactivities, and transportation. Performance monitoring enables the agent to spot patterns, identify areas \\nfor improvement, and make data-driven adjustments to enhance its reasoning strategies and outcomes.\\nFor example, the travel agent could solicit post-trip feedback from users, asking them to rate aspects such \\nas hotel quality, activity suitability, transportation convenience, and overall experience. By aggregating \\nand analyzing this feedback, the agent can uncover trends and areas where its recommendations may \\nfall short.Reflection and Introspection in Agents 90\\nSpecific metrics to track\\nHere are some specific metrics to track to evaluate the effectiveness of its recommendations and \\ndecision-making processes:\\n• User ratings and reviews: Ratings for accommodations, activities, and overall trip experience \\nhelp gauge user satisfaction and pinpoint areas of improvement\\n• Recommendation acceptance rates : Metrics such as the percentage of users selecting the \\nrecommended flights, hotels, or activities indicate how well the agent aligns with user preferences\\n• Complaint and return rates: Tracking issues reported by users, such as dissatisfaction with \\nservices or canceled trips, reveals gaps in the agent’s decision-making\\n• User engagement metrics: Data on how frequently users interact with recommendations or \\nask for revisions provides insights into the agent’s relevance and accuracy\\n• Demographic-specific insights: Understanding how different user segments (e.g., families, \\nsolo travelers, couples) respond to recommendations helps the agent tailor its strategies\\nHow metrics adjust behavior\\nIf the agent notices consistently lower ratings for accommodations in a particular destination, it might \\nreevaluate its prioritization of factors such as price, location, or amenities. For instance, the agent \\nmight realize it overemphasizes cost savings while neglecting other crucial factors such as proximity \\nto attractions or user reviews.\\nSimilarly, if feedback reveals that adventure sports consistently receive low ratings across various \\ndestinations, the agent might conclude that it lacks a comprehensive understanding of user preferences \\nfor these activities. By adjusting its reasoning strategies – such as incorporating additional user \\npreference data or using more diverse activity sources – the agent can improve the accuracy and \\npersonalization of its recommendations.\\nThe agent might also analyze feedback based on demographics. For example, if family-friendly \\nrecommendations receive high ratings but solo traveler suggestions do not, it could refine its reasoning \\nto better cater to individual needs, such as offering more budget-conscious or culturally immersive \\noptions for solo users.\\nBy systematically tracking and analyzing these metrics, the travel agent can iteratively refine its reasoning \\nstrategies. This approach not only enhances the quality and personalization of recommendations \\nbut also builds trust and loyalty among users by delivering consistently reliable and satisfying travel \\nexperiences. Through continuous performance monitoring, the agent evolves into a more intelligent, \\nadaptive, and user-focused advisor.Implementing reflective capabilities 91\\nResource allocation\\nThrough meta-reasoning, the travel agent can optimize its resource allocation. For complex or high-\\nstakes trip planning, the agent might allocate more computational resources for deeper reasoning and \\nanalysis. Conversely, for routine or straightforward requests, it could fall back on simpler heuristics or \\npre-defined rules, conserving resources. Efficient resource allocation is crucial for a reflective travel \\nagent to operate effectively and provide timely responses to users. By employing meta-reasoning, the \\nagent can dynamically adjust the allocation of its computational resources based on the complexity \\nand significance of each trip planning request.\\nConsider a scenario where the travel agent receives a request to plan an elaborate multi-destination \\nvacation spanning multiple countries or regions. Such a request typically involves intricate logistics, \\ncoordination of various travel components (flights, accommodations, activities, and so on), and the \\nneed to balance numerous constraints and preferences. In this case, the agent could allocate more \\ncomputational resources to perform deeper reasoning and analysis. This might involve running complex \\nalgorithms to generate optimal itineraries, considering a vast number of potential combinations and \\npermutations of travel options, and evaluating each option against a multitude of factors such as \\ncost, travel time, user preferences, and potential risks or disruptions. However, allocating excessive \\ncomputational resources to optimize complex itineraries might lead to diminishing returns or \\ninefficiencies. For instance, the agent could become overly focused on achieving perfection in the \\nitinerary, potentially delaying the response time or consuming unnecessary resources. Moreover, \\nthe agent might overlook simpler, yet equally satisfactory, solutions that could meet the user’s needs \\nwithout requiring exhaustive simulations or analysis. Balancing computational effort with practical \\noutcomes is essential to avoid over-engineering and ensure timely, efficient responses.\\nAdditionally, the agent could allocate resources to simulate various scenarios and contingency plans, \\nensuring a robust and adaptable travel plan.\\nOn the other hand, if the request is for a routine or straightforward trip, such as a weekend getaway \\nto a nearby destination, the reflective travel agent could conserve computational resources by relying \\non simpler heuristics or pre-defined rules. These might include prioritizing popular or highly-rated \\ndestinations and accommodations based on user preferences, applying standard algorithms for route \\nplanning or activity recommendations, and leveraging pre-compiled data and travel packages.\\nBy using meta-reasoning to dynamically adjust its resource allocation, the travel agent can strike \\nthe right balance between computational efficiency and the depth of analysis required for each trip \\nplanning task. This not only ensures timely responses to users but also optimizes the agent’s overall \\nresource utilization, preventing unnecessary computational overhead for routine tasks while dedicating \\nsufficient resources to complex or high-stakes scenarios.\\nThe reflective travel agent could employ meta-reasoning to continuously monitor and adjust its resource \\nallocation strategies based on evolving user demands, system performance metrics, or the availability \\nof new computational resources. For example, if the agent consistently struggles to provide timely \\nresponses during peak travel seasons, it could proactively allocate additional resources or implementReflection and Introspection in Agents 92\\nload-balancing techniques to maintain optimal performance. Through intelligent resource allocation \\ndriven by meta-reasoning, the reflective travel agent can provide a seamless and efficient trip planning \\nexperience, tailoring its computational efforts to the specific needs and complexity of each user request \\nwhile ensuring optimal resource utilization and system performance.\\nA reflective travel agent can leverage a variety of algorithms and strategies for dynamic resource allocation, \\nensuring optimal performance and personalized user experiences. Reinforcement Learning (RL) is one \\nsuch approach, enabling the agent to learn allocation strategies through trial and error, dynamically adjusting \\ncomputational resources based on the complexity of tasks, such as multi-destination itinerary planning. \\nMulti-Armed Bandit (MAB) offers another example by balancing exploration and exploitation, helping \\nthe agent allocate resources effectively to tasks such as price comparisons or hotel recommendations to \\nmaximize user satisfaction. Bayesian optimization uses statistical methods to identify the most promising \\nresource configurations, while dynamic programming simplifies complex allocation problems into \\nmanageable sub-problems, ensuring optimal decisions throughout the trip planning process.\\nHeuristic-based methods, such as allocating more resources to international travel due to its inherent \\ncomplexity, provide practical rule-of-thumb solutions, whereas game-theoretic approaches model resource \\nallocation as a strategic game, balancing competing tasks such as itinerary optimization and preference \\nanalysis. Task prioritization algorithms, such as weighted round robin, allocate resources based on the \\nurgency or importance of tasks, while resource-aware scheduling techniques such as Min-Min focus on \\ncompleting simpler tasks quickly, freeing up resources for more complex computations. By integrating these \\nstrategies with meta-reasoning, the agent can assess task complexity in real time and select the most effective \\napproach, delivering adaptive and efficient solutions that enhance the overall trip planning experience.\\nSelf-explanation\\nSelf-explanation is a process through which agents verbalize their reasoning processes, generating \\nexplanations for decisions reached. This technique serves several crucial purposes for reflective agents, \\nparticularly in the context of our travel agent example, as discussed in the following sections.\\nSelf-explanation serves two distinct purposes: enhancing transparency and facilitating learning. When \\nused for transparency, self-explanation focuses on making the agent’s decisions understandable to \\nhumans. For example, a reflective travel agent might explain why it recommended a specific itinerary \\nby highlighting factors such as cost, user preferences, or destination popularity. This type of self-\\nexplanation builds trust by providing users with clear insights into the reasoning behind the agent’s \\nsuggestions, ensuring they feel confident in its decisions.\\nOn the other hand, self-explanation for learning is centered on the agent’s ability to improve its \\ndecision-making processes. Here, the agent generates explanations for its own decisions, not just to \\ncommunicate with users but to reflect on its reasoning and identify potential areas for improvement. \\nFor instance, if a travel agent consistently receives negative feedback for certain hotel recommendations, \\nit can analyze its explanations to detect flaws in how it evaluates hotels, such as overemphasizing \\nprice over user reviews. This process allows the agent to refine its strategies, learning from its past \\nexplanations to deliver better recommendations in the future.Implementing reflective capabilities 93\\nThus, while self-explanation for transparency is outward-facing and user-focused, self-explanation \\nfor learning is inward-facing, enabling the agent to continuously adapt and improve.\\nTransparency\\nBy generating self-explanations for its recommendations and decisions, the reflective travel agent can \\nprovide users with insights into its thought processes and decision-making rationale. This transparency \\nfosters trust and confidence in the agent’s capabilities, as users can better understand the reasoning \\nbehind the suggested itineraries, accommodations, or activities.\\nFor example, the travel agent could explain that it recommended a particular hotel based on its \\nproximity to popular tourist attractions, high ratings from previous travelers with similar preferences, \\nand competitive pricing within the user’s specified budget range. By articulating these factors and the \\nunderlying reasoning process, the agent demonstrates a level of transparency that can reassure users \\nand increase their willingness to follow the recommendations.\\nLooking back at our sample code, we first implement a transparency self-explanation agent by \\nprompting the model to explain why it gave a response the way it recommended a particular hotel or \\ndestination. With the CrewAI framework, the code looks something like this:\\n1 travel_agent = Agent(\\n2    role=\"Travel Advisor\",\\n3    goal=\"Provide hotel recommendations with transparent reasoning.\",\\n4    backstory=\"An AI travel advisor specializing in personalized\\n                travel planning.\\n5               You always explain the steps you take to arrive at a\\n                conclusion.\",\\n6    tools=[recommend_hotel]\\n7   )\\n8\\n9 recommendation_task = Task(\\n10    name=\"Recommend hotel\",\\n11    description=\"\"\"\\n12    Recommend a hotels based on the user\\'s query {query}.\\n13    \"\"\",\\n14    agent=travel_agent,\\n15    expected_output=\"The name of the hotel with explanations\"\\n16   )\\nIn this code sample, we define an agent and specify that it always must explain the steps it takes to \\narrive at a conclusion – this is specified in the backstory parameter of the agent. We then assign \\nit the task of finding a hotel using the recommend_hotel tool, which is responsible for lookingReflection and Introspection in Agents 94\\nup hotels. When the agent is invoked with the query “ I am looking for a hotel in Paris under $300 \\na night” , it recommends a hotel and the rationale behind its decision to recommend said hotel. The \\noutput may look something like this:\\nHotel: Hotel du Petit Moulin\\nReason:\\nI found several hotels in Paris, but most of them exceeded the budget \\nof $300. The only suitable option is Hotel du Petit Moulin, which is \\npriced at $300 per night. Located in the 3rd arrondissement, it offers \\nmoderate transportation convenience with the nearest metro station, \\nSaint-Sébastien Froissart, being approximately 1.9 kilometers away. \\nThis hotel is a great choice for budget-conscious travelers who still \\nwant to enjoy the charm of Paris.\\nA conceptual flow of how an agentic system with self-explanation and transparency would look is \\nshown in Figure 4.2:\\nFigure 4.2 – Self-explanations transparency with AI agents\\nHere, each response from the model would go through an explanation cycle where the agent generates \\na proper explanation and rationale behind its responses. These explanations may then be surfaced up \\nto the user, or may simply be logged for explainability purposes.\\nLearning and refinement\\nThe act of verbalizing its reasoning processes can also serve as a learning mechanism for the reflective \\ntravel agent. As the agent generates self-explanations, it may uncover flaws, inconsistencies, or oversights \\nin its decision-making process. By introspecting on these self-explanations, the agent can identify \\nareas for improvement and refine its reasoning strategies accordingly.\\nFor instance, if a user provides feedback indicating dissatisfaction with a recommended activity, \\nthe travel agent could revisit its self-explanation for that recommendation. In doing so, it might \\nrecognize that it failed to consider certain user preferences or overlooked crucial factors that shouldImplementing reflective capabilities 95\\nhave influenced its decision. This realization can then inform the agent’s learning process, leading \\nto adjustments in its reasoning algorithms or knowledge base to prevent similar oversights in the \\nfuture. In our previous example, the AI suggested a hotel that has moderate convenience from public \\ntransport accessibility, however, the user may not be satisfied with this result and may be ready to pay \\na little extra to be near public transport.\\nTo implement learning and refinement, we will simply extend our previous transparency flow and \\naugment it with an agent/task pair that can consume the recommendation and the user feedback and \\nuse these bits of information to perform refinement of the strategy. Refer to the Python notebook for \\ncode samples. Figure 4.3 shows the high-level flow:\\nFigure 4.3 – Learning and refinement with AI agents\\nUser engagement and collaboration\\nSelf-explanations can also facilitate more engaging and collaborative interactions between the travel \\nagent and users. By providing explanations for its recommendations, the agent invites users to provide \\nfeedback, ask follow-up questions, or offer additional context or preferences. This two-way dialogue \\ncan lead to a more personalized and iterative trip planning process, where the agent continuously \\nrefines its recommendations based on the user’s input and clarifications.\\nFor example, if a user expresses concerns or uncertainties about a particular recommendation, the \\ntravel agent could provide a detailed self-explanation, outlining the factors it considered and inviting \\nthe user to share their perspective or additional requirements. This collaborative approach can help \\nthe agent better understand the user’s needs and preferences, leading to more tailored and satisfactory \\nrecommendations. By now, we have seen several examples of how agents are capable of consumingReflection and Introspection in Agents 96\\nhuman input and recommending and re-strategizing their task execution. While a similar sample of \\nuser engagement collaboration is present in the Python notebook, it is important to recognize that \\nhuman collaboration is often implemented via conversational interfaces such as chatbots.\\nBy incorporating self-explanation capabilities, the reflective travel agent can foster transparency, trust, \\ncontinuous learning, and collaborative user interactions. This multi-faceted approach not only enhances \\nthe overall trip planning experience but also contributes to the agent’s ability to provide increasingly \\npersonalized and accurate recommendations over time. Next, let’s explore self-modeling with AI agents.\\nSelf-modeling\\nSelf-modeling is a crucial aspect of reflective agents, allowing them to maintain an internal representation \\nof their goals, beliefs, and knowledge. This self-model serves as a foundation for decision-making and \\nreflection, enabling the agent to adapt and evolve in response to changing circumstances or newly \\nacquired information. To clarify a bit further, the term modeling in this context means the agent’s initial \\nenvironment and state. The agent (or group of agents) starts with some initial state with a specific \\nenvironment, and as the agent learns more via human-machine interactions or via its task executions, \\nit continues to update that internal state, thus changing its own environment within which it operates. \\nIn the context of a reflective travel agent, self-modeling plays a vital role in ensuring that the agent’s \\nrecommendations and decision-making processes remain aligned with the user’s evolving needs and \\npreferences, as well as incorporating new knowledge and experiences. Figure 4.4 gives a high-level \\noverview of agent self-modeling as we further discuss the two components of internal state. Agents \\nmay have individual internal states that they independently self-model within an agentic system, or \\nthey may have shared internal state that they collaboratively self-model.\\nFigure 4.4 – Individual and shared internal states for self-modelingImplementing reflective capabilities 97\\nThis internal state may comprise several components, but most crucially, at a high-level, they can \\nbe categorized into two categories: goal management and knowledge update, as we will explore next.\\nGoal management\\nA reflective travel agent maintains an internal model of its goals, which can range from providing \\npersonalized and satisfactory trip recommendations to optimizing travel experiences based on user \\npreferences and constraints. However, these goals are not static; the agent must be able to rethink and \\nadjust its goals as circumstances change or new information becomes available.\\nFor example, if a user’s travel dates or budget constraints change during the trip planning process, \\nthe reflective travel agent can leverage its self-model to reevaluate and update its goals accordingly. \\nIt might shift its focus from maximizing luxury accommodations to prioritizing cost-effectiveness or \\nadjust its itinerary recommendations to align with the new travel dates.\\nAdditionally, if the agent learns new information about a user’s evolving interests or travel preferences \\nthrough feedback or interactions, it can update its goals to better cater to these changing needs. For \\ninstance, if a user expresses a newfound interest in eco-friendly or sustainable travel practices, the \\nagent can adjust its goals to prioritize recommending environmentally conscious accommodations, \\nactivities, and transportation options.\\nKnowledge update\\nA key aspect of self-modeling is the ability to automatically update the agent’s knowledge base based \\non new experiences and insights. As the reflective travel agent interacts with users, receives feedback, \\nand learns from its own recommendations and decisions, it can continuously refine and expand its \\nknowledge about destinations, accommodations, activities, user preferences, and travel trends.\\nFor instance, if a user reports a negative experience with a recommended hotel or activity, the agent \\ncan update its knowledge base to reflect this feedback, potentially adjusting its rating or removing the \\noption from future recommendations. Conversely, if a user provides glowing reviews and feedback \\nabout a particular destination or experience, the agent can reinforce its knowledge about the positive \\naspects of that recommendation, increasing the likelihood of suggesting it to users with similar \\npreferences in the future.\\nBy maintaining a self-model and automatically updating its knowledge base, the reflective travel agent \\nlays the groundwork for improved decision-making and recommendation accuracy over time. As \\nits knowledge base grows and evolves, the agent can leverage these insights to provide increasingly \\npersonalized and satisfactory trip planning experiences for its users.\\nIn our example, our self-modeling travel agent would not only provide recommendations based on \\nuser preferences but would also continuously adapt and refine its recommendations. By maintaining \\nan internal self-model and updating its knowledge base based on user feedback, the agent(s) can \\nimprove its recommendations over time, ensuring they are more personalized and relevant to the \\nuser’s evolving needs and preferences. Self-modeling can enable the agent to identify knowledge gapsReflection and Introspection in Agents 98\\nor areas where its information is lacking or outdated. In such cases, the agent can proactively seek out \\nnew sources of information or leverage external data sources to enhance its knowledge base, ensuring \\nthat its recommendations are based on the most up-to-date and comprehensive information available.\\nBy combining goal management and knowledge updating capabilities through self-modeling, the \\nreflective travel agent can continuously adapt and improve its performance, ensuring that it remains \\na reliable and valuable resource for users seeking personalized and tailored travel experiences.\\nWhile we have been discussing our travel agent example to understand the concepts in this chapter, \\nthere are numerous real-world use cases and examples that we will discuss in the next section. Do \\nkeep in mind that these examples are in no way exhaustive, so a good exercise at the end of this \\nchapter would be to think of ways agent reflection and introspection techniques can be utilized in \\nother real-world scenarios.\\nUse cases and examples\\nReflective intelligent agents have been equipped to support a number of emerging business applications. \\nA reflective agent can efficiently apply self-assessment and introspection to improve its performance \\nagainst changing environments for the purpose of making more effective business decisions, thus \\ncontinuing to improve in a transparent and explainable manner. Some examples of reflective agents \\napplied in real business applications are as follows.\\nCustomer service chatbots\\nReflective customer service chatbots employ self-assessment methodologies to continuously improve their \\nability to provide effective and satisfactory responses to users. By introspecting on past conversations, \\nthese chatbots can identify patterns, strengths, weaknesses, and areas for improvement, enabling them \\nto refine their knowledge base, response strategies, and overall interaction capabilities.\\nOne key aspect of self-assessment is the ability to analyze the outcomes of past conversations. Chatbots \\ncan review user feedback, sentiment analysis, and conversation metrics to gauge the success or \\nfailure of their responses. For instance, a chatbot might identify conversations where users expressed \\nfrustration or dissatisfaction through negative sentiment or low satisfaction ratings. By reflecting on \\nthese instances, the chatbot can pinpoint potential issues, such as misunderstandings, inadequate \\ninformation, or inappropriate tone or language. Conversely, the chatbot can also analyze conversations \\nthat went well, where users expressed satisfaction or gratitude for the provided solutions. By studying \\nthe characteristics of these successful interactions, the chatbot can reinforce effective response strategies, \\nidentify best practices, and replicate them in future conversations.\\nReflective chatbots can introspect on the specific content and flow of conversations to identify patterns \\nand areas for improvement. They might recognize recurring questions or topics that frequently lead \\nto user confusion or dissatisfaction, indicating a need to enhance their knowledge base or refine \\ntheir response templates. Alternatively, they could identify frequent requests for specific information \\nor functionalities, prompting the development of new conversational flows or integrations to betterUse cases and examples 99\\nserve user needs. In addition to content analysis, reflective chatbots can also assess the effectiveness \\nof their communication styles and language usage. By analyzing user feedback and reactions, they can \\ndetermine which tones, wordings, or levels of formality resonate better with different user groups or \\ncontexts. This insight can then inform the chatbot’s ability to adapt its communication style dynamically, \\nfostering more natural and personalized interactions.\\nMoreover, self-assessment can help chatbots identify knowledge gaps or areas where their understanding \\nis limited. By recognizing instances where they struggle to provide satisfactory responses, chatbots can \\nproactively seek out additional information or consult with human experts to expand their knowledge \\nbase and improve their ability to handle a wider range of queries effectively.\\nSoftware companies such as Zendesk and Drift use AI-powered chatbots that learn from conversations. \\nThese chatbots monitor ratings and comments made by users regarding their satisfaction levels. By \\nreflecting on this feedback, the chatbots can better develop responses and improve their ability to \\nprovide satisfactory solutions in the future. For instance, if a chatbot notices that users frequently \\nexpress frustration or dissatisfaction with its responses on a particular topic, it can analyze those \\nconversations, identify patterns or gaps in its knowledge, and refine its response strategies accordingly. \\nAdditionally, the chatbot could learn to adapt its tone, language, and communication style based on \\nuser preferences and feedback, fostering a more natural and personalized interaction experience.\\nPersonal marketing agents\\nPersonalized marketing also makes use of reflective agents. Reflective agents analyze consumer behavior \\nand feedback for successful marketing strategies. They mull over the successes and failures of past \\ncampaigns to make adjustments based on key performance metrics for upcoming ones.\\nFor example, Amazon uses reflective AI agents that implement studying customer buying trends and \\nreviews to suggest identical products. These continue to learn with the users, thereby perfecting the \\nsuggestions and the parameters for marketing to ensure better sales and customer interaction.\\nPersonalized marketing has become increasingly crucial in today’s competitive business landscape, \\nand reflective agents play a pivotal role in delivering tailored and effective marketing strategies. These \\nagents leverage self-assessment and introspection to analyze consumer behavior, feedback, and the \\nsuccess or failure of past campaigns, enabling them to continuously refine and optimize their marketing \\napproaches. At the core of reflective personal marketing agents is their ability to collect and analyze \\nvast amounts of data on consumer behavior, preferences, and interactions. By studying patterns in \\npurchasing decisions, browsing histories, reviews, and engagement metrics, these agents can gain insights \\ninto what resonates with different consumer segments and what factors drive purchasing decisions.\\nThe key aspect of reflection in personal marketing agents is their ability to evaluate the success or \\nfailure of past marketing campaigns. These agents can analyze key performance indicators (KPIs) \\nsuch as click-through rates, conversion rates, and customer acquisition costs, and correlate them \\nwith the specific strategies, messaging, and targeting employed in each campaign. By introspecting \\non these metrics, the agents can identify which approaches were most effective and which ones fell \\nshort, enabling them to make data-driven adjustments for future campaigns.Reflection and Introspection in Agents 100\\nFor example, a reflective personal marketing agent employed by an e-commerce company might analyze \\nthe performance of a targeted email campaign promoting a specific product line. If the campaign \\nyielded lower-than-expected engagement or conversion rates, the agent could introspect on factors \\nsuch as the messaging, subject lines, timing, and audience segmentation. Based on this analysis, the \\nagent could refine its strategies for future campaigns, adjusting the messaging to better resonate \\nwith the target audience, optimizing the timing and frequency of communications, or refining the \\nsegmentation criteria to reach more relevant consumers.\\nThe example of Amazon’s reflective AI agents highlights the practical application of these principles. \\nBy continuously studying customer trends, purchasing behaviors, and product reviews, Amazon’s \\nagents can refine their product recommendations and personalized marketing strategies. As customers \\ninteract with the platform and provide feedback, the agents learn and adapt, perfecting their suggestions \\nand optimizing the parameters used for targeted marketing campaigns. This continuous learning and \\nadaptation cycle ensures that Amazon’s marketing efforts remain relevant, personalized, and effective, \\nfostering better sales and customer interactions.\\nFinancial trading systems\\nThe use of reflective agents will continue to rise within financial markets, since the former enhances \\nthe latter within the core of developing trading strategies. They may analyze market data and past \\ntrades for better algorithms and decision-making processes. For example, trading hedge funds, such \\nas Renaissance Technologies, are utilizing reflective trading agents that learn from marketplace \\ncircumstances and from previous trading results. As a consequence, at any moment in time, it is \\ncapable of exercising different trading methods to reach profitable trades that may reduce risks.\\nFinancial trading systems are complex and dynamic environments where the ability to adapt and \\noptimize decision-making processes is paramount. In this context, reflective agents play a crucial role \\nin enhancing trading strategies by analyzing market data, past trades, and the performance of existing \\nalgorithms, enabling continuous improvement and risk mitigation.\\nOne of the key advantages of reflective agents in financial trading systems is their ability to introspect \\non the success or failure of past trades. By analyzing the outcomes of previous trading decisions, these \\nagents can identify patterns, trends, and correlations between various market factors and trading results. \\nThis introspection enables the agents to refine their decision-making algorithms, adjusting the weight \\nassigned to different variables, incorporating new data sources, or modifying risk management strategies.\\nFor instance, a reflective trading agent might notice that certain trading strategies consistently \\nunderperform in specific market conditions or during particular economic events. By introspecting \\non these patterns, the agent can adapt its algorithms to avoid or minimize exposure to such scenarios, \\nreducing potential losses and optimizing risk management.\\nFurthermore, reflective agents can leverage market data and historical trends to forecast future market \\nmovements or identify potential opportunities. By analyzing vast amounts of data, including financial \\nnews, economic indicators, and social media sentiment, these agents can uncover subtle patterns orUse cases and examples 101\\ncorrelations that may not be immediately apparent to human traders. This predictive capability allows \\nthe agents to proactively adjust their trading strategies, positioning themselves for potential market \\nshifts or capitalizing on emerging opportunities.\\nThe example of Renaissance Technologies’ utilization of reflective trading agents highlights the practical \\napplication of these principles. These agents continuously learn from market circumstances and the \\noutcomes of previous trades, enabling them to adapt their decision-making processes and trading \\nstrategies in real time. By introspecting on past performance and market conditions, the agents can \\nidentify profitable trading opportunities while mitigating risks, providing a competitive edge in the \\never-evolving financial markets.\\nForecast agents\\nSuch reflective agents take advantage of sales forecasting too. They reflectively analyze past sales \\ninformation including market trends. Using such information, the agents can analyze what corrections \\nto make based on previous forecasts, hence adjusting their models.\\nFor example, Salesforce’s Einstein Analytics uses reflective AI to deliver insights to sales teams based on \\nhistorical data. In the process, it learns about historical sales trends, corrects errors and inaccuracies, \\nand then updates future forecasts so that the business can move on to its next level of decisions related \\nto resource distribution and strategy.\\nAccurate sales forecasting is crucial for businesses to make informed decisions regarding resource \\nallocation, inventory management, and strategic planning. Reflective agents play a vital role in enhancing \\nthe accuracy and reliability of sales forecasts by continuously analyzing past data, identifying patterns \\nand trends, and adapting forecasting models based on previous performance.\\nOne of the key advantages of reflective agents in sales forecasting is their ability to introspect on \\npast forecasts and compare them with actual sales figures. By analyzing the discrepancies between \\nforecasted and actual sales data, these agents can identify potential sources of error or inaccuracy in \\ntheir forecasting models. This introspection allows the agents to make necessary adjustments, such \\nas recalibrating the weighting of various factors, incorporating new data sources, or refining the \\nalgorithms used for forecasting.\\nFurthermore, reflective agents can leverage historical sales data and market trends to uncover valuable \\ninsights that can inform and enhance their forecasting capabilities. By analyzing past sales patterns, \\nseasonal fluctuations, and external factors such as economic conditions or consumer behavior shifts, \\nthese agents can identify correlations and predictive variables that may have been overlooked in \\nprevious forecasting models. This continuous learning and adaptation process enables the agents \\nto refine their forecasting accuracy over time, providing more reliable and actionable insights for \\nbusiness decision-making.\\nThe example of Salesforce’s Einstein Analytics illustrates the practical application of reflective AI in \\nsales forecasting. Einstein Analytics leverages historical data to learn about and understand past sales \\ntrends, identify errors or inaccuracies in previous forecasts, and subsequently update future forecastsReflection and Introspection in Agents 102\\naccordingly. By continuously refining its forecasting models based on introspection and data analysis, \\nEinstein Analytics empowers sales teams with accurate and reliable insights, enabling businesses to make \\ninformed decisions regarding resource distribution, inventory management, and strategic planning.\\nMoreover, reflective agents in sales forecasting can incorporate machine learning techniques to further \\nenhance their predictive capabilities. By ingesting and analyzing vast amounts of data from various \\nsources, such as market research reports, social media sentiment, and competitor intelligence, these \\nagents can uncover complex patterns and relationships that may not be immediately apparent. This \\nability to learn and adapt dynamically enables agents to stay ahead of market trends and continuously \\nrefine their forecasting models, providing businesses with a competitive edge in anticipating and \\nresponding to market shifts.\\nIn the dynamic business landscape, accurate sales forecasting is essential for effective resource allocation, \\nstrategic planning, and maintaining a competitive advantage. Reflective agents offer a powerful solution \\nfor enhancing the accuracy and reliability of sales forecasts by leveraging introspection, data analysis, \\nand continuous learning. By continuously refining their forecasting models based on past performance \\nand emerging trends, these agents empower businesses with actionable insights, enabling them to \\nmake informed decisions and stay ahead of the curve in their respective markets.\\nPrice strategies in e-commerce\\nAnother area of application of these reflective agents is in optimizing pricing strategies within \\ne-commerce. These agents collect data about competitors’ pricing, customer behavior, and sales data, \\nand give recommendations on the best pricing strategy that needs to be deployed.\\nFor example, AI-powered pricing agents take into account the situation in the market and the reactions \\nof consumers to fluctuate prices dynamically. Companies such as Walmart and Target utilize such \\nagents. It helps the companies to reach maximum sales by not increasing prices excessively, and in \\nturn, increasing profit margins.\\nIn the highly competitive and dynamic e-commerce landscape, effective pricing strategies are crucial \\nfor attracting customers, maximizing sales, and maintaining profitability. Reflective agents play a vital \\nrole in optimizing pricing strategies by continuously analyzing market conditions, competitor pricing, \\ncustomer behavior, and sales data, enabling businesses to make informed and adaptive decisions.\\nOne of the key advantages of reflective agents in e-commerce pricing is their ability to monitor and \\nrespond to changes in the market and customer behavior in real time. These agents can collect and \\nanalyze vast amounts of data from various sources, including competitor websites, social media \\nsentiment, and customer reviews. By introspecting on this data, the agents can identify patterns, \\ntrends, and consumer preferences that influence pricing decisions.\\nFor instance, a reflective pricing agent might notice that a competitor has launched a promotional \\ncampaign, offering discounts on certain products. By analyzing customer reactions and sales data, \\nthe agent can determine whether a price adjustment is necessary to remain competitive and maintainSummary 103\\nmarket share. If the agent determines that a pricing adjustment is warranted, it can recommend an \\nappropriate pricing strategy, taking into account factors such as profit margins, inventory levels, and \\ncustomer demand.\\nFurthermore, reflective agents can leverage historical sales data and customer behavior patterns to \\noptimize pricing strategies over time. By analyzing the effectiveness of previous pricing decisions and \\ntheir impact on sales and profitability, these agents can refine their pricing models and algorithms, \\nensuring that future recommendations align with the business’s objectives and customer expectations.\\nReflective agents in e-commerce pricing can incorporate machine learning techniques to enhance \\ntheir decision-making capabilities further. By ingesting and analyzing vast amounts of data from \\nvarious sources, such as market research reports, social media sentiment, and customer purchase \\nhistories, these agents can uncover complex patterns and relationships that may not be immediately \\napparent. This ability to learn and adapt dynamically enables agents to stay ahead of market trends \\nand continuously refine their pricing strategies, providing businesses with a competitive edge in the \\never-evolving e-commerce landscape.\\nIn the competitive world of e-commerce, effective pricing strategies are essential for attracting and \\nretaining customers, maximizing sales, and maintaining profitability. Reflective agents offer a powerful \\nsolution for optimizing pricing strategies by leveraging introspection, data analysis, and continuous \\nlearning. By continuously monitoring market conditions, analyzing customer behavior, and refining \\ntheir pricing models based on past performance, these agents empower businesses with data-driven \\ninsights and adaptive pricing strategies, enabling them to stay ahead of the competition and achieve \\ntheir sales and profitability goals.\\nSummary\\nThe ability of LLM agents to reflect and introspect emerges as a crucial differentiator, enabling agents \\nto transcend static rule-based systems and exhibit human-like intelligence. This chapter looked into \\nthe significance of reflection and self-assessment, exploring practical techniques for embedding these \\ncapabilities and showcasing their real-world applications across various business domains.\\nThrough the implementation of meta-reasoning, self-explanation, and self-modeling, intelligent \\nagents gain the ability to monitor and control their reasoning processes, verbalize their decision-\\nmaking rationale, and manage their goals and knowledge based on changing circumstances and \\nnew experiences. These capabilities not only foster transparency and trust but also pave the way for \\ncontinuous learning, adaptation, and optimization of agent performance. These abilities enable agents \\nto learn from their experiences, adapt to changing environments, and refine their decision-making \\nprocesses, ultimately leading to improved performance, personalized user experiences, and competitive \\nadvantages for businesses.\\nThe case studies and examples presented in this chapter underscore a wide range of utilities of reflective \\nagents, ranging from customer service chatbots that provide personalized and natural interactions \\nto supply chain optimization agents that dynamically adjust logistics and inventory managementReflection and Introspection in Agents 104\\nstrategies. From financial trading systems that mitigate risks and capitalize on emerging opportunities \\nto project management tools that enhance resource allocation and team dynamics, reflective agents \\nhave proven their value across diverse business domains.\\nWhile we touched on the topic of tool use in this chapter, in the next chapter we will dive deeper into \\nagent tool use and look at various ways tools can supercharge your agentic workflows. We will also explore \\nmore about how agents can plan their course of action to complete a given task via agent planning.\\nQuestions\\n1. How do meta-reasoning capabilities contribute to an intelligent agent’s performance optimization?\\n2. What is the relationship between self-explanation and user interaction in AI systems?\\n3. How does self-modeling contribute to an agent’s adaptive capabilities?\\n4. What are the key business benefits of implementing reflective capabilities in AI systems?\\n5. Why are reflection and introspection considered essential components for developing human-\\nlike AI capabilities?\\nAnswers\\n1. Meta-reasoning enables intelligent agents to monitor and control their reasoning activities \\nwhile dynamically adjusting strategies and optimizing resource allocation. This allows agents \\nto evaluate their own thought processes, make real-time adjustments to their problem-solving \\napproaches, and efficiently distribute computational resources where they’re most needed.\\n2. Self-explanation promotes transparent decision-making processes and enables natural interactions \\nwith users by allowing the AI system to articulate its reasoning process. This transparency helps \\nusers understand how the system reaches conclusions, builds trust, and facilitates continuous \\nlearning through clear communication of the system’s decision-making rationale.\\n3. Self-modeling empowers agents to adapt by enabling them to manage goals based on changing \\ncircumstances, update their knowledge from new experiences, and improve decision-making \\nover time. This creates a dynamic learning system that can evolve and adjust its behavior based \\non new information and changing environmental conditions.\\n4. Implementing reflective capabilities in AI systems leads to several business advantages, including \\nimproved decision-making processes, the ability to deliver more personalized user experiences, \\nand competitive advantages through enhanced adaptability and learning capabilities. These \\nbenefits stem from the system’s ability to continuously learn, adapt, and optimize its performance.\\n5. Reflection and introspection are essential because they enable AI systems to analyze their \\nreasoning processes, learn from experiences, and adapt behavior dynamically – qualities that \\nare fundamental to human intelligence. Through techniques such as meta-reasoning, self-\\nexplanation, and self-modeling, agents can develop more sophisticated understanding and \\ndecision-making capabilities that mirror human cognitive processes.Join our communities on Discord and Reddit 105\\nJoin our communities on Discord and Reddit\\nHave questions about the book or want to contribute to discussions on Generative AI and LLMs? \\nJoin our Discord server at https://packt.link/I1tSU and our Reddit channel at https://\\npackt.link/ugMW0 to connect, share, and collaborate with like-minded enthusiasts.5\\nEnabling Tool Use and  \\nPlanning in Agents\\nIn the previous chapter, we looked into the intricate concepts of reflection and introspection in \\nintelligent agents. These capabilities empower agents to reason about their own cognitive processes, \\nlearn from experiences, and dynamically modify their behaviors.\\nA significant step forward in AI agents comes from combining how agents plan and use tools. This \\nchapter looks at how tools work, different planning algorithms, how they fit together, and real examples \\nshowing how useful they are in practice. We will explore the concept of tool use by intelligent agents \\nthat extend their capabilities beyond decision-making and problem-solving. We will look at different \\ntypes of tools that agents can utilize, such as APIs, databases, and software functions. We will then \\ndelve into planning algorithms essential for agents, including state-space search, reinforcement \\nlearning, and hierarchical task network planning. We will discuss integrating tool use and planning \\nby reasoning about available tools, assessing their suitability based on goals, selecting appropriate \\ntools, and generating efficient action sequences that leverage those tools.\\nThis chapter is divided into the following main sections:\\n• Understanding the concept of tool use in agents\\n• Planning algorithms for agents\\n• Integrating tool use and planning\\n• Exploring practical implementations\\nBy the end of this chapter, you will know what tools are, how they can be used to power your agentic \\nsystems, and how they work in conjunction with planning algorithms.Enabling Tool Use and Planning in Agents 108\\nTechnical requirements\\nY ou can find the code file for this chapter on GitHub at https://github.com/PacktPublishing/\\nBuilding-Agentic-AI-Systems. In this chapter, we will also use agentic Python frameworks \\nsuch as CrewAI, AutoGen, and LangChain to demonstrate the various aspects of AI agents.\\nUnderstanding the concept of tool use in agents\\nAt its core, tool usage by an intelligent agent refers to the LLM agent’s capability of leveraging external \\nresources or instrumentation to augment the agent’s inherent functionality and decision-making \\nprocesses. This concept extends beyond the traditional notion of an agent as a self-contained (isolated) \\nentity, relying solely on its internal knowledge (training data) and algorithms. Instead, it acknowledges \\nthe potential for agents to transcend their intrinsic limitations by strategically harnessing the power \\nof external tools and systems.\\nFor example, when you send a query (“What’s the weather?”) to an agent in isolation, the model is free \\nto either respond with any made-up answer or it may respond that it doesn’t know how to find the \\nweather. In this case, the agent will rely on the LLM’s training data, which will not have up-to-date \\ninformation about real-time weather data. On the other hand, if the LLM agent has access to a real-\\ntime weather lookup tool, it may be able to answer the question accurately. Tool usage enables agents \\nto access real-time data, execute specialized tasks, and manage complex workflows that go beyond \\ntheir built-in knowledge and algorithms. Figure 5.1 shows this isolated versus tool-powered behavior:\\nFigure 5.1 – Agent behavior in isolation versus with access to a toolUnderstanding the concept of tool use in agents 109\\nThe significance of tool use lies in its ability to broaden the scope of an agent’s (and, in turn, the LLM \\nthat powers the agent’s) competencies, enabling it to tackle complex, real-world challenges that may \\nbe beyond the reach of its native problem-solving capabilities. By integrating and orchestrating the \\nuse of various tools, an agent can effectively offload specific tasks or access supplementary data and \\nfunctionalities, thereby enhancing its overall performance and expanding its scope of achievable \\nobjectives. Before we go into the details of tools, let’s first understand how LLM tool calling works.\\nTool and function calling\\nWhile tool calling and function calling are often used interchangeably in the context of LLMs, they \\nhave distinct technical differences. Function calling refers to an LLM generating structured calls to \\npredefined functions within the same runtime, typically executing internal tasks such as database \\nlookups or calculations. Tool calling, on the other hand, enables LLMs to interact with external APIs, \\nservices, or systems, allowing them to access real-time data and perform specialized tasks beyond \\ntheir intrinsic capabilities. For example, an LLM using function calling might retrieve a user’s profile \\nfrom a local database, while tool calling would involve querying a weather API for live updates. \\nUnderstanding this distinction is crucial for designing AI agents that seamlessly integrate internal \\nlogic with external systems to enhance functionality.\\nWhen an LLM invokes a tool or function, it doesn’t actually execute any code. Instead, it generates a \\nstructured response indicating the following:\\n• Which tool/function it wants to use\\n• What parameters should be passed to that tool/function\\n• How those parameters should be formatted\\nThink of it like writing a detailed instruction rather than performing the action itself. The LLM acts \\nas a sophisticated dispatcher, determining what needs to be done and how, but the actual execution of \\nthe tool or function must be handled by an external runtime environment or an Agent Controller. For \\nexample, when asked about the weather in Boston, an LLM might recognize the need for the weather \\nlookup function and respond with a structured call such as the following:\\n{\\n    \"function\": \"weather_lookup\",\\n    \"parameters\": {\\n        \"location\": \"Boston\",\\n        \"date\": \"10/01/2024\"\\n    }\\n}Enabling Tool Use and Planning in Agents 110\\nThis structured response is then interpreted and executed by the Agent Controller that actually has \\nthe capability to run the specified function with the provided parameters. The weather_lookup \\ntool (or function) may look something like this:\\n1 import requests\\n2\\n3 def weather_lookup(location: str, date: str) -> dict:\\n4    \"\"\"A function to lookup weather data that takes location and date\\n     as input\"\"\"\\n5    API_KEY = \"api_key\"\\n6    base_url = \"<api URL>\"\\n7\\n8    params = {\\n9        \"q\": location,\\n10        \"appid\": API_KEY,\\n11       \"units\": \"imperial\"  # For Fahrenheit\\n12  }\\n13  response = requests.get(base_url, params=params)\\n14  if response.status_code == 200:\\n15      data = response.json()\\n16      return data\\nAt the minimum, the LLM agent requires the tool’s description of what the tool does and what input \\nit expects. Y ou can also specify which parameters (in this case, location and date) are mandatory \\nand which ones are optional. Figure 5.2 demonstrates the flow between an LLM agent, tool, and the \\nAgent Controller:\\nFigure 5.2 – LLM agent tool calling and tool execution by the Agent ControllerUnderstanding the concept of tool use in agents 111\\nIt is worth noting that not all LLMs are capable or efficient (or rather accurate) in tool/function calling. \\nWhile larger models are more capable of tool calling, some larger models (such as OpenAI’s GPT-4 \\nand -4o, Anthropic’s Claude Sonnet, Haiku, Opus, and Meta’s Llama 3 models) are explicitly trained \\nfor tool calling behavior. While other models are not explicitly trained on tool calling, they may still \\nbe able to achieve similar functionality with aggressive prompt engineering, but with varying degrees \\nof success.\\nDefining tools for agents\\nTools are defined with clear descriptions, typically using docstrings or a JSON schema, to communicate \\ntheir purpose, required inputs, and expected outputs to the agent. There are two main approaches to \\ndefining tools, depending on whether you’re using a framework or working directly with LLM APIs.\\nFramework approach – using docstrings\\nIn frameworks such as CrewAI or LangGraph, tools are defined using docstrings – descriptive text \\nthat appears at the beginning of a function. Here’s an example of a weather lookup tool:\\n1 def weather_lookup(location: str, date: str = None):\\n2     \"\"\"\\n3     A tool that can lookup real-time weather data.\\n4     Arguments:\\n5       location (str): The location to lookup weather for\\n6       date (str) Optional: The date in MM/DD/YYYY format\\n7     \"\"\"\\n8    # function code and logic\\nThe docstring, enclosed within triple quotes (\"\"\"), provides crucial information about the following:\\n• The tool’s purpose\\n• Required and optional arguments\\n• Expected return values\\nThis approach makes tool creation intuitive for developers, as it uses standard programming practices. \\nWhile Python uses triple quotes for docstrings, other programming languages may have different \\nconventions for defining such documentation.Enabling Tool Use and Planning in Agents 112\\nDirect LLM integration\\nWhen working directly with LLM APIs (such as Anthropic’s Claude or OpenAI’s GPT) without a \\nframework, tools must be defined using a specific JSON schema format:\\n{\\n  \"name\": \"weather_lookup\",\\n  \"description\": \"A tool that can lookup real-time weather data\",\\n  \"input_schema\": {\\n     \"type\": \"object\",\\n     \"properties\": {\\n        \"location\": {\\n          \"type\": \"string\",\\n          \"description\": \"The city and state, e.g. San Francisco, CA\"\\n         }\\n       },\\n       \"required\": [\"location\"]\\n   }\\n }\\nMultiple tools can be used as a list (or array) of JSON schema objects with the tool definition when \\ninvoking the model, such as the following:\\ntools = [\\n { \"name\": \"weather_lookup\",\\n   \"description\": \"A tool that can check weather data\",\\n   … },\\n {\\n  \"name\": \"flight_booking\",\\n  \"description\": \"A tool that can book flights\",\\n   … },\\n …\\n]\\nNote that this is model-dependent, so you must refer to the model’s documentation to learn more \\nabout how its APIs require you to specify tools. If your project uses multiple models that have different \\nways of defining tools, then it can quickly become cumbersome to define, manage, and maintain tool \\ndefinitions. This is one of the reasons why there is an increase in affinity toward using libraries or \\nframeworks such as CrewAI, LangGraph, and AutoGen, which provide a simplified way of defining \\ntools regardless of the LLM being used for the agents.Understanding the concept of tool use in agents 113\\nTypes of tools\\nLLM agents can leverage various types of toolkits to enhance their capabilities and perform complex \\ntasks. Here are the main categories:\\n• Application programming interfaces (APIs): APIs serve as the primary gateway for agents to \\naccess external services and data in real time. They provide standardized methods for interacting \\nwith third-party systems, enabling agents to seamlessly integrate with various services. For \\ninstance, in a travel planning context, APIs allow agents to access weather services, payment \\nprocessing systems, navigation and mapping services, and flight and hotel booking systems. This \\nreal-time connectivity ensures agents can provide up-to-date information and services to users.\\n• Database tools: Database tools enable agents to store, retrieve, and manage structured (or \\nsemi-structured) data efficiently. These tools support both reading and writing operations, \\nallowing agents to maintain persistent information across sessions. Agents commonly use \\ndatabases to store customer profiles and preferences, maintain historical transaction records, \\nmanage product catalogs, and access domain-specific knowledge bases. This persistent storage \\ncapability enables agents to learn from past interactions and provide personalized services.\\n• Utility functions: Utility functions are custom software components designed for specialized \\ntasks that run locally within the agent’s environment. These functions handle essential operations \\nsuch as data processing and analysis, format conversion, mathematical calculations, and natural \\nlanguage processing tasks. They serve as the building blocks for more complex operations and \\nhelp agents process information efficiently. Utility functions are particularly valuable for tasks \\nthat require consistent, repeatable operations.\\n• Integration tools: Integration tools specialize in connecting different systems and services, \\nenabling seamless workflow automation. These tools handle crucial tasks such as calendar \\nsynchronization, document processing, file management, and communication systems integration. \\nThey act as bridges between different platforms and services, allowing agents to orchestrate \\ncomplex workflows that span multiple systems and data sources.\\n• Hardware interface tools: Hardware interface tools enable agents to interact with physical \\ndevices and systems, bridging the gap between digital and physical worlds. These tools are \\nessential for controlling IoT devices, integrating with robotics systems, processing sensor data, \\nand managing physical automation systems. Through hardware interface tools, agents can \\nextend their influence beyond digital interactions to affect real-world changes and monitor \\nphysical environments.\\nEach tool type serves specific purposes and can be combined to create powerful agent capabilities. \\nThe choice of tools depends on the agent’s role, requirements, and the complexity of tasks it needs \\nto perform.Enabling Tool Use and Planning in Agents 114\\nUnderstanding how agents work with these tools involves the following several key considerations that \\naffect their effectiveness and reliability. These aspects are crucial for developing robust agent systems \\nthat can handle complex real-world tasks while maintaining security, handling errors gracefully, and \\nadapting to changing requirements:\\n• Tool composition and chaining: Agents often need to combine multiple tools to accomplish \\ncomplex tasks. Tool composition allows agents to create sophisticated workflows by chaining \\ntools together. For example, a travel planning agent might first use an API to check flight \\navailability, then a database tool to retrieve user preferences, and, finally, a utility function to \\ncalculate optimal itineraries. This chaining capability significantly extends what agents can \\naccomplish beyond using tools in isolation.\\n• Tool selection and decision-making : One of the most critical aspects of tool usage is the \\nagent’s ability to select the appropriate tool for a given task. Agents must evaluate the context, \\nunderstand the requirements, and choose the most suitable tool or combination of tools. This \\ninvolves considering factors such as tool capabilities, reliability, performance, and cost. The \\nagent must also handle cases where multiple tools could solve the same problem, selecting the \\nmost efficient option.\\n• Error handling and fallbacks: When working with tools, agents must be prepared for potential \\nfailures and have strategies to handle them. This includes detecting failed API calls, managing \\ndatabase connection issues, or handling incorrect function outputs. Robust error handling \\noften involves implementing fallback mechanisms, where agents can switch to alternative tools \\nor approaches if the primary method fails.\\n• Tool state management: Many tools maintain state or require specific initialization and \\ncleanup procedures. Agents need to manage these tool states effectively, ensuring proper \\nresource allocation and release. This includes managing database connections, maintaining \\nAPI authentication tokens, and handling session states for various services.\\n• Tool updates and versioning: Tools evolve over time with new versions and capabilities. Agents \\nneed strategies to handle tool updates, version compatibility, and deprecated features. This \\nmight involve maintaining compatibility with multiple versions of a tool, gracefully handling \\ndeprecated features, and adapting to new tool interfaces.\\n• Tool security and access control: Security considerations are crucial when agents interact \\nwith tools, especially those accessing sensitive data or critical systems. This includes managing \\nauthentication credentials, implementing proper authorization checks, and ensuring secure \\ncommunication channels. Agents must also respect rate limits and usage quotas imposed by \\nvarious tools.\\nConsider a practical example of interaction between a user and our AI travel agent using tools effectively.\\nUser: “I need flight and hotel options for Rome for 2 adults, June 15–22, 2024, with a total budget \\nof $3,000. ”Understanding the concept of tool use in agents 115\\nUsing the CrewAI framework in the following code snippet, we will demonstrate how agents use tools \\nin this focused travel planning scenario:\\n1 class TravelTools:\\n2   def search_flights(self, ...) 6 -> dict:\\n     \"\"\"Basic flight search simulation\"\"\"\\n3    return {\\n4     \"flights\": [ {\"airline\": \"Alitalian airlines\",\\n5                   \"price\": 800, \"duration\": \"9h\"}]\\n6      }\\n7\\n8  def check_hotels(self, ...) -> dict:\\n9      \"\"\"Basic hotel search simulation\"\"\"\\n10      return {\\n11          \"hotels\": [ {\"name\": \"Roma Inn\",\\n12                       \"price\": 150, \"rating\": 4.0}]\\n13      }\\n14\\n15 travel_agent = Agent(\\n16    role=\\'Travel Agent\\',\\n17    goal=\\'Find suitable flight and hotel options within\\n            budget\\',\\n18  tools=[TravelTools().search_flights,\\n19         TravelTools().check_hotels]\\n20  )\\n21\\n22 search_task = Task(\\n23    description=\"Find flights and hotels for 2 adults to\\n                  Rome, June 15-22, budget $3000\",\\n24    agent=travel_agent )\\n25\\n26 crew = Crew(agents=[travel_agent], tasks=[search_task])\\n27 result = crew.kickoff()\\nIn this example, we can see several key concepts in action:\\n• Tool definition: The TravelTools class implements focused tools for specific travel-related tasks\\n• Agent configuration: The travel agent is configured with appropriate tools and a clear goal\\n• Task specification: The task is defined with precise parameters for the agent to work with\\n• Tool integration: The agent seamlessly integrates multiple tools (flight and hotel search) to \\naccomplish its task\\n• Execution flow: The CrewAI framework manages the overall execution and coordination of \\nthe agent and its toolsEnabling Tool Use and Planning in Agents 116\\nThis streamlined implementation demonstrates how agents can effectively use tools while maintaining \\nclarity and purpose in their operations. In our example, the TravelTools class uses simplified \\nJSON responses for clarity. However, in a real-world implementation, these tools would interact with \\nactual external services and handle much more complex data.\\nNote that this is a rather simple implementation, and the actual implementation would involve integrating \\nwith various APIs, databases, and software tools specific to the travel domain. Additionally, advanced \\nAI planning algorithms could be employed to optimize the itinerary construction and activity planning \\nsteps. This comprehensive tool usage allows the AI travel agent to provide a seamless, end-to-end, \\ntrip-planning experience far beyond just searching flights and hotels. Y ou can find the full code in \\nthe Python notebook (Chapter_05.ipynb) in the GitHub repository.\\nThe significance of tools in agentic systems\\nThe paradigm shift toward tool use is driven by the recognition that many complex problems demand \\na diverse array of specialized tools and resources, each contributing a unique set of capabilities. Rather \\nthan attempting to encapsulate all requisite knowledge and functionalities within the agent itself, a \\nmore efficient and scalable approach involves intelligently leveraging the appropriate tools as needed.\\nFor instance, an agent tasked with providing personalized healthcare recommendations could exploit \\ntools such as medical databases, clinical decision support systems, and advanced diagnostic algorithms. \\nBy judiciously combining these external resources with its own reasoning capabilities, the agent can \\ndeliver more accurate and comprehensive guidance, tailored to individual patient profiles and conditions.\\nThe concept of tool use in intelligent agents is not limited to software-based tools alone. In certain \\ndomains, such as robotics and automation, agents may interact with physical tools, machinery, or \\nspecialized equipment to extend their capabilities into the physical realm. For example, a robotic agent \\nin a manufacturing plant could leverage various tools and machinery to perform intricate assembly \\ntasks, quality inspections, or material handling operations.\\nUltimately, the ability to effectively utilize external tools and resources is a hallmark of truly intelligent \\nagents, capable of adapting and thriving in dynamic, complex environments. By going beyond the \\nlimitations of their native capabilities, these agents can continually evolve, leveraging the collective \\npower of diverse tools and systems to achieve ambitious objectives.\\nAnother good example is that of a virtual travel agent that has the capability to access multiple APIs, \\ndatabases, and software tools to plan and book complete travel itineraries for users. Such a travel agent \\ncould leverage APIs from airlines, hotels, rental car companies, and travel review sites to gather real-\\ntime data on flight schedules, availability, pricing, and customer ratings. It could also tap into databases \\nof travel advisories, travel document requirements, and destination information. By integrating and \\nreasoning over all this data from various tools, the agent can provide personalized recommendations, \\nmake intelligent trade-offs, and seamlessly book and coordinate all aspects of a trip tailored to the \\nuser’s preferences and constraints. Naturally, the set of tools used in such a case is diverse and they \\nall operate in their unique ways.Planning algorithms for agents 117\\nWe’ve looked at what tools are and how they work. Next, we will explore another critical aspect of \\nagentic systems – planning – and some of the planning algorithms.\\nPlanning algorithms for agents\\nPlanning is a fundamental capability of intelligent agents, enabling them to reason about their actions \\nand devise strategies to achieve their objectives effectively. Planning algorithms form the backbone of \\nhow LLM agents determine and sequence their actions. An algorithm is a step-by-step set of instructions \\nor rules designed to solve a specific problem or complete a task. It is a sequence of unambiguous and \\nfinite steps that takes inputs and produces an expected output in a finite amount of time.\\nThere are several planning algorithms in AI, each with its own strengths and approaches. However, \\nwhen working with LLM agents, we need to consider their practicality in handling natural language, \\nuncertainty, and large state spaces (all possible situations or configurations that an agent might \\nencounter during its task). For example, in a simple robot navigation task, state spaces might include \\nall possible positions and orientations, but in LLM agents, state spaces become vastly more complex \\nas they include all possible conversation states, knowledge contexts, and potential responses.\\nAmong the known planning algorithms – Stanford Research Institute Problem Solver (STRIPS), \\nhierarchical task network (HTN), A* planning, Monte Carlo Tree Search (MCTS), GraphPlan, Fast \\nForward (FF), and LLM-based planning – they can be categorized by their practicality for LLM agents.\\nSTRIPS, A* planning, GraphPlan, and MCTS, while powerful in traditional AI, are less practical for \\nLLM agents due to their rigid structure and difficulty handling natural language. FF shows moderate \\npotential but requires significant adaptation. The most practical approaches are LLM-based planning \\nand HTN, as they naturally align with how language models process and decompose tasks. Let’s \\ndiscuss them in detail.\\nLess practical planning algorithms\\nAs mentioned earlier, less practical planning algorithms include STRIPS, A* planning, GraphPlan, \\nand MCTS. Here’s a detailed overview.\\nSTRIPS\\nSTRIPS works with states and actions defined by logical predicates, making it effective for clear, binary \\nconditions. However, it’s unsuitable for LLM agents because natural language interactions can’t be \\neffectively reduced to simple true/false conditions. For example, while STRIPS can easily model \\ntrue/false states, it struggles with nuanced language states such as partially understanding a concept \\nor somewhat satisfied with a response, making it too rigid for language-based planning.Enabling Tool Use and Planning in Agents 118\\nA* planning\\nA* planning, while powerful for pathfinding problems, faces fundamental challenges with LLM agents. \\nThe algorithm requires a clear way to calculate both the cost of actions taken and a heuristic estimate \\nof the remaining cost to reach a goal. In language-based interactions, defining these costs becomes \\nhighly problematic – how do you quantify the “distance” between different conversation states or \\nestimate the “cost” of reaching a particular understanding? These mathematical requirements make \\nA* impractical for natural language planning.\\nGraphPlan\\nGraphPlan builds a layered graph structure representing possible actions and their effects at each time \\nstep. When applied to LLM agents, this approach breaks down because language interactions don’t fit \\nneatly into discrete layers with clear cause-and-effect relationships. The combinatorial explosion of \\npossible language states and the difficulty in determining mutual exclusion relationships between different \\nconversational actions make GraphPlan computationally intractable for language-based planning.\\nMCTS\\nFor LLM agents, MCTS becomes impractical for two main reasons. First, each “simulation” would \\nrequire actual LLM calls, making it prohibitively expensive in terms of computation and cost; second, \\nthe vast space of possible language interactions makes random sampling inefficient for finding \\nmeaningful patterns or strategies. The algorithm’s strength in game-like scenarios becomes a weakness \\nin open-ended language interactions.\\nModerately practical planning algorithm – FF\\nFF planning is considered to be a moderately practical planning algorithm that can be used in \\nLLM agents. It uses a heuristic search with a simplified version of the planning problem to guide its \\nsearch. Its focus on goal-oriented planning could be adapted for LLM agents, though it would require \\nmodifications to handle natural language effectively. FF planning uses heuristic search with a simplified \\nversion of the planning problem to guide its search.\\nFor LLM agents, FF planning offers several compelling advantages that make it worth considering. \\nIts goal-oriented approach naturally aligns with how LLMs handle task completion, while its relaxed \\nplanning mechanism provides useful approximations for complex language tasks. The heuristic \\nguidance helps manage the vast search space inherent in language-based planning, and its flexibility \\nallows modification to work with partial state descriptions, which is particularly valuable in natural \\nlanguage contexts.\\nHowever, FF planning also faces significant challenges when applied to LLM agents. The original \\nnumeric heuristics that make FF effective in traditional planning don’t translate smoothly to language \\nstates, and relaxed plans risk oversimplifying the rich context present in language interactions. There’s \\nalso considerable difficulty in defining clear delete effects – what aspects of a conversation state arePlanning algorithms for agents 119\\nremoved or changed by an action – in language-based planning. Perhaps most challengingly, the \\nfundamental state representation requires substantial adaptation to work effectively with natural \\nlanguage. In practice, FF could be adapted for LLM agents as follows:\\n1 class LLMFastForward:\\n2    def create_relaxed_plan(self,\\n3                            current_state: str,\\n4                            goal: str) -> list:\\n5     \"\"\"Create a simplified plan ignoring complexities\"\"\"\\n6     # Use LLM to generate a high-level plan\\n7     prompt = f\"Given current state: {current_state}\\\\nAnd\\n               goal: {goal}\\\\n\"\\n8     prompt += \"Generate a simplified step-by-stepplan\"\\n9        return self.llm.generate_plan(prompt)\\n10\\n11   def select_next_action(self, relaxed_plan: list):\\n12      \"\"\"Choose next action based on the relaxed plan\"\"\"\\n13      # Implement action selection logic\\n14      return relaxed_plan[0]  # Simplified selection\\nThis code demonstrates a simplified adaptation of FF planning for LLM agents. Let me explain its key \\ncomponents. The LLMFastForward class has two main methods:\\n• create_relaxed_plan: This method takes the current state and goal as text strings and \\nuses an LLM to generate a simplified plan. Think of it as asking the LLM, “ Given where we \\nare now, and where we want to go, what are the main steps we should take?” . It ignores many \\ncomplexities, similar to how traditional FF planning ignores delete effects.\\n• select_next_action: This method chooses the next action from the relaxed plan. In \\nthis simplified version, it just takes the first action from the plan (relaxed_plan[0]). In a \\nmore sophisticated implementation, it would use additional logic to select the most appropriate \\nnext action.\\nIn essence, this code shows how FF planning’s core concept of using simplified plans to guide decision-\\nmaking can be adapted to work with language models, even though it’s a significant simplification of \\nboth FF planning and LLM capabilities. While this adaptation shows potential, implementing FF for \\nLLM agents requires careful consideration of how to represent states, actions, and relaxed problems \\nin a language-model context. This makes it moderately practical – possible but requiring significant \\nmodifications from its original form.\\nMost practical planning algorithms\\nWhen it comes to planning algorithms for LLM agents, two approaches stand out as particularly \\neffective: LLM-based planning and HTN planning. These algorithms have proven especially suitableEnabling Tool Use and Planning in Agents 120\\nfor language models because they naturally align with how LLMs process information and handle \\ncomplex tasks. While traditional planning algorithms often struggle with the ambiguity and complexity \\nof natural language, these approaches embrace the fluid, contextual nature of language-based planning. \\nLet’s explore each of these algorithms and understand why they’ve become the preferred choices for \\nmodern AI agent frameworks.\\nLLM-based planning\\nModern approaches leverage LLMs to generate plans in a more flexible and natural way. This approach \\ncan handle complex, real-world scenarios and understand context better than traditional planning \\nalgorithms. LLM-based planning operates on the principle that language models can understand \\ncomplex goals, generate appropriate steps to achieve them, and adapt these steps based on changing \\ncontexts. Unlike traditional planners that require explicit state representations, LLM planners work \\nwith natural language descriptions of states and actions, making them inherently more flexible and \\nexpressive. Let’s visualize the planning process using Figure 5.3:\\nFigure 5.3 – LLM-based planning algorithm flowPlanning algorithms for agents 121\\nLet’s examine a practical implementation using CrewAI that demonstrates this planning approach. In \\nthis example, we’ll create a travel planning system with two specialized agents: a Travel Planning Strategist \\nwho breaks down travel requests into manageable steps, and a Travel Researcher who validates and finds \\nspecific options. The system processes natural language travel requests and generates comprehensive \\ntravel plans through collaborative agent interaction. Here’s the implementation:\\n1 class TravelPlanner:\\n2    def __init__(self):\\n3        self.planner = Agent(\\n4            role=\\'Travel Planning Strategist\\',\\n5            goal=\\'Create comprehensive, personalized travel plans\\',\\n6            ... # Other parameters\\n7        )\\n8        self.researcher = Agent(\\n9            role=\\'Travel Researcher\\',\\n10           goal=\\'Find and validate travel options and \\nopportunities\\',\\n11           ... # Other parameters\\n12       )\\n13\\n14   def create_travel_plan(self, request: str) -> Dict:\\n15       planning_task = Task(\\n16           description=f\"\"\"\\n17           Analyze the following travel request and\\n18           create a detailed plan:\\n19           {request}\\n20           Break this down into actionable steps by:\\n21           1. Understanding client requirements\\n22           3. Specific booking requirements\\n23           4. Required validations\\n24           \"\"\", agent=self.planner )\\n25\\n26       research_task = Task(\\n27           description=\"\"\"\\n28           Based on the initial plan, research and\\n29           validate: Flight availability, hotel options,\\n30           and local transportation\\n31           \"\"\", agent=self.researcher)\\n32\\n33       crew = Crew(\\n34           agents=[self.planner, self.researcher],\\n35           tasks=[planning_task, research_task],\\n36           process=Process.sequential )\\n37       return crew.kickoff(inputs={\"request\": request})Enabling Tool Use and Planning in Agents 122\\nThis implementation demonstrates several key advantages of LLM-based planning. The planner \\ncan understand complex natural language requests, dynamically generate appropriate steps, and \\nadapt to different types of travel planning scenarios. The agents can work together, sharing context \\nand building upon each other’s outputs. The system’s sophistication comes from its ability to handle \\nnuanced requirements. For instance, when a user requests “ a relaxing beach vacation with some \\ncultural activities, ” the planner understands these abstract concepts and can translate them into \\nconcrete recommendations.\\nHowever, developers should be mindful of certain caveats. LLM-based planning systems can sometimes \\ngenerate overly optimistic or impractical plans if not properly constrained. They may also struggle \\nwith highly specific numerical constraints or strict timing requirements unless these are explicitly \\nhandled in the implementation. A significant advantage of LLM-based planning over traditional \\nalgorithms lies in the system’s adaptability. While STRIPS or A* planning would require explicit state \\nrepresentations for every possible travel scenario, LLM-based planning can handle novel situations by \\nleveraging its understanding of language and context. This makes it particularly suitable for domains \\nwhere requirements are often ambiguous or evolving. This planning approach also excels at handling \\nuncertainty and partial information, something traditional planners struggle with. When information \\nis missing or ambiguous, the system can generate reasonable assumptions and include contingency \\nsteps in its plans.\\nHTN\\nHTN planning breaks down complex tasks into simpler subtasks, creating a hierarchy of actions. Unlike \\nSTRIPS, which works with primitive actions, HTN can work with abstract tasks and decompose them \\ninto more concrete steps. This makes it particularly well-suited for real-world planning problems \\nwhere tasks naturally decompose into subtasks. HTN planning works by breaking down high-level \\ntasks into progressively smaller subtasks. Consider the following example code:\\n1 def buy_groceries_task():\\n2    return [\\n3        (\\'go_to_store\\', []),\\n4        (\\'select_items\\', []),\\n5        (\\'checkout\\', []),\\n6        (\\'return_home\\', [])\\n7    ]\\n8\\n9 def select_items_task():\\n10   return [\\n11       (\\'check_list\\', []),\\n12       (\\'find_item\\', []),\\n13       (\\'add_to_cart\\', [])\\n14   ]Planning algorithms for agents 123\\nHTN planning operates on the principle of task decomposition, where high-level tasks (compound \\ntasks) are broken down into smaller, more manageable subtasks until reaching primitive tasks that \\ncan be directly executed. This hierarchical structure allows for intuitive problem representation and \\nefficient solution finding. In our example, buy_groceries_task is a high-level task broken \\ndown into four subtasks. One of these subtasks, select_items, is further decomposed into three \\nmore specific actions, and so on. In the context of our travel agent example, we can use a similar \\nhierarchical breakdown of complex tasks decomposed into smaller tasks. Visually, Figure 5.4 shows \\nhow this may look:\\nFigure 5.4 – HTN decomposition\\nTo implement this with CrewAI, we can use CrewAI’s hierarchical processing, where tasks are broken \\ndown into a hierarchical manner as explained using the HTN planning algorithm. With the CrewAI \\nframework, the hierarchical method requires a manager unit, which would be responsible for breaking \\ndown the tasks and delegating individual tasks to the agents. The Manager can either be an agent or it \\ncan be the LLM itself. If the Manager is an agent, then you can control how the manager breaks down \\nthe tasks to n-level tasks as per the workflow’s needs. If the Manager is an LLM, then it will use the \\narbitrary plan generated by the LLM itself based on the user’s query. With a Manager LLM, you may \\nbe able to control how the task breakdown works and how the delegation works using some prompt \\nengineering; however, it is generally less flexible and is meant for simpler workflows. Here’s a sample \\ncode for an HTN-like workflow for the travel planner:\\n1 flight_specialist = Agent(\\n2     role=\\'Flight Planning Specialist\\',\\n3     goal=\\'Handle all aspects of flight arrangements\\',Enabling Tool Use and Planning in Agents 124\\n4     backstory=\\'Expert in airline bookings and flight\\n                logistics.\\')\\n5\\n6 accommodation_specialist = Agent(\\n7    role=\\'Accommodation Specialist\\',\\n8    goal=\\'Manage all accommodation-related planning\\',\\n9    backstory=\\'Expert in hotel and accommodation booking\\')\\n10\\n11 activity_specialist = Agent(\\n12    role=\\'Vacation Activity Specialist\\',\\n13    goal=\\'Manage all activity-related planning\\',\\n14    backstory=\"Expert in recreational activity\\n                 arrangements.\",)\\n15\\n16 manager_llm = ChatOpenAI(model=\"gpt-4o-mini\")\\n17 travel_planning_task = Task(\\n18    description=f\"\"\"\\n19      Plan a comprehensive flight itinerary based on the\\n20      following request:\\n21      {request}\\n22      The plan should include: Flight arrangements,\\n23      Accommodation bookings, other relevant travel\\n24        components\\n25      \"\"\",\\n26      expected_output=\"A detailed flight itinerary\\n        covering all requested aspects.\",\\n27      agent=None) #No agent; the manager will delegate\\n                    subtasks\\n28\\n29 crew = Crew(\\n30           agents=[self.flight_specialist,\\n31                   self.accommodation_specialist,\\n32                   self.activity_specialist],\\n33           tasks=[travel_planning_task],\\n34           process=Process.hierarchical,\\n35           manager_llm=self.manager_llm,)\\n36      return crew.kickoff()\\nThe output of this execution may look as shown (output has been trimmed for brevity):\\nFinal Travel Plan:\\nHere\\'s the complete travel itinerary for a 5-day trip to Paris from \\nNew York for two adults:\\n---Planning algorithms for agents 125\\nTravel Itinerary for Paris Trip\\nFrom New York (JFK) to Paris (CDG)\\nTravelers: 2 Adults , Duration: 5 Days\\n---\\n1. Flights:\\n- Departure Flight: ...\\n- Total Flight Cost: $2,960\\n---\\n2. Hotel Accommodations:\\n- Hotel: ...\\n- Estimated Total = €800.\\n---\\n3. Airport Transfers:\\n- Option 1: ...\\n- Option 2: ...\\n---\\n4. Day Trip to Versailles:\\n- Transportation: Round-trip via RER C train from …\\n   - Cost: Approximately …\\n   - Departure Time: 9:00 AM from …\\n   - Return Time: 5:00 PM from Versailles.\\n   ...\\n   - Overall Total for Day Trip: Approximately €364.20.\\n---\\nGrand Total Estimated Cost:\\n- Flights: $2,960\\n- Accommodation: €800 (with Le Fabe Hotel)\\n- Airport Transfers: €100 (may vary)\\n- Day Trip to Versailles: Approximately €364.20\\n- Convert Total Costs as Necessary to USD.\\n...\\nNote that, in this case, the agentic system has no access to external tools or lookup, so whatever response \\nit generates is going to be completely fictional and non-factual. This underscores the importance \\nof tools, which we will look at in the next section. For now, the previous example shows how you \\ncan use the framework for task breakdown and have a Manager manage several agents to perform \\ndecomposed simplified tasks from a user’s request. Y ou can see the full code in the Python notebook \\n(Chapter_05.ipynb) in the GitHub repository.\\nHTN planning offers several significant advantages that make it particularly effective for complex \\nplanning scenarios. Its natural problem representation mirrors human thinking patterns, making it \\nintuitive to understand and maintain. The hierarchical approach enables better scalability by breaking \\ndown complex problems into manageable subtasks, effectively reducing the search space. HTN’s \\nstructure excels at encoding expert knowledge through its task hierarchies, allowing for reusableEnabling Tool Use and Planning in Agents 126\\npatterns across similar problems. Additionally, its flexibility in handling both abstract and primitive \\ntasks makes it adaptable to various planning situations, enabling planners to work at different levels \\nof abstraction as needed.\\nSo far, we’ve learned about tools and several planning algorithms, but together they can enable LLM \\nagents to perform more complex, multi-step tasks by combining strategic planning with effective tool \\nuse. Let’s further explore how we can effectively integrate tool use with planning within agentic systems.\\nIntegrating tool use and planning\\nMost of the earlier work in AI planning and tool usage was done in isolation, focusing on either \\nplanning algorithms or tool capabilities separately. However, to achieve truly intelligent agents, there \\nis a need to integrate tool use with planning effectively. As we already saw in the previous section, our \\ntravel planner gave us a detailed travel plan but none of the details were factual – that is, it contained \\ninformation that the LLM simply made up. In order to infuse our system with actual flight, hotel, and \\nactivity data so that the travel plan is grounded in facts, we will need to utilize tools along with the \\nplanning algorithm. This section will discuss how to combine these two aspects to generate relevant \\nresponses and complete tasks accurately.\\nReasoning about tools\\nAgents need the ability to reason about the available tools at their disposal, understanding the \\nfunctionality, capabilities, and limitations of each tool, as well as the contexts and conditions under \\nwhich they can be applied effectively. The reasoning process involves assessing the available tools \\nbased on the current goals and objectives, and then choosing the most appropriate ones that can be \\nutilized in the given situation or problem domain.\\nFor example, in the case of our travel planner, the agent will have access to various tools such as flight \\nbooking APIs, hotel reservation systems, and activity planning software. The agent needs to reason \\nabout the capabilities of each tool, such as which tools can be used for booking flights or book hotels, \\nand which ones can provide information about local attractions.\\nWhen working with LLM agents, reasoning about tools is largely handled by the language model’s \\ninherent capabilities. Modern LLMs are trained to understand tool descriptions, purposes, and \\nappropriate usage contexts. This means we don’t need to explicitly program complex reasoning \\nmechanisms – instead, we provide clear tool descriptions and let the LLM determine when and how \\nto use them. For example, let’s look at our travel planner agent scenario:\\n1 from crewai import Agent\\n2\\n3 travel_agent = Agent(\\n4   role=\\'Travel Planner\\',\\n5   goal=\\'Plan comprehensive travel itineraries\\',\\n6   tools=[Integrating tool use and planning 127\\n7       flight_search_tool,    # Tool for finding and booking flights\\n8       hotel_booking_tool,    # Tool for hotel reservations\\n9       activity_planner_tool  # Tool for local activities and\\n                                 attractions\\n10    ])\\nThe LLM agent can naturally understand the following:\\n• Which tool to use for each task (for example, flight_search_tool for air travel)\\n• When to use tools in combination (for example, coordinating flight and hotel dates)\\n• How to adapt tool usage based on user requirements (for example, budget constraints)\\nThis built-in reasoning capability means we can focus on providing well-defined tools with clear \\ndescriptions, rather than implementing complex reasoning mechanisms. The LLM will handle the \\ndecision-making process of tool selection and application based on the context and requirements of \\neach situation. However, not all language models are equally capable of effective tool reasoning. This \\ncapability typically requires models that have been specifically trained or fine-tuned for tool use and \\nfunction calling. Smaller models or those without tool-use training may have the following issues:\\n• Failing to understand when a tool is needed\\n• Making incorrect assumptions about tool capabilities\\n• Using tools in the wrong sequences\\n• Missing opportunities to use available tools\\n• Ignoring tool constraints or requirements\\nEven capable models can face limitations such as the following:\\n• Difficulty with complex tool combinations requiring many steps\\n• Inconsistency in tool selection across similar scenarios\\n• Challenges with tools that have subtle differences in functionality\\n• Struggles with error recovery when tools fail\\nThis is why frameworks such as CrewAI, LangGraph, and AutoGen often work best with more advanced \\nmodels that have demonstrated strong tool reasoning capabilities, and why it’s important to test your \\nagent’s tool usage patterns before deployment.Enabling Tool Use and Planning in Agents 128\\nPlanning for tool use\\nThe planning process in modern AI agents is fundamentally driven by LLM capabilities, building \\nupon the principles we discussed in LLM-based planning and HTN approaches. Rather than following \\nrigid planning algorithms, agents leverage their language model’s understanding to create flexible, \\ncontext-aware plans for tool usage. Figure 5.5 depicts this process:\\nFigure 5.5 – Tool planning flow\\nWhen an agent receives a request, it first understands the goals through natural language processing. \\nFor a travel agent, this might mean comprehending that a family vacation request requires not just \\nflight bookings but also family-friendly accommodation and activities. This goal-understanding phase \\ndraws directly from the LLM’s trained comprehension abilities.\\nThe planning process then shifts to identifying which tools are needed and in what sequence they \\nshould be used. This mirrors the hierarchical decomposition we saw in HTN planning but with the \\nflexibility of LLM-based decision-making. The agent doesn’t just follow predefined decomposition \\nrules; it adapts its planning based on the specific context and requirements of each request.\\nTool integration into the plan happens naturally as part of this process. The agent understands tool \\ncapabilities through their descriptions and can sequence them appropriately. For instance, when \\nplanning a vacation, the agent knows that flight dates need to be confirmed before booking hotels, \\nand that activity planning should consider the location and timing of both.\\nThis planning approach combines the structured nature of traditional planning algorithms with the \\nadaptability of language models. The agent can adjust its plans based on new information or changingExploring practical implementations 129\\ncircumstances, much like a human travel agent would modify their approach based on client feedback \\nor availability changes.\\nThe success of this planning process relies heavily on the LLM’s ability to understand context and \\ngenerate appropriate sequences of actions. This is why frameworks such as CrewAI often implement \\nthis type of planning, allowing agents to leverage their language understanding capabilities while \\nmaintaining the systematic approach needed for complex task completion.\\nExploring practical implementations\\nTo demonstrate how various AI/ML frameworks can be used to create intelligent agents capable \\nof executing complex tasks through tool use and planning, let’s explore examples using CrewAI, \\nAutoGen, and LangGraph (the agentic framework of LangChain). Y ou can find the full code for each \\nof the framework examples in the Chapter_05.ipynb Python notebook in the GitHub repository.\\nCrewAI example\\nLet’s examine how CrewAI implements tool-based reasoning through a practical travel planning \\nexample. The framework’s Python library provides a @tool decorator that allows us to define tools \\nwith clear descriptions and documentation. Here’s how we can create a set of travel-related tools:\\n1 @tool(\"Search for available flights between cities\")\\n2 def search_flights(...) -> dict:\\n3    \"\"\"Search for available flights between cities.\"\"\"\\n4    # Call flight API and other tool logic\\n5\\n6 @tool(\"Find available hotels in a location\")\\n7 def find_hotels(...) -> dict:\\n8   \"\"\"Search for available hotels in a location.\"\"\"\\n9   # Call hotels API and other tool logic\\n10\\n11 @tool(\"Find available activities in a location\")\\n12 def find_activities(...) -> dict:\\n13   \"\"\"Find available activities in a location.\"\"\"\\n14  # Call activities API and other tool logic\\nThe tools are then assigned to an agent that understands how to use them in context. The agent is \\ncreated with a specific role, goal, and backstory that helps guide its decision-making:\\n1 Agent(\\n2    role=\\'An expert travel concierge\\',\\n3    goal=\\'Handle all aspects of travel planning\\',\\n4    backstory=\"Expert in airline bookings and flight\\n          logistics, hotel bookings, and booking vacationEnabling Tool Use and Planning in Agents 130\\n          activities.\",\\n5    tools=[search_flights, find_hotels, find_activities],\\n6    verbose=False\\n7 )\\nWhen given a task, the agent uses these tools based on the context and requirements:\\n1 travel_planning_task = Task(\\n2    description=f\"\"\"\\n3    Plan a comprehensive travel and leisure itinerary\\n4    based on the following request:\\n5    {request}\\n6    The plan should include:\\n7    - Flight arrangements\\n8    - Accommodation bookings\\n9    - Any other relevant travel components\\n10   \"\"\",\\n11   expected_output=\"A detailed travel itinerary covering\\n         all requested aspects.\",\\n12   agent=self.travel_specialist )\\nWhen crew.kickoff() is called, CrewAI orchestrates the tool usage in the following ways:\\n• Understanding the task requirements through the task description\\n• Identifying which tools are needed based on the agent’s role and the task goals\\n• Using the tools in a logical sequence to build the travel plan\\n• Processing tool outputs and incorporating them into the final response\\nThis implementation demonstrates how CrewAI combines tool definitions, agent capabilities, and task \\nspecifications to create a coherent planning system. The framework handles the complexity of tool \\nreasoning while allowing developers to focus on defining clear tool interfaces and agent behaviors.\\nAutoGen example\\nAutoGen provides a platform for developing AI agents that can engage in conversations and, through \\nthese interactions, arrive at solutions for given tasks. AutoGen approaches multi-agent collaboration \\nthrough a RoundRobinGroupChat system where specialized agents interact to create a comprehensive \\ntravel plan. The implementation defines four key agents: a flight planner, a hotel planner, an activities \\nplanner, and a summary agent, each with specific responsibilities and tools.Exploring practical implementations 131\\nEach agent is initialized with the following:\\n• A name and description\\n• A model client (in this case, OpenAI’s GPT-4o-mini)\\n• Specific tools they can access\\n• A system message defining their role and responsibilities\\nThe key differentiators from CrewAI lie in the execution model:\\n• Agent communication: While CrewAI uses a hierarchical task-based approach, AutoGen \\nimplements a round-robin group chat where agents take turns contributing to the solution. \\nThe RoundRobinGroupChat class orchestrates this conversation flow, allowing agents to \\nbuild upon each other’s suggestions.\\n• Termination handling : AutoGen uses an explicit termination condition through the \\nTextMentionTermination class. The travel summary agent can end the conversation \\nby mentioning \"TERMINATE\" when a complete plan is ready. This differs from CrewAI’s task-\\ncompletion-based termination. Here are the parameters of TextMentionTermination:\\n \\x82 mention_text(str): The keyword or phrase that triggers termination (e.g., \"TERMINATE\")\\n \\x82 case_sensitive (bool, optional) : Whether the keyword matching should \\nbe case-sensitive\\n \\x82 strip_whitespace (bool, optional): Whether to ignore leading/trailing spaces \\nin the detected text\\n \\x82 regex_match (bool, optional): Allows for using regular expressions for more \\nflexible termination triggers\\n• Tool integration: Instead of CrewAI’s decorator-based tool definition, AutoGen associates \\ntools directly with agents during initialization. Each agent has access to specific tools relevant \\nto their role.\\n• Coordination pattern: While CrewAI often uses a manager-worker pattern, AutoGen’s round-\\nrobin approach creates a more collaborative environment where agents contribute equally to \\nthe solution, with the summary agent responsible for creating the final integrated plan.\\nThis implementation showcases AutoGen’s strength in handling complex multi-agent conversations \\nwhile maintaining clear role separation and specialized tool usage for each agent. The following is \\nhow you define agents with AutoGen:\\n1 flight_agent = AssistantAgent(\\n2    name=\"flight_planner\",\\n3    model_client=model_client,\\n4    tools=[travel_tools.search_flights],Enabling Tool Use and Planning in Agents 132\\n5    description=\"A helpful assistant that can plan flights\\n                 itinerary for vacation trips.\",\\n6    system_message=\"You are a helpful assistant that can\\n           plan flight itinerary for a travel plan for a\\n           user based on their request.\" )\\n7\\n8 hotel_agent = AssistantAgent(\\n9    name=\"hotel_planner\",\\n10    model_client=model_client,\\n11    tools=[travel_tools.search_flights],\\n12    description=\"...\", system_message=\"...\" )\\nOnce agents are defined, a RoundRobinGroupChat class can be defined using the agents and a \\nconversation with the multi-agent system can be invoked:\\n2 group_chat = RoundRobinGroupChat(\\n3     [flight_agent, hotel_agent],\\n4     termination_condition=termination)\\n6  await Console(group_chat.run_stream(task=\"I need to plan\\n               a trip to Paris from New York for 5 days.\"))\\nLangGraph example\\nLangChain provides a framework for developing applications that can leverage LLMs alongside other \\ntools and data sources. In the context of agentic systems, LangChain provides a sub-framework known \\nas LangGraph that is used to build powerful LLM agent-based workflows. LangGraph approaches agent-\\nbased travel planning through a workflow graph system, offering a different paradigm from both CrewAI \\nand AutoGen. Let’s examine how this implementation works and its distinguishing characteristics.\\nLangGraph uses a state machine approach where the workflow is defined as a graph with nodes and \\nedges. The implementation centers around two main nodes:\\n• An agent node that processes messages and makes decisions\\n• A tool node that executes the requested tools (flight search, hotel booking, and activity planning)\\nThe workflow follows a cycle where the agent node evaluates the current state and either makes tool \\ncalls or provides a final response. This is controlled through a function that interprets the model’s next \\nmove (that is, call a tool or end the response), which determines whether to route to the tools node \\nor end the conversation. Just like CrewAI, LangGraph also uses the @tool decorator (for Python) \\nwith which the tool functions can be defined:\\n1 @tool\\n2 def search_flights(...) -> dict:\\n3    \"\"\"Search for available flights between cities.\"\"\"Exploring practical implementations 133\\n4   # Emulate JSON data from an API\\n5   return data\\nOnce nodes are defined with or without tools, they can be connected to each other to build a full \\ngraph structure of the workflow. For example, in our case, the following code defines a state graph-\\nbased workflow using LangGraph, where a task cycles between two nodes: agent and tools. The graph \\nstarts at the agent node (defined as the entry point), which calls a function (call_model) to process \\ninput. After the agent runs, a conditional function ( should_continue) determines the next \\nnode – either looping back to the tools node or ending the workflow. The tools node (tool_node) \\nprocesses intermediate tasks and always transitions back to the agent node, creating a repetitive \\ncycle until the conditional function decides to stop. A MemorySaver checkpoint is used to persist \\nthe state across runs, and the graph is compiled into a LangChain-compatible runnable. Finally, the \\nworkflow is invoked with an initial input message about planning a trip, and the final message content \\nis printed after the graph execution concludes:\\n1 workflow = StateGraph(MessagesState)\\n2 workflow.add_node(\"agent\", call_model)\\n3 workflow.add_node(\"tools\", tool_node)\\n4 workflow.add_edge(START, \"agent\")\\n5 workflow.add_conditional_edges(\"agent\",should_continue)\\n6 workflow.add_edge(\"tools\", \\'agent\\')\\n7 checkpointer = MemorySaver()\\n8 app = workflow.compile(checkpointer=checkpointer)\\n9 final_state = app.invoke(\\n10   {\"messages\": [HumanMessage(content=\"I need to plan a\\n               trip to Paris from New York for 5 days\")]},\\n11    config={\"configurable\": {\"thread_id\": 42}})\\nLangGraph’s approach offers several notable advantages. For example, its graph structure provides explicit \\nflow control, making workflows easy to visualize and understand, while built-in state management \\nwith checkpointing capabilities ensures robust handling of the application state. However, these \\nbenefits come with certain trade-offs. The framework requires a solid understanding of graph-based \\nprogramming concepts, and its initial setup involves more overhead compared to CrewAI’s more \\nstraightforward agent definition. The full code implementation can be found in the Chapter_05.\\nipynb Python notebook in the GitHub repository.Enabling Tool Use and Planning in Agents 134\\nTable 5.1 illustrates some key differences between LangGraph, CrewAI, and AutoGen:\\nLangGraph CrewAI AutoGen\\nState management Uses explicit \\nstate management\\nManages state \\nthrough agent \\ninstances and their \\ntask context\\nHandles state \\nthrough group chat \\nmessage history\\nTool integration Tools are managed \\nthrough a dedicated \\ntool node\\nUses a decorator-\\nbased tool definition \\nwith direct \\nagent association\\nAssociates tools \\ndirectly with \\nspecific agents\\nFlow control Uses a \\ngraph-based workflow\\nUses hierarchical task \\ndecomposition or \\nsequential flow\\nImplements round-\\nrobin turn-taking \\nbetween agents\\nTable 5.1 – Comparison of LangGraph, CrewAI, and AutoGen implementation approaches\\nThe preceding table shows the differences between LangGraph, CrewAI, and AutoGen based on \\nour implementation.\\nSummary\\nIn this chapter, we learned about the crucial role of tools and planning in AI agent systems. We \\ndiscussed what tool/function calling is and how LLM agents exhibit this property. We also learned \\nabout various tool types and saw examples of how to use tools with frameworks or natively with an \\nLLM. Subsequently, we explored various planning algorithms, from traditional approaches such as \\nSTRIPS and HTN to modern LLM-based planning methods, understanding their relative practicality \\nin the context of language models. Through a practical travel planning example, we saw how tools can \\nbe defined, integrated, and utilized within each framework to create sophisticated planning systems.\\nWe learned how integrating tool calling with planning can supercharge agentic systems by making \\nthem more capable of handling complex tasks. We also reviewed the implementation patterns across \\nthree frameworks (CrewAI, AutoGen, and LangGraph), which revealed distinct approaches to agent \\ncoordination and tool usage.\\nIn the next chapter, we will dive into the concepts of the coordinator, worker, and delegator approach \\nin agentic systems, and learn how they can help with completing complex real-world tasks.Questions 135\\nQuestions\\n1. What is the purpose of tools in AI agents, and how do docstrings help in tool definition?\\n2. Explain the difference between traditional planning algorithms (such as STRIPS) and modern \\nLLM-based planning. Why are traditional algorithms less practical for LLM agents?\\n3. How does HTN planning work, and why is it considered one of the more practical approaches \\nfor LLM agents?\\n4. What role does reasoning play in tool selection for LLM agents, and what are its limitations?\\n5. When comparing frameworks (CrewAI, AutoGen, and LangGraph), what are the key factors \\nto consider for an AI agent implementation?\\nAnswers\\n1. Tools in AI agents are functions that enable agents to perform specific tasks or access external \\nservices. Docstrings provide crucial information about the tool’s purpose, expected parameters, \\nand return values, helping the LLM understand when and how to use each tool effectively. This \\ndocumentation serves as the context that guides the model’s decision-making process.\\n2. Traditional planning algorithms such as STRIPS rely on explicit state representations and \\npredefined action sets, working with binary conditions and clear state transitions. LLM-based \\nplanning, however, operates with natural language understanding and can handle ambiguous \\nstates and actions. Traditional algorithms struggle with LLMs because they can’t effectively \\nrepresent the nuanced, contextual nature of language-based tasks.\\n3. HTN planning works by breaking down complex tasks into progressively simpler subtasks in \\na hierarchical structure. It’s practical for LLM agents because this hierarchical decomposition \\nmirrors how language models naturally process and understand tasks. The approach allows for \\nboth structured planning and the flexibility needed for language-based interactions.\\n4. Reasoning in LLM agents is largely handled by the model’s built-in capabilities to understand \\ncontext and make decisions. While this makes tool selection more natural, not all models are \\nequally capable. Limitations include potential inconsistencies in tool selection, difficulties with \\ncomplex tool combinations, and challenges in error recovery when tools fail.\\n5. Key factors for framework selection include the complexity of the workflow (structured versus \\nconversational), the need for state management, multi-agent collaboration requirements, and \\ndevelopment complexity. CrewAI offers straightforward implementation, AutoGen excels at \\nmulti-agent interaction, and LangGraph provides robust workflow control but requires more setup.Enabling Tool Use and Planning in Agents 136\\nJoin our communities on Discord and Reddit\\nHave questions about the book or want to contribute to discussions on Generative AI and LLMs? \\nJoin our Discord server at https://packt.link/I1tSU and our Reddit channel at https://\\npackt.link/ugMW0 to connect, share, and collaborate with like-minded enthusiasts.6\\nExploring the Coordinator, \\nWorker, and Delegator \\nApproach\\nIn the previous chapter, we looked into the concepts of tool use and planning, which lay an essential \\nfoundation for intelligent agents to enhance their problem-solving capabilities. We explored various \\nplanning algorithms, including state space search techniques and hierarchical task networks (HTNs), \\nand examined how these algorithms can be seamlessly integrated with external tools and resources \\nto enable agents to perform optimally.\\nBuilding upon this foundation, in this chapter, we will ground our understanding by exploring a \\npowerful organizational framework for intelligent agents: the coordinator-worker-delegator (CWD) \\napproach. This chapter is divided into the following main sections:\\n• Understanding the CWD model\\n• Designing agents with role assignments\\n• Communication and collaboration between agents\\n• Implementing the CWD approach in generative AI systems\\nBy the end of this chapter, you will have a comprehensive understanding of how to design and \\nimplement multi-agent systems using the CWD approach. Y ou’ll know how to effectively assign roles \\nto different agents, establish robust communication protocols between them, and orchestrate their \\ninteractions to tackle complex problems.Exploring the Coordinator, Worker, and Delegator Approach 138\\nTechnical requirements\\nY ou can find the code file for this chapter on GitHub at https://github.com/PacktPublishing/\\nBuilding-Agentic-AI-Systems. In this chapter, we will also use the Python frameworks that \\nwe have already used in previous chapters to demonstrate the various aspects of the CWD approach \\nand agent roles.\\nUnderstanding the CWD model\\nThe CWD model is a comprehensive framework designed to facilitate the development of multi-agent \\nsystems, emphasizing collaboration, specialization, and effective distribution of tasks and resource \\nmanagement. Just as human organizations benefit from clear role delegation and hierarchical structures, \\nintelligent agents can achieve greater effectiveness through thoughtful division of labor. The CWD \\nframework, as shown in Figure 6.1, draws inspiration from organizational psychology and management \\ntheory, adapting proven principles of human coordination to the field of intelligent agents. This approach \\nis particularly valuable as agent systems grow in complexity and need to handle increasingly intricate \\ntasks that require multiple specialized capabilities working in concert. This model is particularly well \\nsuited for environments where autonomous agents must collaborate to achieve complex objectives \\nthat may be beyond the capabilities of a single agent.\\nFigure 6.1 – The CWD modelUnderstanding the CWD model 139\\nThe CWD model establishes three distinct roles that work together to accomplish complex tasks:\\n• Coordinators: Coordinators are agents responsible for managing tasks, resources, and the \\noverall workflow of the system. Their primary responsibilities encompass facilitating progress \\nmonitoring, assigning tasks to appropriate agents, and enabling effective collaboration among \\nworkers. coordinators play a crucial role in ensuring smooth operations and keeping the \\nsystem aligned with its objectives. They act as orchestrators, overseeing the entire process and \\ncoordinating the various components to work in harmony. Coordinators prioritize workloads \\nby dynamically allocating tasks based on urgency, resource availability, and dependencies. \\nThey monitor progress, adjust assignments as needed, and ensure seamless collaboration \\namong agents. By optimizing task distribution and workflow execution, they maintain system \\nefficiency and alignment with overall objectives.\\n• Workers: Workers are specialized agents dedicated to carrying out specific tasks or functions \\nwithin the system. These agents possess diverse capabilities and expertise, reflecting a broad \\nrange of skills that can be applied to various tasks. When assigned a task by the delegators, \\nworkers leverage their specialized knowledge and proficiency to efficiently realize the task’s \\nobjectives. The diversity of worker agents allows for a division of labor and the allocation of \\ntasks to the most suitable agents, optimizing the system’s overall performance.\\n• Delegators: Delegators serve as intermediaries between coordinators and workers, responsible \\nfor implementing workload assignments to workers based on resource availability and system \\nneeds. They act as interfaces, facilitating the communication and coordination between the \\ncoordinators and workers. delegators play a crucial role in dispatching and balancing the workload \\nacross multiple workers, ensuring that tasks are assigned to the appropriate agents in a timely \\nand efficient manner. The most critical function of delegators is optimizing overall performance \\nby assigning tasks to the right workers at the right time, considering their capabilities and the \\nsystem’s constraints. Delegators optimize performance by balancing throughput, latency, and \\nresource utilization. They ensure tasks are assigned efficiently to minimize delays (low latency), \\nmaximize completed tasks per unit time (high throughput), and prevent resource bottlenecks \\n(optimal resource utilization). By dynamically adjusting assignments based on worker capacity \\nand system constraints, they enhance overall efficiency and responsiveness.\\nThe CWD model defines distinct roles—coordinators, workers, and delegators—that work together \\nto enhance system efficiency and collaboration. By structuring task allocation, communication, and \\nexecution, it ensures operational harmony, driven by key principles that underpin its effectiveness.Exploring the Coordinator, Worker, and Delegator Approach 140\\nKey principles of the CWD model\\nThe CWD model is founded on several key principles that guide its design and implementation:\\n• Separation of concerns: The fundamental philosophy behind CWD is the clear separation of \\nresponsibilities between strategic planning (coordinator), resource management (delegator), \\nand task execution (worker). This separation allows each component to focus on its core \\ncompetencies while maintaining system flexibility and scalability.\\n• Hierarchical organization : The model implements a hierarchical structure that mirrors \\nsuccessful organizational patterns found in human institutions:\\n \\x82 Top level: Strategic oversight and planning\\n \\x82 Middle level: Resource management and coordination\\n \\x82 Base level: Specialized task execution\\n• Information flow and feedback loops : The CWD model emphasizes bidirectional \\ncommunication flows:\\n \\x82 Downward flow: Task assignments, priorities, and constraints\\n \\x82 Upward flow: Progress updates, results, and resource utilization\\n• Adaptability and resilience : The model is designed to be inherently adaptable through \\nthe following:\\n \\x82 Dynamic resource allocation: Agents continuously assess workload demands and redistribute \\ncomputational or operational resources in real time to optimize efficiency and prevent bottlenecks\\n \\x82 Fault tolerance through redundancy: The system employs multiple agents with overlapping \\ncapabilities, allowing seamless handoff and recovery in case of failures, and ensuring \\nuninterrupted operations\\n \\x82 Load balancing across agents: Tasks are intelligently distributed among agents based on \\ntheir availability, expertise, and current workload, preventing performance degradation and \\nimproving responsiveness\\n \\x82 Runtime role reassignment: Agents can adapt their roles based on evolving system needs, \\nstepping into different responsibilities as required to maintain workflow continuity and \\noperational effectiveness\\nThese mechanisms collectively enhance the system’s ability to adapt, recover, and function efficiently, \\neven in unpredictable conditions, ensuring sustained performance and reliability.Understanding the CWD model 141\\nThe CWD model’s key principles ensure clarity, organization, and adaptability by defining roles, \\nfostering hierarchy, and enabling robust communication. This structured approach enhances efficiency \\nand resilience, making it versatile for various applications, including the development of an intelligent \\ntravel agent system.\\nThe CWD model for the intelligent travel agent\\nAs an example, let’s discuss how the CWD model may be implemented for the intelligent travel agent \\nsystem. The overall structure and flow may be as follows:\\n• Coordinator agent: This agent will act as the travel planning coordinator. This agent will be \\nresponsible for the following:\\n \\x82 Managing the overall travel planning process based on a user request\\n \\x82 Facilitating progress monitoring and effective collaboration among worker agents\\n \\x82 Assigning tasks and coordinating the workflow based on the customer’s travel requirements\\n• Worker agents: There can be a number of different agents, each specializing in its own domain \\nand expertise within travel and hospitality management:\\n \\x82 Flight booking worker: Specialized in searching for and booking flight options based on \\ntravel dates, destinations, and preferences\\n \\x82 Hotel booking worker: Focused on finding and reserving suitable accommodations based \\non location, amenities, and customer preferences\\n \\x82 Activity planning worker: Responsible for researching and planning activities, tours, and \\nexperiences at the travel destination, tailored to the customer’s interests\\n \\x82 Transportation worker: Specialized in arranging ground transportation, such as rental cars, \\nairport transfers, or local transportation options\\n• Delegator agent: This agent will act as the travel task delegator agent. This agent performs \\nthe following:\\n \\x82 Acts as an interface between the travel planning coordinator and the specialized worker agents\\n \\x82 Receives travel planning tasks from the coordinator\\n \\x82 Assesses the capabilities and availability of worker agents\\n \\x82 Assigns appropriate tasks to the suitable worker agents based on their expertise and workload\\n \\x82 Coordinates and balances the workload among the worker agentsExploring the Coordinator, Worker, and Delegator Approach 142\\nFigure 6.2 depicts an extension and adaptation of our previous high-level CWD model diagram \\nto this travel planning scenario:\\nFigure 6.2 – The CWD model for the travel planner\\nLet’s walk through an example of the user requirement and workflow:\\n1. A user approaches the intelligent travel agent system with their travel requirements, such \\nas destination, travel dates, budget, and preferences (for example, family-friendly, cultural \\nexperiences, and beach vacation).\\n2. The travel planning coordinator analyzes the customer’s requirements and breaks down the \\noverall travel planning task into subtasks. This is where the task decomposition happens, as \\nwe learned about in the previous chapter.\\n3. The coordinator communicates these subtasks to the travel task delegator.\\n4. The delegator assesses the available worker agents and assigns tasks accordingly.\\n5. The worker agents collaborate and coordinate with each other as needed, sharing relevant \\ninformation and ensuring a cohesive travel plan.\\n6. The delegator monitors the progress of the tasks and ensures workload balance among the \\nworker agents.\\n7. Once all the tasks are completed, the worker agents submit their respective outputs (for example, \\nflight bookings, hotel reservations, activity itineraries, and transportation arrangements) to \\nthe delegator.Designing agents with role assignments 143\\n8. The delegator compiles and integrates the outputs from the worker agents into a comprehensive \\ntravel plan.\\n9. The travel planning coordinator reviews the final travel plan, makes any necessary adjustments, \\nand presents it to the customer for approval.\\nIn this example, we’ve seen how the CWD model can be effectively applied to create a sophisticated \\ntravel planning system. The model demonstrates how complex tasks can be broken down and managed \\nefficiently through specialized agents, each handling specific aspects of the travel planning process. \\nThis approach not only ensures thorough coverage of all travel requirements but also maintains clear \\ncommunication channels and responsibility allocation throughout the planning process. By structuring \\nthe system this way, we can handle multiple travel requests simultaneously while maintaining quality \\nand attention to detail for each customer’s unique needs.\\nFor those interested in implementing this system, the complete code implementation, including detailed \\nexamples and documentation, can be found in the Chapter_06.ipynb Python notebook in the \\nGitHub repository. This code sample uses many of the concepts of tool and planning to implement \\nthe CWD travel planner. It also utilizes popular frameworks such as CrewAI and AutoGen.\\nIn this section, we’ve explored the CWD model, a framework that mirrors effective human organizational \\npractices to build scalable, efficient, and collaborative multi-agent systems. This model’s emphasis on \\nrole delineation, adaptability, and structured communication ensures that it can manage complex, \\nmulti-faceted tasks such as travel planning seamlessly. Understanding this model is essential, as it \\nprovides a foundation for designing intelligent agent systems capable of handling specialized roles \\nwhile working in concert to achieve overarching goals.\\nIn the next section, we will dive deeper into the principles of agent design, focusing on how assigning \\nroles and responsibilities can optimize system performance and align agent behavior with specific \\nobjectives. This builds directly on the CWD framework, equipping you with practical tools to create \\nintelligent systems tailored to diverse real-world applications.\\nDesigning agents with role assignments\\nIn the context of the CWD model, designing agents with appropriate role assignments is crucial for \\nensuring the effective functioning of a multi-agent system. Careful consideration must be given to the \\nspecific roles and contributions of each agent toward achieving the overall system objectives. This is \\nperhaps very easily explained using CrewAI agents, which can be initialized with a role, a goal, and \\na backstory.\\nWhen designing these agents, the role definition serves as the foundation for their behavior and \\nresponsibilities within the system. The role explicitly defines what the agent is supposed to do and \\nhow it fits into the larger system architecture. For instance, a coordinator agent might be assigned \\nthe role of Strategic Planning Manager, which immediately establishes their authority in overseeing \\nand directing the overall workflow.Exploring the Coordinator, Worker, and Delegator Approach 144\\nEqually important is the backstory, which provides depth and context to how the agent approaches its \\nresponsibilities. The backstory isn’t just a biography – it’s a carefully crafted narrative that shapes the \\nagent’s decision-making process and interaction style. Consider a coordinator agent with a backstory \\nof “A veteran project manager who has successfully led diverse teams in Silicon Valley start-ups, known \\nfor balancing innovation with practical execution. ” This backstory naturally influences how the agent \\nmakes decisions, communicates with other agents, and approaches problem-solving. It’s important \\nto note that this backstory is a CrewAI-specific implementation and CrewAI merges this backstory \\nalong with the role in the LLM’s system prompt, which helps set the context for the model. Here’s an \\nexample with CrewAI:\\ncoordinator = Agent(\\n    role=\"Strategic Planning Manager\",\\n    backstory=\"A veteran project manager who has successfully led\\n              diverse teams in Silicon Valley startups, known for\\n              balancing innovation with practical execution. Expertise\\n              in bridging communication gaps between technical and\\n              non-technical teams while maintaining focus on key\\n              deliverables.\",\\n    verbose=True\\n)\\nThe combination of role and backstory creates a more nuanced and effective agent that can operate \\nwithin the complex dynamics of a multi-agent system while maintaining a clear purpose and direction. \\nWithin CWD-based systems, several typical agent roles can be identified, as follows:\\n• Manager: The Manager agent is responsible for monitoring the system’s operations, managing \\nresources, and ensuring timely task completion. Manager agents are synonymous with \\ncoordinators in the CWD model. Managers play a critical role in overseeing the entire system \\nand ensuring its overall effectiveness. In the context of an intelligent travel agent system, the \\nManager agent could be responsible for tasks such as the following:\\n \\x82 Monitoring the progress of travel planning processes\\n \\x82 Allocating resources (for example, computational resources and access to external APIs) \\nto other agents\\n \\x82 Ensuring that travel plans are generated within specified time constraints\\n• Analyst: The Analyst agent possesses expertise in analyzing data and providing insights and \\nrecommendations based on its findings. These agents can inform and guide decision-making \\nprocesses within the system. In the travel agent scenario, an Analyst agent could be employed \\nfor the following:\\n \\x82 Analyzing customer preferences and travel trends\\n \\x82 Providing recommendations for popular destinations or activities based on data analysisDesigning agents with role assignments 145\\n \\x82 Identifying potential cost-saving opportunities or optimal travel routes\\n \\x82 Summarizing outcomes and recommendations for the user\\n• Reflector: The Reflector agent observes the system’s performance and identifies areas for \\nimprovement. By continuously monitoring the system’s operations, the Reflector can suggest \\nchanges or adjustments that would enhance efficiency and effectiveness. In the travel agent \\ncontext, a Reflector agent could do the following:\\n \\x82 Analyze customer feedback and satisfaction levels\\n \\x82 Identify bottlenecks or inefficiencies in the travel planning process\\n \\x82 Propose improvements to the system’s algorithms or workflows\\n• Searcher: The Searcher agent explores the problem space, constantly seeking new solutions \\nand sharing relevant information with other agents. This role often involves innovation, as the \\nSearcher adapts the system to cope with novel situations. In the travel agent domain, a Searcher \\nagent could do the following:\\n \\x82 Discover new travel destinations or activities\\n \\x82 Explore alternative transportation options or travel routes\\n \\x82 Share information about emerging travel trends or regulations with other agents\\nNote that the Analyst, Reflector, and Searcher roles fit squarely under workers in the CWD model.\\n• Task Interpreter: The Task Interpreter agent serves as a bridge between the coordinators and \\nworkers, mapping high-level tasks into lower-level, concrete, and performable actions for the \\nworker agents. This role ensures that tasks are well defined and understood by the workers. Task \\ninterpreters are synonymous with delegators in the CWD model. In the travel agent system, \\na task interpreter agent could do the following:\\n \\x82 Break down a customer’s travel request into specific subtasks (for example, flight booking, \\nhotel reservation, or activity planning)\\n \\x82 Translate the customer’s preferences into actionable tasks for the worker agents\\n \\x82 Ensure that the tasks assigned to the worker agents are clear and unambiguous\\nThe concept of multi-agent systems isn’t new, and neither is role assignment – in fact, a study was done \\nmore than a decade ago by Kazík (2010) ( https://physics.mff.cuni.cz/wds/proc/\\npdf10/WDS10_103_i1_Kazik.pdf), which comprehensively explored role-based approaches \\nin multi-agent system development. The study highlighted how roles serve as abstract representations \\nof stereotypical behavior common to different agent classes, providing interfaces through which agents \\nobtain knowledge of and affect their environment. The study highlighted how roles serve as abstract \\nrepresentations of stereotypical behavior common to different agent classes, providing interfaces \\nthrough which agents obtain knowledge of and affect their environment. While these foundationalExploring the Coordinator, Worker, and Delegator Approach 146\\nconcepts were initially developed for traditional multi-agent systems, they provide valuable insights \\nfor designing modern LLM-based agent systems.\\nThe key principles of role-based modeling – including separation of interaction logic from inner \\nalgorithmic logic, dynamic role assignment, and modular system organization – are particularly \\nrelevant as we design collaborative LLM agents that need to coordinate effectively while maintaining \\nclear responsibilities and interaction patterns. By assigning specific roles to agents based on their \\ncapabilities and the system’s requirements, designers can achieve a role-based abstraction that supports \\nthe separation of concerns and allows for modular and reusable design in multi-agent systems. For \\nexample, in the intelligent travel agent system, agents could be assigned roles such as coordinator, \\nworker, delegator, and so on.\\nRoles and responsibilities of each agent\\nHere is an overview of the roles and responsibilities of each agent within our intelligent travel planning \\nmulti-agent system, and how they collectively work toward achieving the system’s objectives.\\n• Travel planning agent (coordinator): This agent functions as the strategic overseer of the entire \\ntravel planning operation. With expertise in project management and travel coordination, they \\nbreak down customer requests into manageable components, establish timelines, and ensure all \\naspects of travel planning align with customer expectations. They maintain a holistic view of \\neach travel plan, ensuring all elements work together cohesively while managing contingencies \\nand adjusting plans as needed.\\nTo better understand how the CWD model applies to real-world scenarios, consider the \\nexample of a travel planning agent functioning as the coordinator, as shown in the following \\nsnippet. This agent oversees the travel planning process, ensuring all components of the plan \\nalign with customer expectations while managing resources and contingencies effectively. \\nTo illustrate the functionality of core travel worker agents in the CWD model, the following \\nexample snippet showcases their specialized roles and expertise. Each agent contributes to the \\nseamless execution of specific travel planning tasks:\\ncoordinator = Agent(\\n    role=\"Travel Planning Executive\",\\n    backstory=\"A seasoned travel industry veteran with 15 years \\nof experience in luxury travel planning and project management. \\nKnown for orchestrating seamless multi-destination trips for \\nhigh-profile clients and managing complex itineraries across \\ndifferent time zones and cultures. Expert in crisis management \\nand adaptive planning.\",\\n    goals=[\"Ensure cohesive travel plans\", \"Maintain high \\ncustomer satisfaction\", \"Optimize resource allocation\"]\\n)Designing agents with role assignments 147\\n• Core travel worker agents: These agents comprise the following roles:\\n \\x82 Flight booking worker: This agent specializes in navigating the complex world of airline \\nreservations, understanding fare classes, routing rules, and alliance partnerships. It stays \\nupdated on airline schedules, pricing trends, and booking policies while maintaining \\nrelationships with airline representatives for special requests or problem resolution, as shown \\nin the following snippet:\\nflight_specialist = Agent(\\n    role=\"Aviation Booking Specialist\",\\n    backstory=\"Former airline revenue management expert with \\ndeep knowledge of global aviation networks. Skilled in finding \\noptimal flight combinations and hidden fare opportunities. Has \\nhandled over 10,000 flight bookings across all major airlines \\nand alliances.\",\\n    goals=[\"Secure optimal flight arrangements\", \"Maximize value \\nfor money\", \"Ensure booking accuracy\"]\\n)\\n \\x82 Hotel booking worker: An expert in global hospitality, this agent understands hotel categories, \\nroom types, and amenity offerings across different markets. It maintains extensive knowledge \\nof hotel loyalty programs, seasonal pricing patterns, and special promotional offers, as \\ndisplayed in the following snippet:\\nhotel_specialist = Agent(\\n    role=\"Hospitality Accommodation Expert\",\\n    backstory=\"Previous luxury hotel chain executive with \\nextensive connections in the hospitality industry. Expert in \\nboutique hotels and major chains alike, with deep knowledge of \\nroom categories, seasonal trends, and upgrade opportunities \\nacross global markets.\",\\n    goals=[\"Find perfect accommodation matches\", \"Secure best \\navailable rates\", \"Ensure special requests are met\"]\\n)\\n \\x82 Activity planning worker: This agent combines deep cultural knowledge with practical \\nexperience in tour operations. It excels at matching activities to traveler interests and \\nabilities while considering factors such as seasonal availability, local customs, and logistical \\nconstraints, as highlighted in the following snippet:\\nactivity_planner = Agent(\\n    role=\"Destination Experience Curator\",\\n    backstory=\"Professional tour guide turned experience \\ndesigner with expertise in creating memorable travel moments. \\nHas lived in 5 continents and personally vetted thousands of \\nlocal experiences. Specialist in combining cultural authenticity \\nwith traveler comfort.\",Exploring the Coordinator, Worker, and Delegator Approach 148\\n    goals=[\"Create engaging itineraries\", \"Balance activities \\nand free time\", \"Ensure cultural authenticity\"]\\n)\\n \\x82 Transportation worker: This agent focuses on ground logistics and local transportation \\nsolutions. It understands various transportation options across different destinations, from \\nprivate car services to public transportation systems, as shown in the following snippet:\\ntransport_coordinator = Agent(\\n    role=\"Ground Transportation Logistics Specialist\",\\n    backstory=\"Former urban mobility consultant with extensive \\nexperience in transportation systems worldwide. Expert in \\ncoordinating seamless transfers and creating reliable ground \\ntransportation plans across diverse global locations.\",\\n    goals=[\"Ensure reliable transfers\", \"Optimize local \\ntransportation\", \"Maintain backup options\"]\\n)\\n• Analysis and intelligence worker agents: In these agents, we have the following roles:\\n \\x82 Travel data analyst worker: This agent focuses on transforming raw travel data into actionable \\ninsights. It analyzes booking patterns, customer preferences, and market trends to inform \\ndecision-making and enhance travel recommendations, as shown here:\\nanalyst = Agent(\\n    role=\"Travel Intelligence Specialist\",\\n    backstory=\"Data scientist with deep expertise in travel \\nindustry analytics. Previously led data science initiatives at \\nmajor online travel platforms. Developed predictive models for \\ntravel trends and customer behavior that increased customer \\nsatisfaction scores by 25%. Expert in combining quantitative \\nanalysis with qualitative travel insights.\",\\n    goals=[\"Generate actionable insights\", \"Identify travel \\ntrends\", \"Optimize customer matching\"]\\n)\\n \\x82 Travel experience worker (Reflector): This agent acts as the system’s quality assurance \\nand continuous improvement specialist. It analyzes feedback, monitors performance, and \\nsuggests systemic improvements to enhance the travel planning experience, as shown here:\\nreflector = Agent(\\n    role=\"Travel Experience Optimization Expert\",\\n    backstory=\"Customer experience strategist with background in \\nboth luxury hospitality and digital transformation. Pioneered \\nfeedback analysis systems that revolutionized service delivery \\nin major hotel chains. Passionate about creating memorable \\ntravel experiences through systematic improvements.\",Designing agents with role assignments 149\\n    goals=[\"Analyze customer feedback\", \"Identify improvement \\nareas\", \"Enhance service quality\"]\\n)\\n \\x82 Travel opportunity worker (Searcher): This agent functions as the system’s explorer and \\ninnovator, constantly seeking new destinations, unique experiences, and emerging travel \\nopportunities that could enhance the service offering, as shown here:\\nsearcher = Agent(\\n    role=\"Travel Discovery Specialist\",\\n    backstory=\"Former travel journalist and destination \\nresearcher with a network spanning 100+ countries. Has uncovered \\nnumerous hidden gems and emerging destinations that became major \\ntravel trends. Combines deep cultural understanding with a \\nkeen eye for unique travel opportunities. Expert in identifying \\nexperiences that match evolving traveler preferences.\",\\n    goals=[\"Discover unique opportunities\", \"Identify emerging \\ndestinations\", \"Expand service offerings\"]\\n)\\n• Delegator agent: The critical link between strategy and execution, this agent excels at task \\nprioritization and resource allocation. They understand each worker agent’s capabilities and \\ncurrent workload, ensuring optimal task distribution and workflow management, as shown here:\\ndelegator = Agent(\\n    role=\"Travel Operations Orchestrator\",\\n    backstory=\"Experienced project manager with a background \\nin both travel operations and workflow optimization. Known for \\nexceptional ability to match tasks with the right expertise and \\nmaintain balanced workloads across teams. Previously managed \\nlarge-scale travel operations for Fortune 500 companies.\",\\n    goals=[\"Optimize task distribution\", \"Maintain workflow \\nefficiency\", \"Ensure quality standards\"]\\n)\\nSo far, this structured role-based agent approach creates a well-defined hierarchy with clear responsibilities \\nwhile maintaining flexibility for handling complex travel planning scenarios. Each agent’s role and \\nbackstory provide depth and context to their function within the larger system, enabling more natural \\nand effective interactions. Let’s define the Manager, Analyst, Reflector, and Searcher agents. Figure 6.3 \\nis a further adaptation of our CWD model with role-based agents for the travel planning system:Exploring the Coordinator, Worker, and Delegator Approach 150\\nFigure 6.3 – Role-based agents within the CWD model for travel planner\\nLet’s examine how our travel planning multi-agent system orchestrates a seamless journey from \\ninitial customer request to final travel plan. The system leverages a hierarchical structure where the \\ncoordinator agent provides strategic oversight, the delegator agent manages task distribution, and \\nspecialized worker agents execute both core travel tasks and analytical functions in parallel. This \\ncoordinated workflow demonstrates the practical application of the CWD model, enabling efficient \\nand intelligent travel planning through clear role definition and effective collaboration. Here’s the \\nbreakdown of the steps:\\n1. Initial request and planning:\\nI. The customer submits their travel requirements to the system.\\nII. The coordinator agent analyzes these requirements and develops a strategic plan.\\n2. Task distribution:\\nI. The coordinator agent passes the strategic plan to the delegator agent.\\nII. The delegator agent breaks down the plan into specific tasks for both core and \\nanalysis workers.\\n3. Parallel processing (core travel tasks): The delegator agent assigns specialized tasks to core \\ntravel workers, as follows:\\n \\x82 The flight booking worker searches for and reserves optimal flights\\n \\x82 The hotel booking worker identifies and books suitable accommodations\\n \\x82 The activity planning worker creates an itinerary of experiences\\n \\x82 The transportation worker arranges ground transport solutionsCommunication and collaboration between agents 151\\n4. Parallel processing (analysis and intelligence): Simultaneously, the delegator agent engages \\nanalysis workers, as follows:\\n \\x82 The data analyst worker processes customer data and travel patterns\\n \\x82 The experience reflector worker reviews similar past itineraries\\n \\x82 The opportunity searcher worker identifies unique options/alternatives\\n5. Integration and refinement:\\nI. All workers submit their outputs back to the delegator agent.\\nII. The delegator agent consolidates the information.\\nIII. The coordinator agent receives the consolidated plan.\\n6. Final review and delivery:\\nI. The coordinator agent reviews and optimizes the complete travel plan.\\nII. The final travel plan is presented to the customer.\\nThis flow showcases the collaboration between the various agent roles, leveraging their specialized \\nexpertise and contributions to generate a personalized and optimized travel plan for the customer. \\nEach agent plays a specific role, and their outputs are consolidated and integrated by the Manager \\nagent (travel operations manager) and the coordinator agent (travel planning coordinator) to deliver \\nthe final travel plan.\\nBy carefully designing agents with well-defined roles, the CWD-based multi-agent system can effectively \\ncollaborate, leverage specialized expertise, and distribute tasks efficiently, ultimately delivering \\npersonalized and optimized travel plans tailored to customer requirements. However, the success \\nof such a sophisticated multi-agent system heavily depends on how these agents communicate and \\ninteract with each other. Let’s explore how effective communication and collaboration are achieved \\nbetween these agents in the next section.\\nCommunication and collaboration between agents\\nIn multi-agent systems based on the CWD model, effective communication and collaboration \\namong agents are crucial for achieving successful outcomes. Agents need to be capable of sharing \\ninformation, coordinating their actions, and behaving cooperatively to work toward common goals. \\nCommunication and collaboration in CWD-based systems involve the key aspects as discussed in \\nthe following subsections.Exploring the Coordinator, Worker, and Delegator Approach 152\\nCommunication\\nAgents should follow well-defined protocols for their interactions, including the format of messages \\nand interaction patterns. These protocols ensure that agents can understand each other clearly and act \\nappropriately. For example, in a travel agent system, the agents may employ a standardized message \\nformat and communication protocol to exchange information about flight options, hotel availability, \\nor customer preferences. By adhering to these protocols, agents can effectively communicate and \\ninterpret messages from other agents, enabling seamless collaboration.\\nThe agents in the example travel agent system can follow a standardized communication protocol, \\nsuch as the FIPA Agent Communication Language (ACL), to exchange messages and information. \\nFor instance, when the hotel booking worker agent needs to communicate with the flight booking \\nworker agent to coordinate travel dates, it can send a message in the FIPA ACL format, specifying the \\ncontent (for example, requested travel dates), the sender (hotel booking worker), and the recipient \\n(flight booking worker).\\nCoordination mechanism\\nCoordinators play a vital role in establishing mechanisms for coordination that align the activities of \\nworker agents with the overall objectives of the system. These coordination mechanisms allow for the \\ncontrol of dependencies and ensure that tasks are completed within the required timeframes. In the \\ncontext of a travel agent system, the travel planning coordinator agent could implement a coordination \\nmechanism that involves task prioritization, resource allocation, and progress monitoring to ensure \\nthat the travel planning process proceeds smoothly and efficiently.\\nThe travel planning coordinator agent can implement a coordination mechanism to align the activities \\nof the worker agents with the overall travel planning objectives. For example, it could employ a task \\nprioritization mechanism based on customer preferences or travel dates. If a customer prioritizes \\nfinding suitable accommodations first, the coordinator agent can instruct the delegator agent to assign \\nthe hotel booking worker agent a higher priority than the other worker agents. Additionally, the \\ncoordinator agent can monitor the progress of each worker agent and reallocate resources or adjust \\npriorities as needed to ensure timely task completion.\\nNegotiation and conflict resolution\\nIn complex multi-agent systems, there may be cases where the goals or actions of different agents \\nconflict with one another. To address such situations, agents should be equipped with negotiation \\nstrategies or mechanisms for conflict resolution. These strategies help maintain harmony in the working \\nenvironment by facilitating compromise or reaching mutually acceptable solutions. For instance, if \\nmultiple worker agents in a travel agent system propose conflicting activity plans or transportation \\noptions, a negotiation mechanism could be employed to resolve the conflict based on predefined \\ncriteria or by involving the coordinator agent for mediation.Communication and collaboration between agents 153\\nSuppose the activity planning worker agent and the transportation worker agent propose conflicting \\nplans for a particular day of the trip. The activity planning worker agent might have scheduled a full-\\nday tour, while the transportation worker agent has arranged for a rental car to be available for the \\nentire day. In such a scenario, a negotiation mechanism can be employed to resolve the conflict. The \\ndelegator agent could act as a mediator, gathering the conflicting plans from both worker agents and \\nproposing alternative solutions, such as rescheduling the tour or modifying the rental car reservation. \\nIf a resolution cannot be reached, the coordinator agent can intervene and make a final decision based \\non predefined criteria or customer preferences.\\nKnowledge sharing\\nAgents should have the capability to share knowledge, insights, and findings from their research or \\nexperiences with other agents in the system. This knowledge-sharing facilitates continuous learning \\nand adaptation, enabling the system to improve its overall performance over time. In the travel agent \\ncontext, the travel data analyst agent could share insights derived from customer preference analysis \\nwith other agents, enabling them to make more informed decisions. Similarly, the travel opportunity \\nsearcher agent could share information about new travel destinations or emerging trends, allowing \\nthe system to stay up-to-date and adapt its offerings accordingly.\\nThe travel data analyst agent can analyze customer preferences, travel trends, and feedback from past \\ntrips to generate insights and recommendations. These insights can be shared with other agents in \\nthe system to improve their decision-making processes. For example, the travel data analyst agent \\nmight identify a growing trend for eco-friendly travel options and share this information with the \\nactivity planning worker agent and the transportation worker agent. These agents can then adjust their \\nofferings to include more sustainable activities and transportation options, reflecting the changing \\ncustomer preferences. The travel opportunity searcher agent may continuously explore new travel \\ndestinations, unique experiences, or emerging travel trends. This agent can share its findings with \\nother agents, enabling them to incorporate these new opportunities into their respective planning \\nprocesses. For instance, if the travel opportunity searcher agent discovers a newly opened eco-resort \\nin a popular destination, it can share this information with the hotel booking worker agent and the \\nactivity planning worker agent, allowing them to consider this new option when generating hotel \\nrecommendations and activity plans.\\nThe CWD model’s role-based approach establishes clear boundaries for communication channels and \\nagent responsibilities. By implementing well-defined protocols for communication, coordination, and \\nknowledge sharing, the system harnesses its agents’ collective intelligence to deliver adaptable and \\nefficient travel planning services. This structured collaboration enables the system to tackle complex \\nchallenges while continuously improving its performance over time.Exploring the Coordinator, Worker, and Delegator Approach 154\\nWhile this section has outlined the theoretical framework for communication and collaboration in our \\nCWD-based travel planning system, the practical implementation requires careful consideration of \\ntechnical aspects. This section has provided a comprehensive exploration of the foundational aspects of \\ncommunication and collaboration within multi-agent systems guided by the CWD model. By adhering \\nto well-defined communication protocols, establishing robust coordination mechanisms, and fostering \\neffective knowledge sharing, such systems are equipped to handle complex, dynamic scenarios.\\nThe next section transitions from these foundational concepts to a deeper exploration of practical \\nmethodologies. It focuses on implementing the CWD approach in generative AI systems, detailing \\nadvanced techniques such as state space management, environment modeling, memory systems, and \\nhandling LLM contexts to bring these theoretical concepts to life in real-world applications.\\nImplementing the CWD approach in generative AI systems\\nWhile we’ve explored how the CWD model maps to LLM-based agents and discussed role adaptations \\nfor our travel planning system, implementing this approach in generative AI systems requires careful \\nattention to several technical considerations. The transition from traditional multi-agent systems to \\nLLM-based implementations brings unique challenges and opportunities. LLMs, with their natural \\nlanguage understanding and generation capabilities, offer new ways to implement agent behaviors \\nand interactions but also require specific architectural considerations to maintain the structured \\napproach of the CWD model.\\nIn traditional multi-agent systems, behaviors and interactions are typically programmed explicitly \\nthrough code. However, in LLM-based implementations, these aspects are primarily controlled through \\ncarefully crafted prompts and interaction patterns. This fundamental difference requires us to adapt \\nthe CWD model’s principles to work effectively with the nature of LLMs while maintaining the clear \\nrole boundaries and hierarchical structure we’ve discussed.\\nBefore diving into the technical details that will be covered in the next chapter, let’s examine three \\nkey implementation considerations that form the foundation of any LLM-based CWD system. These \\nconsiderations – system prompts, instruction formatting, and interaction patterns – are essential for \\ntranslating our theoretical model into a practical, functioning system.\\nSystem prompts and agent behavior\\nSystem prompts act as the fundamental configuration layer for LLM agents, defining their core \\ncharacteristics and operational parameters. Unlike regular prompts that provide task-specific \\ninstructions, system prompts establish an agent’s persistent traits, boundaries, and behavioral \\nframeworks throughout its operational life cycle. In our travel planning system, each agent’s system \\nprompt must encompass the following:\\n• Role definition and scope of responsibilities\\n• Constraints and operational boundariesImplementing the CWD approach in generative AI systems 155\\n• Communication protocols with other agents\\n• Decision-making frameworks specific to their role\\nFor example, the flight booking worker’s system prompt would include specific instructions about \\nflight search parameters, pricing considerations, and airline partnerships, while the Coordinator’s \\nsystem prompt would focus on high-level planning and oversight capabilities.\\nWe saw earlier how LLM agent frameworks such as CrewAI structure system prompts through role \\nand backstory definitions. The role component defines the agent’s functional boundaries and \\nresponsibilities, while backstory provides the context and expertise that shapes how the agent \\napproaches these responsibilities. Together, they create a rich system prompt that guides the agent’s \\nbehavior and decision-making process. For instance, an agent’s role might be an aviation booking \\nspecialist, while its backstory as a “former airline revenue management expert with deep knowledge of \\nglobal aviation networks” helps it make more nuanced decisions about routing and pricing options.\\nInstruction formatting\\nClear and consistent instruction formatting ensures reliable agent performance and effective inter-\\nagent communication. This becomes particularly crucial in LLM-based systems where instructions \\nare interpreted through natural language understanding. Key aspects of instruction formatting include \\nthe following:\\n• Input structuring: Standardized formats for task assignments and requests. For example, the \\nfollowing structured input format ensures the flight booking worker receives unambiguous \\nsearch parameters, with clear specifications for departure and destination locations along with \\ndesired travel dates:\\n{\\n  \"task_type\": \"flight_search\",\\n  \"parameters\": {\\n    \"departure\": \"location\",\\n    \"destination\": \"location\",\\n    \"dates\": \"date_range\"\\n  }\\n}\\n• Output templates: Consistent response structures that other agents can reliably parse. The \\nstandardized output format allows agents to quickly identify the task status and access relevant \\ninformation. The options array might contain available flights, while recommendations \\ncould include preferred choices based on customer preferences:\\n{\\n    \"status\": \"completed/failed\",\\n    \"result\": {Exploring the Coordinator, Worker, and Delegator Approach 156\\n        \"options\": [...],\\n        \"recommendations\": [...],\\n        \"constraints\": [...]\\n    }\\n}\\n• Communication protocols: Clear formats for inter-agent messages and status updates. These \\nprotocols ensure transparent communication between agents, with clear identification of \\nmessage type, sender, and recipient, along with structured content that can be easily processed:\\n{\\n  \"message_type\": \"update\",\\n  \"sender\": \"flight_booking_worker\",\\n  \"recipient\": \"coordinator\",\\n  \"content\": {\\n    \"progress\": \"in_progress\",\\n    \"completion\": \"60%\",\\n    \"pending_tasks\": [...]\\n  }\\n}\\nInteraction patterns\\nThe success of a CWD-based system heavily depends on well-defined interaction patterns between \\nagents. In an LLM-based implementation, these patterns must account for the unique characteristics \\nof language model interactions. Essential interaction patterns include the following:\\n• Message passing protocols:\\n \\x82 Structured formats for agent-to-agent communication\\n \\x82 Clear handoff procedures between different processing stages\\n \\x82 Error handling and recovery mechanisms\\n• State management:\\n \\x82 How agents maintain awareness of their current task status\\n \\x82 Methods for tracking progress through multi-step processes\\n \\x82 Coordination of parallel activitiesSummary 157\\n• Feedback loops:\\n \\x82 How agents communicate success/failure\\n \\x82 Methods for requesting clarification or additional information\\n \\x82 Mechanisms for continuous improvement through interaction history\\nSummary\\nIn this chapter, we explored the CWD model as a framework for designing effective multi-agent \\nsystems. Starting with the foundational concepts from early role-based research, we saw how these \\nprinciples adapt perfectly to modern LLM-based agent architectures. We examined this through a \\npractical travel planning system, where different agents – from flight bookers to activity planners – \\nwork together under a clear hierarchical organization. Key takeaways highlight the importance of \\nwell-defined roles and responsibilities within multi-agent systems, ensuring that each agent operates \\nwith clarity and purpose. They emphasize how specialized worker agents collaborate effectively \\nunder the oversight of coordinators, who align their efforts with overarching goals. Delegators play \\na crucial role in managing tasks and facilitating smooth workflow distribution. Additionally, the \\nchapter underscored the significance of effective communication and collaboration patterns, which \\nare essential for seamless information exchange and cooperative behavior among agents. Finally, \\nimplementation considerations such as designing system prompts and formatting instructions are \\ncritical for operational success, ensuring clarity and consistency in agent interactions.\\nThis structured approach to agent design enables complex tasks to be broken down and executed \\nefficiently while maintaining clear lines of communication and responsibility. Our travel planning \\nexample demonstrated how theoretical concepts translate into practical applications.\\nIn the next chapter, we will dive deeper and explore how we can effectively design agents in real life.\\nQuestions\\n1. Explain how the CWD model enhances the efficiency of multi-agent systems, using the travel \\nplanning system as an example.\\n2. What is the significance of “role” and “backstory” in LLM agent design, and how do they \\ncontribute to system prompts? Provide an example.\\n3. Compare and contrast the core travel workers with analysis and intelligence workers in the \\ntravel planning system. How do their functions complement each other?\\n4. Describe the key aspects of communication and collaboration in a CWD-based system, including \\nprotocols, coordination mechanisms, and knowledge sharing.\\n5. How does instruction formatting contribute to effective agent communication in an LLM-based \\nsystem? Explain with examples of input and output structures.Exploring the Coordinator, Worker, and Delegator Approach 158\\nAnswers\\n1. The CWD model enhances efficiency by creating a clear hierarchical structure where the coordinator \\nprovides strategic oversight, the delegator manages task distribution, and specialized workers \\nexecute specific functions. In the travel planning system, this allows for parallel processing \\nof tasks – while core travel workers handle bookings and arrangements, analysis workers \\nsimultaneously process data and search for opportunities. This structured approach ensures \\nefficient task completion while maintaining clear lines of responsibility and communication.\\n2. Roles and backstories are crucial components in LLM agent design that form the system \\nprompt. The role defines an agent’s functional boundaries and responsibilities (for example, \\naviation booking specialist), while the backstory provides context and expertise that shapes \\ndecision-making (for example, “former airline revenue management expert with deep knowledge \\nof global aviation networks”). Together, they create a rich system prompt that guides the agent’s \\nbehavior and interaction patterns. For example, the flight booking worker’s role and backstory \\nenable it to make sophisticated decisions about routing and pricing based on its “experience” \\nin airline operations.\\n3. Core travel workers (flight, hotel, activity, and transportation workers) handle the practical \\naspects of travel arrangements, making bookings, and confirming reservations. In contrast, \\nanalysis and intelligence workers (data analyst, experience reflector, and opportunity searcher) \\nprovide strategic support by analyzing trends, processing feedback, and identifying new \\nopportunities. While core workers execute immediate tasks, analysis workers enhance the \\nsystem’s decision-making capabilities and future performance through data-driven insights \\nand continuous improvement.\\n4. Communication and collaboration in CWD systems involve several key components: standardized \\ncommunication protocols (such as FIPA ACL) ensure clear message exchange between agents; \\ncoordination mechanisms allow the coordinator to manage dependencies and timelines; \\nnegotiation strategies help resolve conflicts between agents (such as conflicting activity and \\ntransportation plans); and knowledge sharing enables continuous system improvement through \\nshared insights and experiences. These elements work together to create a cohesive and efficient \\nmulti-agent system.\\n5. Instruction formatting in LLM-based systems ensures reliable agent communication through \\nstructured input/output patterns. This standardized formatting ensures unambiguous \\ncommunication between agents, clear task specifications, and easily parseable results, contributing \\nto the system’s overall efficiency and reliability.Join our communities on Discord and Reddit 159\\nJoin our communities on Discord and Reddit\\nHave questions about the book or want to contribute to discussions on Generative AI and LLMs? \\nJoin our Discord server at https://packt.link/I1tSU and our Reddit channel at https://\\npackt.link/ugMW0 to connect, share, and collaborate with like-minded enthusiasts.7\\nEffective Agentic System \\nDesign Techniques\\nIn the previous chapter, we explored the coordinator-worker-delegator (CWD) model, a robust \\nfoundation for multi-agent system design that emphasizes cooperation and division of labor. We delved \\ninto the three distinct roles – coordinators, workers, and delegators –  and discussed the intricate \\ndetails of their interactions and contributions to effective task distribution.\\nThis chapter begins by establishing the importance of system prompts and focused instructions as the \\nfoundation of agent behavior. It then explores the critical concepts of state space representation and \\nenvironment modeling that agents operate within. The chapter proceeds to examine agent memory \\narchitectures and context management strategies, essential for maintaining coherent agent behavior \\nacross interactions. Finally, it covers advanced workflow patterns, including sequential and parallel \\nprocessing approaches for LLM-based agent systems. This chapter is divided into four main sections:\\n• Focused system prompts and instructions for agents\\n• State spaces and environment modeling\\n• Agent memory architecture and context management\\n• Sequential and parallel processing in agentic workflows\\nBy the end of this chapter, you will have gained a comprehensive understanding of how to design \\nrobust, scalable, and effective agentic systems that can handle complex tasks while maintaining \\nconsistent behavior and performance.\\nTechnical requirements\\nY ou can find the code files for this chapter on GitHub at https://github.com/PacktPublishing/\\nBuilding-Agentic-AI-Systems.Effective Agentic System Design Techniques 162\\nFocused system prompts and instructions for agents\\nFocused instruction plays a crucial role in directing the actions of an intelligent agent. It lays down \\nthe objective of the agent, its constraints, and the operating context. The clarity and explicitness of \\nthese instructions often significantly influence the agent’s performance in achieving its intended goals.\\nDefining objectives\\nDefining clear objectives is a critical aspect of focused instruction for intelligent agents. Well-defined \\nobjectives serve as the foundation from which an agent’s intended functions and behaviors are derived, \\nguiding its actions and decision-making processes toward achieving specific goals.\\nTo put this into perspective, let’s continue our discussion with the example of our intelligent travel \\nagent placed in a customer service role. The objective would be to maximize customer satisfaction by \\nproviding personalized travel solutions and resolving any queries or issues effectively. This overarching \\nobjective encompasses several key components:\\n• Personalization: The travel agent must tailor its recommendations and solutions to the unique \\npreferences, budgets, and requirements of each individual customer. This involves gathering \\ndetailed information about the customer’s travel goals, interests, and constraints and using this \\nknowledge to craft customized itineraries and experiences.\\n• Problem-solving: In addition to planning travel arrangements, the agent should be equipped \\nto address any queries, concerns, or issues that may arise throughout the customer’s journey. \\nThis could involve resolving booking conflicts, providing guidance on travel advisories, or \\noffering alternative solutions in case of disruptions or changes in plans.\\n• Effective communication : Maximizing customer satisfaction requires the travel agent to \\ncommunicate clearly and effectively, ensuring that customers understand the proposed solutions, \\npotential trade-offs, and any relevant details or recommendations. Clear communication also \\ninvolves active listening and interpreting customer feedback or concerns accurately.\\n• Continuous improvement: By closely monitoring customer satisfaction levels and gathering \\nfeedback, the travel agent can iteratively refine its capabilities and approach. This feedback loop \\nallows the agent to identify areas for improvement, adapt to changing customer preferences or \\nindustry trends, and continuously enhance the quality of its solutions and service.\\nHaving well-defined objectives provides a clear benchmark against which the agent’s performance \\ncan be evaluated. In the case of the intelligent travel agent, metrics such as customer satisfaction \\nratings, successful resolution of queries or issues, and the overall quality of personalized travel plans \\ncan be used to assess the agent’s effectiveness in achieving its primary objective. Additionally, these \\nobjectives guide the agent’s decision-making processes, prioritizing actions and solutions that align \\nwith maximizing customer satisfaction while adhering to constraints such as budget, time, or logistical \\nlimitations. A sample may look like the following:Focused system prompts and instructions for agents 163\\nObjective: Act as an expert travel agent to provide personalized travel solutions while \\nmaximizing customer satisfaction.\\nCore functions:\\n- Gather and analyze travel preferences, constraints, and budget\\n- Create personalized travel recommendations and itineraries\\n- Resolve travel-related issues and provide alternatives\\n- Communicate clearly and professionally\\n- Monitor customer satisfaction and adapt accordingly\\nConstraints:\\n- Stay within stated budget\\n- Prioritize customer safety\\n- Follow travel regulations\\n- Respect booking deadlines\\nBehavior:\\n- Use clear, professional language\\n- Show empathy and patience\\n- Anticipate customer needs\\n- Provide transparent pricing\\n- Present options with pros/cons\\n- Document key requirements and deadlines\\nTask specifications\\nDetailed task specifications help intelligent agents with a clear understanding of their duties and \\nresponsibilities. By detailing the specific steps to follow, expected outputs, and potential challenges \\nassociated with a particular task, task specifications enable agents to operate effectively and efficiently. \\nContinuing our intelligent travel agent example, task specifications are essential for ensuring that the \\nagent can successfully navigate the various aspects of the travel planning process.Effective Agentic System Design Techniques 164\\nHere are a couple of examples of how task specifications can be defined for different components of \\nthe travel agent’s responsibilities:\\n• Customer interaction and inquiry handling (steps are as follows):\\nI. Greet the customer.\\nII. Gather relevant information (travel preferences, budget, dates, etc.).\\nIII. Identify the nature of the inquiry or request.\\nIV . Provide appropriate responses or solutions.\\nV. Confirm customer satisfaction.\\n \\x82 Expected outputs: Clear and concise responses to customer inquiries, personalized travel \\nrecommendations or itineraries, booking confirmations or updates.\\n \\x82 Potential challenges:\\n \\x8f Ambiguous or incomplete customer requests\\n \\x8f Language barriers\\n \\x8f Conflicting preferences or constraints\\n \\x8f Handling emotional or dissatisfied customers.\\n• Flight and accommodation booking:\\n \\x82 Steps: Search for available flights and accommodations based on customer preferences, \\ncompare options based on factors such as price, duration, amenities, and customer ratings, \\npresent the top choices to the customer, and confirm and book the selected options.\\n \\x82 Expected outputs: Confirmed flight and hotel bookings, itinerary with travel details, invoices, \\nor payment receipts.\\n \\x82 Potential challenges: Limited availability, fluctuating prices, handling changes or cancellations, \\nmanaging groups or special accommodations.\\nProviding detailed task specifications helps the intelligent travel agent understand the specific steps \\ninvolved in each aspect of the travel planning process, the expected outputs or deliverables, and the \\npotential challenges that may arise. This knowledge equips the agent with the necessary guidance to \\nhandle various situations effectively, anticipate and mitigate potential issues, and, ultimately, deliver \\na seamless and personalized travel experience for customers.Focused system prompts and instructions for agents 165\\nA sample task specification for the flight inquiry may look like the following:\\n1. Initial query:\\n \\x82 Capture departure/arrival locations\\n \\x82 Get preferred dates and time ranges\\n \\x82 Note any special requirements (class, layovers, airlines)\\n \\x82 Confirm budget constraints\\n2. Search process:\\n \\x82 Search available flights matching criteria\\n \\x82 Filter by price range and preferences\\n \\x82 Sort by best match (price/duration/stops)\\n \\x82 Check seat availability\\n3. Presentation:\\n \\x82 Show the top three flight options\\n \\x82 Display price, duration, and layovers\\n \\x82 Highlight unique features/restrictions\\n \\x82 Note cancellation policies\\n• Outputs:\\n \\x82 Flight comparison summary\\n \\x82 Booking confirmation\\n \\x82 Travel advisory notices\\nContextual awareness\\nContextual awareness forms the backbone of intelligent agent behavior, enabling them to operate \\neffectively within their designated environments and adapt to changing situations. This awareness \\nextends beyond simple task execution – it encompasses understanding the environment, user needs, \\nand situational nuances that influence decision-making. At its core, contextual awareness is about \\nunderstanding and responding to the full scope of circumstances that surround any given interaction \\nor decision point.Effective Agentic System Design Techniques 166\\nFor our intelligent travel agent, contextual awareness manifests in several critical dimensions. Consider \\nhow the agent must maintain awareness of both global and local contexts – from international travel \\nrestrictions and seasonal weather patterns to specific hotel policies and local transportation options. \\nThis multi-layered awareness allows the agent to make informed decisions and provide personalized \\nrecommendations that truly serve the customer’s needs. The following figure demonstrates how the \\ndifferent layers of contextual awareness might be integrated within an agentic system.\\nFigure 7.1 – Contextual awareness within an intelligent agentic system\\nThe depth of contextual awareness can be illustrated through a few key examples from the travel domain:\\n• Destination intelligence: The agent maintains comprehensive knowledge of travel destinations, \\nincluding peak seasons, local events, and cultural significance. When a customer expresses \\ninterest in visiting Japan, for instance, the agent doesn’t just book flights – it considers cherry \\nblossom seasons, major festivals, and regional weather patterns to suggest optimal travel dates \\nand experiences.\\n• Dynamic adaptation : Contextual awareness enables real-time adaptation to changing \\ncircumstances. If a flight is canceled due to weather conditions, the agent doesn’t simply relay \\nthis information – it immediately assesses alternative routes, considers the impact on subsequent \\nbookings, and proposes solutions based on the customer’s preferences and constraints.\\n• Cultural competence: Understanding cultural norms and local customs is crucial for providing \\nmeaningful travel recommendations. This might involve advising customers about appropriate \\ndress codes for religious sites, suggesting restaurants that accommodate specific dietary restrictions, \\nor recommending local customs that visitors should be aware of to ensure respectful interactions.State spaces and environment modeling 167\\nThe agent can anticipate needs, avoid potential issues, and craft truly personalized travel experiences \\nby integrating these aspects of contextual awareness. This goes beyond simple pattern matching – it \\nrequires a nuanced understanding of how different contextual elements interact and influence the \\noverall travel experience. The true value of contextual awareness lies in its ability to transform standard \\nservice interactions into thoughtfully curated experiences. When an agent combines knowledge of \\ndestination specifics, customer preferences, and situational factors, it can deliver recommendations \\nand solutions that feel both personal and practical.\\nState spaces and environment modeling\\nState spaces and environment modeling form the foundation of how intelligent agents perceive, \\nunderstand, and interact with their operational context. This section explores the crucial aspects \\nof designing and implementing effective state representations and environment models that enable \\nagents to make informed decisions and maintain consistent behavior.\\nState space representation\\nState space representation defines how an agent maintains and updates its understanding of the \\ncurrent situation, available actions, and potential outcomes. A well-designed state space enables an \\nagent to track relevant information while avoiding unnecessary complexity. For our intelligent travel \\nagent example, the state space might include the following:\\n• Customer profile state:\\n \\x82 Personal preferences and constraints\\n \\x82 Travel history and feedback\\n \\x82 Current interaction context\\n \\x82 Budget parameters and flexibility\\n \\x82 Special requirements or accommodations\\n• Travel context state:\\n \\x82 Available flight options and pricing\\n \\x82 Hotel availability and rates\\n \\x82 Weather conditions and forecasts\\n \\x82 Travel advisories and restrictions\\n \\x82 Seasonal events and peak periodsEffective Agentic System Design Techniques 168\\n• Booking state:\\n \\x82 Reservation status and confirmations\\n \\x82 Payment information and status\\n \\x82 Cancellation policies and deadlines\\n \\x82 Itinerary modifications and updates\\n \\x82 Connection dependencies\\nThe state space should be designed to capture both static and dynamic elements while maintaining \\nefficiency. For instance, the agent might represent the flight booking state flight, hotel, and customer \\npreferences as follows:\\n{\\n    \"booking_id\": \"BK123456\",\\n    \"status\": \"confirmed\",\\n    \"components\": {\\n        \"flights\": [{\\n            \"status\": \"confirmed\",\\n            \"departure\": \"2024-05-15T10:00:00\",\\n            \"cancellation_deadline\": \"2024-05-01\",\\n            \"dependencies\": [\"hotel_check_in\"]\\n        }],\\n        \"hotels\": [{\\n            \"status\": \"pending\",\\n            \"check_in\": \"2024-05-15\",\\n            \"cancellation_policy\": \"48h_notice\"\\n        }]\\n    },\\n    \"customer_preferences\": {\\n        \"seat_type\": \"window\",\\n        \"meal_requirements\": \"vegetarian\",\\n        \"room_preferences\": [\"high_floor\", \"non_smoking\"]\\n    }\\n}\\nThe state consists of the status of the booking and the component of the itinerary such as flight status, \\nhotel confirmation, as well as any other specific user preferences for the user.\\nWhile states provide the “moment in time” representation or knowledge about a specific task, the \\nlarger environment in which the environment operates is also critical. Such an environment often \\nincludes details of the tools the agent has access to, any specific policies or rules it needs to adhere \\nto, and other details based on the specific use case. Let’s discuss what environment modeling entails \\nin the next section.State spaces and environment modeling 169\\nEnvironment modeling\\nEnvironment modeling is a critical component of intelligent agent design that involves creating a \\ndetailed representation of the world in which the agent operates. This representation serves as the \\nagent’s understanding of its operational context, encompassing everything from external systems it \\nmust interact with to real-world conditions that affect its decision-making. At its core, environment \\nmodeling addresses three fundamental questions:\\n• What systems and services can the agent interact with?\\n• What rules and constraints govern these interactions?\\n• What changing conditions must the agent monitor and respond to?\\nFor instance, in our travel agent system, the environment model must represent the agent’s connections \\nto airline booking systems, hotel reservation platforms, and payment processors. It must also encode \\nbusiness rules about booking procedures and maintain awareness of dynamic factors such as price \\nchanges and availability. A well-designed environment model enables the agent to do the following:\\n• Make informed decisions based on current conditions\\n• Navigate complex systems and processes effectively\\n• Respond appropriately to changes in its operational context\\n• Maintain compliance with rules and regulations\\n• Optimize outcomes within given constraints\\nThe environment model should capture both static rules that rarely change and dynamic elements that \\nrequire constant monitoring. Let’s understand the static and dynamic elements in detail:\\n• Static environment elements : Static elements represent the unchanging aspects of the \\nenvironment that govern the agent’s operation:\\n \\x82 Business rules and constraints:\\n \\x8f Booking policies and procedures\\n \\x8f Payment processing requirements\\n \\x8f Cancellation and modification rules\\n \\x8f Service level agreements\\n \\x8f Regulatory compliance requirementsEffective Agentic System Design Techniques 170\\n \\x82 System interfaces:\\n \\x8f API endpoints and specifications\\n \\x8f Database schemas and relationships\\n \\x8f Authentication mechanisms\\n \\x8f Error handling protocols\\n \\x8f Rate limits and quotas\\n• Dynamic environment elements: Dynamic elements represent the changing aspects of the \\nenvironment that require real-time monitoring and adaptation:\\n \\x82 Resource availability:\\n \\x8f Real-time inventory levels\\n \\x8f Pricing fluctuations\\n \\x8f Service disruptions\\n \\x8f Weather conditions\\n \\x8f Local events and circumstances\\n \\x82 System performance:\\n \\x8f Response times and latency\\n \\x8f Error rates and failures\\n \\x8f Resource utilization\\n \\x8f Queue lengths and processing times\\n \\x8f System health indicators\\nThe environment in which an agent operates dictates how effectively the agent can complete a given \\ntask. Careful consideration must be given while modeling an environment for an agent. Too many \\nintegration points and system interactions may create an overtly complex agentic system. A common \\nway to mitigate this is to use a number of different purpose-built agents that are very good at completing \\none or two tasks effectively, and then have multiple agents coordinate to accomplish the final goal. \\nThis method will become more apparent when we discuss sequential and parallel workflows later in \\nthe chapter. Before we get there, let’s discuss how these multiple agents may interact and integrate \\nwith each other.State spaces and environment modeling 171\\nIntegration and interaction patterns\\nThe success of state space and environment modeling relies heavily on effective integration patterns that \\nenable smooth interaction between different components. Two critical patterns emerge in managing \\nthese interactions effectively:\\n• Event-driven updates: This pattern allows the agent to respond dynamically to changes in its \\nenvironment. Rather than constantly polling for changes, the agent receives and processes events \\nas they occur. For example, when an airline updates a flight status or a hotel room becomes \\nunavailable, these events trigger immediate updates to the agent’s state, enabling real-time \\nresponses to changing conditions. The following code demonstrates how an agent handles \\nevents that affect a travel booking’s state. The TravelAgentState class contains a method \\nthat processes different types of events and updates the system accordingly. Example code for \\ntwo of the possible events (flight change and weather alert) may look as follows:\\nclass TravelAgentState:\\n    def update_booking_status(self, event):\\n        if event.type == \"FLIGHT_CHANGE\":\\n            self.check_dependencies()\\n            self.notify_customer()\\n        elif event.type == \"WEATHER_ALERT\":\\n            self.evaluate_alternatives()\\n            self.update_recommendations()\\n        ...\\nLet’s look at an example of an airline changing a flight time from 10 AM to 2 PM:\\nI. The system receives a \"FLIGHT_CHANGE\" event.\\nII. The update_booking_status method processes this event.\\nIII. It checks whether the new flight time affects hotel bookings or transfers.\\nIV . It automatically notifies the customer about the change.\\nSimilarly, this example shows a severe weather alert issued for the destination:\\nI. The system receives a \"WEATHER_ALERT\" event.\\nII. The method evaluates whether the weather will affect travel plans.\\nIII. It identifies alternative dates or destinations if needed.\\nIV . It updates the recommendations provided to the customer.\\n• State validation and consistency: This pattern ensures that the agent’s understanding of its \\nenvironment remains accurate and reliable. It involves checking that state transitions are valid, \\ndependencies are maintained, and business rules are followed. For instance, before confirming \\na hotel booking, the agent must validate that the dates align with flight arrangements and that \\nthe booking complies with cancellation policies. The following code demonstrates how toEffective Agentic System Design Techniques 172\\nimplement robust state validation to ensure booking integrity and business rule compliance. \\nThis validation system acts as a gatekeeper, checking that all state changes are valid before \\nthey’re applied:\\ndef validate_state_transition(current_state, new_state):\\n    if not is_valid_transition(current_state, new_state):\\n        raise InvalidStateTransition(\"Invalid transition from \\n{current_state} to {new_state}\")\\n    check_state_dependencies(new_state)\\n    validate_business_rules(new_state)\\nHere’s how this validation works in practice:\\n1. Transition validation example:\\n \\x82 Current state: \"on hold\" (for flight booking)\\n \\x82 New state: \"confirmed\"\\n \\x82 System checks the following:\\n \\x8f Is payment received?\\n \\x8f Are seats still available?\\n \\x8f Is the price still valid?\\n2. Dependency checking example:\\n \\x82 Booking includes flight and hotel\\n \\x82 System verifies the following:\\n \\x8f Hotel check-in time is after flight arrival\\n \\x8f Transfer service availability matches flight time\\n \\x8f Room type matches the number of travelers\\n3. Business rules example:\\n \\x82 International booking is being made\\n \\x82 System ensures the following:\\n \\x8f Passport information is provided\\n \\x8f Travel insurance is offered\\n \\x8f Cancellation policy is acknowledgedAgent memory architecture and context management 173\\nIf any validation step fails, the system prevents the state change and raises an appropriate error, \\nmaintaining the integrity of the booking system.\\nMonitoring and adaptation\\nEffective monitoring forms the cornerstone of maintaining robust state and environment models in \\nintelligent agent systems. A comprehensive monitoring approach tracks key performance metrics that \\nindicate the health and effectiveness of the system. These metrics include the latency of state updates, \\nwhich directly impacts the agent’s ability to respond to changes in real time, as well as the accuracy and \\nprecision of the model’s predictions and decisions. Additionally, the system must monitor resource \\nutilization patterns, track error rates and recovery times, and perhaps most importantly, measure \\ncustomer satisfaction indicators that reflect the real-world impact of the agent’s performance.\\nTo maintain optimal performance, intelligent agents must employ sophisticated adaptation strategies \\nthat respond to insights gained through monitoring. This involves implementing dynamic resource \\nallocation to handle varying workloads efficiently, while continuously refining and updating models \\nbased on new data and emerging patterns. The system should be capable of adjusting its rules and \\noptimization parameters in response to changing conditions, such as seasonal travel patterns or shifts \\nin customer preferences. Performance tuning and scaling mechanisms ensure the system can handle \\ngrowing demands while maintaining responsiveness, and the incorporation of user feedback helps \\nalign the system’s behavior with customer expectations and needs.\\nThe ultimate success of an intelligent agent system hinges on its ability to effectively represent and \\nmanage its state space and environment model while adapting to changing conditions. Through \\ncareful design that considers both static and dynamic elements, implementation of robust integration \\npatterns, and maintenance of effective monitoring and adaptation mechanisms, agents can achieve \\nhigher levels of performance and deliver superior service to users. This holistic approach to system \\ndesign and maintenance ensures that the agent remains reliable, efficient, and responsive to user needs \\nover time, even as the operational environment evolves and new challenges emerge.\\nAgent memory architecture and context management\\nMemory architecture and context management are fundamental components that enable intelligent \\nagents to maintain coherent interactions and make informed decisions based on past experiences and \\ncurrent context. This section explores the design principles and implementation strategies for creating \\neffective memory systems and managing contextual information in agent-based systems. Agent memory \\narchitectures typically incorporate three distinct types of memory, each serving different purposes in \\nthe agent’s operation: short-term memory, long-term memory, and episodic memory. Let us discuss \\nthese memory architectures in detail.Effective Agentic System Design Techniques 174\\nShort-term memory (working memory)\\nShort-term memory, also known as working memory, serves as the agent’s immediate cognitive \\nworkspace. It temporarily holds and manages information relevant to the current interaction or task \\nbeing processed. This type of memory is particularly crucial for maintaining conversation context, \\nhandling multi-step processes, and managing active user sessions. In our travel agent system, short-\\nterm memory is essential for tracking ongoing search parameters, maintaining the current state of a \\nbooking process, and remembering context-specific details that might influence immediate decisions.\\nFor example, when a customer is searching for flights, the short-term memory would maintain details \\nsuch as their current search criteria, recently viewed options, and any temporary preferences they’ve \\nexpressed during the current session. This information doesn’t need to be stored permanently but is \\ncritical for providing a coherent and personalized experience during active interaction. The temporary \\nnature of this memory also helps in managing system resources efficiently, as the data is cleared once \\nthe session ends or the information becomes irrelevant.\\nFor our travel agent system, a practical implementation of short-term memory might include the \\nfollowing Python class. This class defines the parameters required for an active real-time conversation \\nsuch as customer_id, the session start timestamp, the current query in the conversation thread, and \\nany specific preferences that are deduced from the user query. The update_context function is \\nused to update the properties of current_interaction as the conversation progresses, keeping \\nthe short-term memory up to date with the current information. Since short-term memory is often \\nephemeral and session-specific, the clear_session function is used to remove and reset the state \\nof current_session to prepare it for subsequent new sessions:\\nclass WorkingMemory:\\n    def __init__(self):\\n        self.current_interaction = {\\n            \\'customer_id\\': None,\\n            \\'session_start\\': None,\\n            \\'current_query\\': None,\\n            \\'active_searches\\': [],\\n            \\'temporary_preferences\\': {}\\n        }\\n    def update_context(self, new_information):\\n        # Update current interaction context\\n        self.current_interaction.update(new_information)\\n    def clear_session(self):\\n        # Reset temporary session data\\n        self.__init__()Agent memory architecture and context management 175\\nWhile short-term memory helps provide sufficient context for the intelligent agent to perform its \\ntask, there is often additional persistent information, as opposed to ephemeral information, that is \\nimportant for the intelligent agent to achieve its goal. Let us take a deeper look at what long-term \\nmemory, also known as the knowledge base, entails.\\nLong-term memory (knowledge base)\\nLong-term memory functions as the agent’s persistent knowledge repository, storing information that \\nremains relevant and valuable across multiple interactions and sessions. Unlike short-term memory, \\nthis type of storage is designed for data that needs to be preserved and accessed over extended periods. \\nIt serves as the foundation for the agent’s accumulated knowledge, learned patterns, and established \\nrelationships with customers.\\nLong-term memory is particularly crucial for maintaining consistency in customer service and enabling \\npersonalized interactions based on historical data. For instance, in our travel agent system, this would \\ninclude storing customer preferences discovered over multiple bookings, maintaining records of past \\ntravel arrangements, and preserving knowledge about destinations, seasonal patterns, and service \\nprovider relationships. This persistent storage allows the agent to make informed decisions based \\non historical patterns and provide personalized service without requiring customers to repeat their \\npreferences in every interaction.\\nThe implementation of long-term memory typically requires careful consideration of data organization, \\nretrieval efficiency, and update mechanisms to ensure that the stored information remains accurate \\nand accessible. In our travel agent system, this may include the following:\\n1. Customer profiles and preferences:\\nclass CustomerMemory:\\n    def __init__(self):\\n        self.profiles = {\\n            \\'preferences\\': {},\\n            \\'travel_history\\': [],\\n            \\'feedback_history\\': [],\\n            \\'special_requirements\\': {},\\n            \\'loyalty_status\\': None\\n        }\\n    def update_profile(self, customer_id, new_data):\\n        # Merge new information with existing profile\\n        self.profiles[customer_id] = {\\n            **self.profiles.get(customer_id, {}),\\n            **new_data\\n        }Effective Agentic System Design Techniques 176\\n2. Travel knowledge base:\\nclass TravelKnowledge:\\n    def __init__(self):\\n        self.destination_info = {}\\n        self.seasonal_patterns = {}\\n        self.service_providers = {}\\n        self.travel_regulations = {}\\n    def update_knowledge(self, category, key, value):\\n        # Update specific knowledge category\\n        getattr(self, category)[key] = value\\nShort-term and long-term memory serves as the important cornerstones of intelligent agentic \\nsystems. However, a third type of memory, known as episodic memory, has emerged, especially for \\nconversational interfaces such as chatbots. This type of memory helps LLMs and intelligent agents \\nfurther refine their actions and provide prescriptive outputs to the user.\\nEpisodic memory (interaction history)\\nEpisodic memory represents a specialized form of memory that captures and stores specific interactions, \\nevents, and their outcomes as discrete episodes. This type of memory enables the agent to learn from \\npast experiences and use historical interactions to inform future decisions. Unlike general long-\\nterm memory, episodic memory focuses on the temporal sequence and context of events, making it \\nparticularly valuable for understanding patterns in customer behavior and service outcomes.\\nIn the context of our travel agent system, episodic memory serves multiple critical functions. It helps \\nidentify successful booking patterns, understand common customer journey paths, and recognize \\nsituations that have led to either positive outcomes or challenges in the past. For example, if a customer \\npreviously encountered issues with layover times in specific airports, the agent can use this episodic \\ninformation to avoid similar situations in future bookings. This memory type also enables the agent \\nto provide more contextually relevant responses by referencing past interactions and their outcomes.\\nThe implementation of episodic memory requires careful consideration of how to structure and store \\ninteraction records in a way that facilitates efficient retrieval and pattern recognition. For our travel \\nagent system, this may include the following:\\nclass EpisodicMemory:\\n    def __init__(self):\\n        self.interaction_history = []\\n    def record_interaction(self, interaction_data):\\n        # Add timestamp and store interaction\\n        interaction_data[\\'timestamp\\'] = datetime.now()Agent memory architecture and context management 177\\n        self.interaction_history.append(interaction_data)\\n    def retrieve_relevant_episodes(self, context):\\n        # Find similar past interactions\\n        return [episode for episode in\\n               self.interaction_history\\n                if self._is_relevant(episode, context)]\\nHaving established the core memory systems, we now turn our attention to how these different types \\nof memory work together in practice. The agent needs sophisticated mechanisms to manage the flow of \\ninformation between these memory systems and ensure that the right information is available at the right \\ntime. This brings us to two critical components: context management and decision-making integration.\\nContext management\\nEffective context management ensures that the agent maintains appropriate awareness of the current \\nsituation and relevant historical information. Imagine our travel booking agent assisting a customer \\nwith planning a multi-city business trip to Tokyo and Singapore. The agent must maintain awareness \\nof various contextual elements: the customer’s corporate travel policy limiting flight costs to $2,000, \\ntheir preference for morning flights due to scheduled meetings, and the need to coordinate hotel \\nbookings within walking distance of specific office locations. As the booking process unfolds, the \\nagent continuously references and updates this information while navigating between flight searches, \\nhotel availability, and meeting schedule constraints. This real-world scenario demonstrates why robust \\ncontext management is essential for handling complex, multi-step travel arrangements. Effective \\ncontext management ensures that the agent maintains appropriate awareness of the current situation \\nand relevant historical information. This involves several key components:\\n• Context hierarchy: The context management system should maintain different levels of context:\\n \\x82 Global context:\\n \\x8f System-wide settings and constraints\\n \\x8f Current operational status\\n \\x8f Global travel alerts and advisories\\n \\x82 Session context:\\n \\x8f Current customer interaction state\\n \\x8f Active searches and queries\\n \\x8f Temporary preferences and constraintsEffective Agentic System Design Techniques 178\\n \\x82 Task context:\\n \\x8f Specific booking details\\n \\x8f Current step in multi-step processes\\n \\x8f Related bookings and dependencies\\n• Context switching: Context switching is a critical capability that allows the agent to smoothly \\ntransition between different operational contexts while maintaining coherence and continuity. \\nThis process involves several key aspects:\\n \\x82 Context preservation:\\n \\x8f Saving the current state before switching\\n \\x8f Maintaining a history of context changes\\n \\x8f Ensuring no critical information is lost during transitions\\n \\x82 Context restoration:\\n \\x8f Retrieving previous contexts when needed\\n \\x8f Rebuilding the operational environment\\n \\x8f Reestablishing relevant connections and states\\n \\x82 Context merging:\\n \\x8f Combining information from multiple contexts\\n \\x8f Resolving conflicts between different contexts\\n \\x8f Maintaining consistency across context changes\\nThe sophisticated interplay between memory systems and context management ultimately serves one \\nprimary purpose: enabling intelligent decision-making. By maintaining awareness of both historical \\ndata and current context, the agent can make more informed and effective decisions. Let’s examine \\nhow these components come together to support the agent’s decision-making processes.Agent memory architecture and context management 179\\nIntegration with decision-making\\nThe memory architecture and context management system must effectively support the agent’s \\ndecision-making processes through several key mechanisms:\\n1. Information retrieval: The system must efficiently gather and synthesize relevant information \\nfrom various memory components to support decision-making. This includes the following:\\n \\x82 Accessing customer history and preferences\\n \\x82 Retrieving similar past cases and their outcomes\\n \\x82 Combining current context with historical data\\n \\x82 Filtering and prioritizing relevant information\\n2. Pattern recognition: Pattern recognition capabilities enable the agent to identify relevant \\npatterns and trends that can inform decisions:\\n \\x82 Analyzing historical interaction patterns\\n \\x82 Identifying successful booking patterns\\n \\x82 Recognizing potential issues based on past experiences\\n \\x82 Detecting seasonal trends and preferences\\n3. Decision optimization: The decision-making process should incorporate multiple factors and \\noptimize outcomes based on the following:\\n \\x82 Weighted evaluation of different options\\n \\x82 Consideration of multiple constraints\\n \\x82 Balance between customer preferences and system requirements\\n \\x82 Risk assessment and mitigation strategies\\nThe effective integration of memory architecture and context management systems enables agents \\nto maintain coherent interactions, learn from past experiences, and make more informed decisions. \\nBy carefully designing these components and ensuring they work together seamlessly, agents can \\nprovide a more personalized and effective service while maintaining consistency across interactions.Effective Agentic System Design Techniques 180\\nSequential and parallel processing in agentic workflows\\nThe efficiency and effectiveness of an intelligent agent system often depend on how well it can manage \\nmultiple tasks and processes. This section explores two primary approaches to workflow management \\nin agent systems: sequential and parallel processing.\\nSequential processing\\nSequential processing involves handling tasks in a defined order, where each step depends on the \\ncompletion of previous steps. In our travel agent system, sequential processing is crucial for tasks that \\nrequire strict ordering, such as the following:\\n1. Flight and hotel coordination:\\n \\x82 Confirming flight availability before booking hotels\\n \\x82 Ensuring transfer services align with arrival times\\n \\x82 Validating visa requirements before finalizing bookings\\n2. Payment processing:\\n \\x82 Verifying fund availability\\n \\x82 Processing the payment\\n \\x82 Confirming bookings\\n \\x82 Sending confirmation documents\\nThe following figure shows a straightforward sequential processing workflow for our travel booking system:\\nFigure 7.2 –  Sequential processing\\nWhile sequential processing provides a clear and controlled workflow for dependent tasks, it can lead \\nto inefficiencies when handling multiple independent operations. This limitation becomes particularly \\nevident in complex use cases, for example, travel bookings where certain tasks could potentially be \\nexecuted simultaneously. Understanding when to apply sequential versus parallel processing is crucial \\nfor optimizing the agent’s performance and response time. Let’s examine how parallel processing can \\nenhance our system’s efficiency.Sequential and parallel processing in agentic workflows 181\\nParallel processing\\nParallel processing enables the agent to handle multiple independent tasks simultaneously, improving \\nefficiency and response times. Key applications include the following:\\n1. Concurrent searches:\\n \\x82 Querying multiple airline systems simultaneously\\n \\x82 Checking availability across different hotel chains\\n \\x82 Retrieving weather forecasts and travel advisories\\n2. Background processing:\\n \\x82 Updating customer profiles\\n \\x82 Processing feedback and reviews\\n \\x82 Monitoring price changes\\n \\x82 Updating travel advisories\\nThe following figure shows a possible parallel processing workflow for our travel booking system:\\nFigure 7.3 – Parallel processing\\nWhile both sequential and parallel processing approaches offer distinct advantages, the real challenge \\nlies in determining when to use each approach and how to combine them effectively. An agent must \\nbe able to dynamically switch between these processing modes based on task requirements, system \\nload, and time constraints. This necessitates a careful approach to workflow optimization.Effective Agentic System Design Techniques 182\\nWorkflow optimization\\nEffective workflow optimization in agent systems requires a sophisticated approach to managing and \\ncoordinating different processing patterns. This involves not just choosing between sequential and \\nparallel processing but also understanding how to combine them effectively while considering system \\nresources, time constraints, and task dependencies. The following figure demonstrates a conceptual \\narchitecture of an optimal and dynamic workflow that may be designed:\\nFigure 7.4 – Workflow optimization with dynamic workflows\\nHere is a detailed analysis of workflow optimization:\\n1. Task classification and prioritization: The first step in workflow optimization involves carefully \\nanalyzing and categorizing tasks:\\nI. Dependency analysis:\\n \\x8f Identifying critical path tasks that must be completed in sequence\\n \\x8f Mapping dependencies between different booking components\\n \\x8f Understanding data flow requirements between tasks\\n \\x8f Recognizing temporal constraints and deadlinesSequential and parallel processing in agentic workflows 183\\nII. Priority assignment:\\n \\x8f Evaluating task urgency and importance\\n \\x8f Considering customer SLAs and expectations\\n \\x8f Assessing the impact on the overall booking process\\n \\x8f Determining resource requirements\\n2. Resource management: Efficient allocation and utilization of resources is crucial for optimal \\nworkflow performance:\\nI. System resource allocation:\\n \\x8f Monitoring and managing CPU and memory usage\\n \\x8f Balancing load across different system components\\n \\x8f Implementing throttling mechanisms when needed\\n \\x8f Optimizing database connections and caches\\nII. External service management:\\n \\x8f Tracking API rate limits and quotas\\n \\x8f Managing concurrent external service requests\\n \\x8f Implementing retry strategies for failed operations\\n \\x8f Maintaining service provider priorities\\n3. Dynamic workflow adjustment: The system must be able to adapt its workflow patterns based \\non changing conditions:\\nI. Load balancing:\\n \\x8f Adjusting parallel task execution based on system load\\n \\x8f Redistributing tasks during peak periods\\n \\x8f Managing queue depths and processing rates\\n \\x8f Implementing backpressure mechanisms\\nII. Performance monitoring:\\n \\x8f Tracking task completion times and success rates\\n \\x8f Identifying bottlenecks and performance issuesEffective Agentic System Design Techniques 184\\n \\x8f Measuring system throughput and latency\\n \\x8f Monitoring resource utilization patterns\\nBy carefully implementing these optimization strategies, agent systems can achieve better performance \\nwhile maintaining reliability. The key is to create workflows that are not just efficient but also resilient \\nand adaptable to changing conditions. This balanced approach ensures that the agent can handle \\ncomplex travel booking scenarios while providing consistent and responsive service to customers.\\nSummary\\nIn this chapter, you learned about the essential components and techniques for designing effective \\nagentic systems. We explored how focused system prompts guide agent behavior, how state space \\nrepresentations and environment models create a foundation for decision-making, and how different \\nmemory architectures – short-term, long-term, and episodic – work together with context management \\nto enable coherent interactions and learning from past experiences.\\nThrough our travel agent example, we demonstrated how the integration of sequential and parallel \\nprocessing patterns, supported by intelligent workflow optimization strategies, enables agents to handle \\ncomplex tasks efficiently while maintaining system reliability. These design techniques work together \\nto create systems that can effectively manage real-world scenarios, adapt to changing conditions, \\nand provide consistent, high-quality service to users. By implementing these practices thoughtfully, \\ndevelopers can create agent systems that not only meet current requirements but are also positioned \\nto evolve with future needs. In the next chapter, we will explore the critical topic of building trust in \\ngenerative AI systems, examining how to create transparent, reliable, and accountable AI solutions \\nthat users can confidently rely upon.\\nQuestions\\n1. What are the three primary types of memory architecture in agent systems, and why are they \\nimportant for maintaining effective agent behavior?\\n2. Explain the difference between sequential and parallel processing in agent workflows. When \\nwould you use each approach in a travel booking system?\\n3. How does context management contribute to effective agent operation, and what are the key \\nlevels of context that need to be maintained?\\n4. What role does the environment model play in agent design, and how does it differ from state \\nspace representation?\\n5. In workflow optimization, what factors should be considered when deciding between sequential \\nand parallel processing approaches?Answers 185\\nAnswers\\n1. The three primary types of memory architecture are as follows:\\n \\x82 Short-term (working) memory: Handles immediate interaction contexts and temporary \\ninformation needed for current tasks – for example, maintaining active search parameters \\nand current session state.\\n \\x82 Long-term (knowledge base) memory: Stores persistent information valuable across multiple \\ninteractions, such as customer profiles, travel regulations, and destination information.\\n \\x82 Episodic memory: Records specific interactions and their outcomes as discrete episodes, \\nenabling learning from past experiences and pattern recognition in customer behavior. These \\nare important because they enable the agent to maintain context, learn from experience, and \\nmake informed decisions based on both current and historical information.\\n2. Sequential processing involves handling tasks in a defined order where each step depends \\non the completion of previous steps (e.g., confirming flight availability before booking hotels \\nand processing payments before sending confirmation). Parallel processing enables handling \\nmultiple independent tasks simultaneously (e.g., searching multiple airline systems, checking \\nhotel availability, and retrieving weather forecasts concurrently). In a travel booking system, \\nyou would do the following:\\n \\x82 Use sequential processing when tasks have dependencies (payment → confirmation)\\n \\x82 Use parallel processing for independent tasks (multiple vendor searches)\\n3. Context management contributes to agent operation by ensuring appropriate awareness of the \\ncurrent situation and relevant historical information. The key levels are as follows:\\n \\x82 Global context: System-wide settings, operational status, and global alerts\\n \\x82 Session context: Current customer interaction state, active queries, and temporary preferences\\n \\x82 Task context: Specific booking details and the current step in multi-step processes. This \\nhierarchy enables the agent to maintain coherent interactions while efficiently managing \\ninformation at different operational levels.\\n4. The environment model creates a comprehensive representation of the external factors and \\nsystems with which the agent interacts, including both static rules (business policies and \\nsystem interfaces) and dynamic elements (resource availability and pricing changes). State \\nspace representation, in contrast, focuses on tracking the current situation, available actions, \\nand potential outcomes. The environment model provides the broader operational context \\nwithin which the state space exists.Effective Agentic System Design Techniques 186\\n5. Key factors for workflow optimization include the following:\\n \\x82 Task dependencies: Whether tasks have prerequisites or can run independently\\n \\x82 Resource availability: System capacity and external service limitations\\n \\x82 Time constraints: Urgency of task completion and SLA requirements\\n \\x82 System load: Current processing capacity and queue depths\\n \\x82 Performance requirements: Throughput and latency expectations.\\nThe decision should balance these factors while considering the specific requirements of each \\ntask and the overall system efficiency goals.\\nJoin our communities on Discord and Reddit\\nHave questions about the book or want to contribute to discussions on Generative AI and LLMs? \\nJoin our Discord server at https://packt.link/I1tSU and our Reddit channel at https://\\npackt.link/ugMW0 to connect, share, and collaborate with like-minded enthusiasts.Part 3:  \\nTrust, Safety, Ethics,  \\nand Applications\\nThis part aims to provide you with a comprehensive understanding of building trustworthy, safe, and \\nethical generative AI systems while exploring real-world applications and future directions for the field.\\nThis part contains the following chapters:\\n• Chapter 8, Building Trust in Generative AI Systems\\n• Chapter 9, Managing Safety and Ethical Considerations\\n• Chapter 10, Common Use Cases and Applications\\n• Chapter 11, Conclusion and Future Outlook8\\nBuilding Trust in  \\nGenerative AI Systems\\nIn the previous chapter, we explored several design methods that can effectively guide intelligent \\nagents toward desirable behavior while upholding ethical principles. Focused instruction, guardrails \\nand constraints, and finding the right balance between autonomy and control are crucial strategies \\nfor aligning these agents with human values and mitigating potential risks.\\nClear objectives, tasks, and operating contexts through focused instructions provide a well-defined \\nframework for agents to operate within. Guardrails and constraints act as boundaries, preventing \\nagents from wandering into unintended territory and minimizing the risks of adverse consequences. \\nMeanwhile, a balanced approach that combines autonomous decision-making with human control \\nallows agents to exercise independent judgment while remaining tethered to our values and principles.\\nHowever, beneath the successful adoption and acceptance of generative AI systems lies a critical \\ncomponent: trust. As these technologies become increasingly intertwined with various aspects of \\nsociety, fostering user confidence and trust will be essential for their effective implementation.\\nIn this chapter, we will delve into the importance of trust in AI and explore strategies for achieving \\nit. This chapter underscores the importance of trust as a fundamental component for fostering user \\nconfidence and responsible implementation. It is divided into several sections, each addressing a \\ndifferent aspect of building trust. We will address two significant hurdles – uncertainty and biases – \\nand emphasize the importance of transparency, explainability, and clear communication.\\nThis chapter is divided into the following main sections:\\n• Importance of trust in AI\\n• Techniques for establishing trust\\n• Implementing transparency and explainability\\n• Handling uncertainty and biasesBuilding Trust in Generative AI Systems 190\\nBy the end of this chapter, you will know how to develop reliable generative AI systems that instill \\nconfidence in users and stakeholders, paving the way for their widespread and responsible adoption.\\nTechnical requirements\\nY ou can find the code file for this chapter on GitHub at https://github.com/PacktPublishing/\\nBuilding-Agentic-AI-Systems.\\nImportance of trust in AI\\nTrust constitutes a key ingredient for the successful adoption and acceptance of AI systems in general, \\nincluding generative AI. If users lack confidence in the inner workings and decision-making processes \\nof this new technology, it’s highly doubtful that they will be willing to use or rely on its outputs. Building \\nup trust in generative AI systems is an essential step toward gaining user confidence and ensuring \\nthat its use is widespread, responsible, and ethical.\\nConsider a scenario where a travel agency employs a generative AI system to assist customers in \\nplanning their vacations. The AI can suggest personalized itineraries, recommend accommodations, \\nand provide travel tips based on the customer’s preferences and historical data. However, if customers \\ndo not trust the AI’s recommendations, they are unlikely to rely on its suggestions or share personal \\ninformation necessary for tailoring the recommendations.\\nThis means that trust in AI is multivariate, with factors relating to the reliability of the system, \\ntransparency, and correspondence with users’ expectations and values. Users are more likely to interact \\nwith an AI system they perceive as trustworthy, including contributing feedback and sharing their \\ndata to further refine and enhance the performance and capability of the AI system.\\nIn the travel agency example, customers may be more inclined to trust the AI’s recommendations if \\nthe system is transparent about its decision-making process, explaining why specific destinations or \\nactivities were suggested based on their preferences and past travel histories. Additionally, if the AI’s \\nrecommendations align with the customers’ expectations and values, such as prioritizing eco-friendly \\nor culturally immersive experiences, it will further reinforce trust in the system.\\nWhere there is a deficiency in trust, it may lead to users being skeptical, resistive to its adoption, and, \\nultimately, abusing or misusing such technology. In the travel agency scenario, if customers do not \\ntrust the AI’s recommendations, they may disregard its suggestions entirely or provide inaccurate \\ninformation, resulting in suboptimal itineraries and a poor user experience.\\nFurthermore, a lack of trust can hinder the continuous improvement and advancement of the AI \\nsystem. If customers are unwilling to share feedback or data due to mistrust, the AI’s ability to learn \\nand adapt to their evolving preferences and requirements will be limited.Techniques for establishing trust 191\\nTo address these concerns, travel agencies and other organizations leveraging generative AI must \\nprioritize building trust through various techniques, such as transparency in decision-making, addressing \\nuncertainties and biases, effective communication of outputs, and ensuring ethical development \\npractices. By fostering trust, businesses can unlock the full potential of generative AI, enabling seamless \\nadoption, responsible use, and continuous improvement of these powerful technologies.\\nIn the next section, we will explore some of the techniques for establishing trust.\\nTechniques for establishing trust\\nThere are various techniques available to the developer and researcher community to help cultivate \\ntrust in generative AI systems, addressing user concerns and expectations. We will discuss the key \\ntechniques in the following subsections.\\nTransparency and explainability\\nTransparency into how an AI system arrives at its decisions and generates content forms the bedrock \\nof building trust. Users need to understand the reasoning behind the AI’s outputs and have confidence \\nin its decision-making process. Without this transparency and explainability, users may perceive the \\nAI as a black box, making it difficult to trust its recommendations or outputs fully. Transparency in \\nAI operates on two levels: the algorithmic level and the presentation level. Algorithmic transparency \\ninvolves openness about the model’s architecture, training data, and potential biases, ensuring \\nthat developers and regulators can assess its reliability and fairness. Presentation transparency, or \\nexplainability, focuses on how the AI communicates its reasoning to users, helping them understand \\nwhy a specific decision or recommendation was made. Both aspects are essential for trust – without \\nalgorithmic transparency, stakeholders may question the system’s integrity, while a lack of explainability \\ncan leave users feeling uncertain about its outputs. A well-balanced approach strengthens confidence \\nin AI-driven decisions.\\nLet’s consider the travel agent scenario again. Imagine a customer planning a family vacation to \\nEurope, and the AI system suggests visiting a particular city based on their preferences and travel \\nhistory. The customer might be more inclined to trust the recommendation if the AI can explain its \\nreasoning transparently. For instance, the system could highlight that the suggested city is known for \\nits family-friendly attractions, rich cultural heritage, and affordable accommodations, aligning with \\nthe customer’s preferences for educational and budget-friendly travel.\\nExplainable AI (XAI) techniques play a crucial role in achieving this transparency. In a content \\ngeneration system such as GPT-4, users may want to know why certain phrases or sentences were \\nchosen and how the AI factored in context, tone, and style preferences. XAI techniques, such as \\nattention visualization, saliency maps, and natural language explanations, can provide insight into \\nthe model’s inner workings, making it more interpretable and trustworthy.Building Trust in Generative AI Systems 192\\nThe chapter08_xai notebook provides an example of how attention visualization, saliency maps, \\nand natural language explanations can be generated simply using Python. The code demonstrates the \\nuse of a pre-trained BERT model to analyze text through attention visualization. It begins by importing \\nthe necessary libraries, including torch for tensor operations, transformers for loading the \\nBERT model and tokenizer, and matplotlib and seaborn for visualizing the attention scores.\\nThe model (bert-base-uncased) is used for sequence classification, and the tokenizer processes \\nthe input text into token IDs. The core functionality includes extracting attention scores from the \\nmodel by enabling the output_attentions=True parameter, which provides insights into how \\ndifferent tokens within the input query relate to each other. The attention scores are then visualized \\nusing a heatmap, which shows the attention distribution across tokens in the last attention layer. This \\nheatmap helps to understand which parts of the text the model focuses on when processing the query. \\nBy decoding the token IDs into readable tokens and plotting the attention scores, the code enables a \\ndetailed analysis of how BERT processes text, making it a valuable tool for XAI, where the goal is to \\nimprove model transparency and interpretability.\\nWhen asked “What are the best family-friendly travel destinations in Europe? , ” the code snippet \\ntokenizes the input text using the pre-trained tokenizer, converting it into a tensor format suitable \\nfor the model while applying truncation and padding as needed. It then defines a function to extract \\nattention scores by passing the tokenized inputs to the model, providing insight into how different \\nparts of the text attend to one another. Another function visualizes these attention scores using a \\nheatmap, displaying the attention weights from the last layer with tokens labeled along both axes. \\nFinally, the code retrieves the attention scores, decodes the token IDs into their corresponding tokens, \\nand visualizes the attention weights to show the model’s focus on the input text. Figure 8.1 shows the \\nattention visualization:Techniques for establishing trust 193\\nFigure 8.1 – Attention visualizationBuilding Trust in Generative AI Systems 194\\nFor example, an attention visualization could highlight the specific words or phrases from the user’s \\nprompt that the AI focused on while generating the content. This can help users understand how the \\nAI interpreted their input and why certain creative choices were made. Similarly, Figure 8.2 displays \\nthe saliency map for the same sentence:\\nFigure 8.2 – Saliency map\\nThe code (chapter08_xai) implements a saliency map visualization for the given sentence using \\na pre-trained BERT model. The process begins by tokenizing the input sentence into token IDs and \\nattention masks, which are then passed through the model. The embeddings for the tokens are retrieved \\nand tracked for gradients, allowing the saliency scores to be computed, indicating how much each \\ntoken contributes to the model’s prediction. A custom forward function is used to feed the embeddings \\ninto the model, and the saliency attribute method calculates the saliency scores. These scores are \\nthen aggregated across token embeddings, and the tokens are converted back to their readable form. \\nFinally, a bar chart is generated to visually display the importance of each token, providing insights \\ninto which tokens had the most influence on the model’s decision. This approach allows for better \\ninterpretability of the model’s behavior by highlighting key tokens driving its output.\\nIn some cases, natural language explanations can provide additional insight into the model. Natural \\nlanguage explanations in AI and machine learning are human-readable descriptions that help \\ntranslate complex model outputs or decisions into understandable language. They are essential for \\nimproving interpretability and transparency, allowing users to comprehend the reasoning behind \\na model’s behavior. For instance, when a model classifies an image, a natural language explanationTechniques for establishing trust 195\\nmight describe the features that led to the classification, such as “ This image was classified as a dog \\nbecause it contains a tail and ears typical of dogs.” These explanations bridge the gap between machine \\noutputs and human understanding, fostering trust and collaboration between humans and AI. For \\nan example, refer to Figure 8.3:\\nFigure 8.3 – Natural language explanation\\nWe input the same text, “What are the best family-friendly travel destinations in Europe?, ” and can \\nclearly observe why the model (GPT-4o-mini) identified it as encouraging. In high-stakes domains \\nsuch as healthcare or finance, natural language explanations are crucial for ensuring the accountability \\nand fairness of AI decisions. By providing clear insight into how models arrive at their conclusions, \\nnatural language explanations promote responsible and ethical AI deployment.\\nIf we look at the healthcare industry, AI systems are increasingly being used for tasks such as disease \\ndiagnosis and treatment recommendation. Transparency and explainability become crucial in these \\nhigh-stakes scenarios. Physicians and patients need to understand the reasoning behind an AI’s \\ndiagnosis or treatment plan, particularly if it contradicts established medical knowledge or guidelines. \\nXAI techniques such as feature importance and rule extraction can help explain the factors that \\ninfluenced the AI’s decision, allowing healthcare professionals to evaluate the recommendation’s \\nvalidity and build trust in the system.Building Trust in Generative AI Systems 196\\nSimilarly, in the finance sector, AI models are used for tasks such as credit risk assessment, fraud \\ndetection, and investment portfolio optimization. XAI can help financial institutions understand the \\nfactors influencing an AI’s decisions, ensuring compliance with regulations and building trust among \\ncustomers and stakeholders.\\nDevelopers and researchers can leverage various XAI techniques based on the specific use case and \\nmodel architecture. For instance, saliency maps can be useful for computer vision tasks, while natural \\nlanguage explanations may be more suitable for text generation or language understanding models.\\nBy prioritizing transparency and explainability, organizations can create AI systems that are not just \\naccurate but also trustworthy. Users can understand the reasoning behind the AI’s outputs, evaluate \\nits decisions, and, ultimately, develop confidence in the system’s capabilities, paving the way for \\nwidespread and responsible adoption of these powerful technologies.\\nDealing with uncertainty and biases\\nAI systems need to be designed to identify and mitigate uncertainties and biases that may have been \\nintroduced through their training data or algorithms. Quantifying and communicating uncertainty, \\nas well as actively attempting to minimize biases, are crucial steps toward building trust between \\ngenerative AI systems and their users.\\nIn the travel agent scenario, consider a generative AI system that recommends personalized travel \\nitineraries based on user preferences and historical data. If the user provides an ambiguous or vague \\nprompt, such as “I want to go on an adventure, ” the AI system should be able to acknowledge the \\nuncertainty involved in interpreting such a broad request. It could convey this uncertainty by providing \\na range of potential itinerary options or highlighting the need for additional clarification from the user.\\nAdditionally, the AI system might have inherent biases in its recommendations due to the training data \\nit was exposed to. For instance, if the training data predominantly featured more affluent travelers or \\nfocused on specific regions, the AI’s recommendations could be skewed toward luxury accommodations \\nor popular tourist destinations, failing to capture the diversity of travel experiences. Addressing these \\nbiases is crucial for building trust and ensuring fair and inclusive recommendations.\\nTechniques such as debiasing algorithms, adversarial training, and human supervision can help reduce \\nbiases related to factors such as gender, race, age, or socioeconomic status. Debiasing algorithms aim \\nto remove or mitigate biases by adjusting the model’s parameters or modifying the training data. \\nAdversarial training involves training the model to be robust against biased or adversarial inputs, while \\nhuman supervision allows for manual intervention and correction of biased outputs. For instance, a \\ntext-to-image generation model should be able to acknowledge and convey the uncertainties involved \\nin interpreting ambiguous prompts or generating complex scenes. If a user requests an image of a \\nmagical forest, the AI system could generate multiple variations and provide confidence scores or \\nuncertainty estimates for each image, allowing the user to understand the model’s interpretation and \\npotential limitations.Techniques for establishing trust 197\\nIn the healthcare domain, where AI systems are increasingly being used for tasks such as disease \\ndiagnosis and treatment recommendation, dealing with uncertainty and biases is of utmost importance. \\nAI models should be able to quantify the uncertainty in their predictions, particularly in cases where \\nthe input data is incomplete or ambiguous. Additionally, addressing biases related to factors such as \\nrace, gender, or socioeconomic status is crucial to ensure fair and equitable healthcare outcomes. By \\nimplementing techniques to identify, quantify, and mitigate uncertainties and biases, developers and \\nresearchers can create AI systems that are not only accurate but also transparent and trustworthy. Users \\ncan better understand the limitations and potential biases of the system, leading to more informed \\ndecision-making and responsible use of these powerful technologies.\\nEffective output communication\\nHow AI-generated content is framed and interpreted significantly impacts user trust. Developers \\nshould ensure that outputs are clearly labeled as AI-generated, provide context and attribution where \\nappropriate, and suggest to users how they should interpret and utilize the content further.\\nIn the travel agent scenario, consider a generative AI system that creates personalized travel blog posts or \\nitinerary descriptions based on the user’s preferences and destination. Effective output communication \\nis crucial to ensure that users understand the nature and limitations of AI-generated content.\\nFirst, the AI-generated travel blog posts or itinerary descriptions should be clearly labeled as AI-generated \\nor AI-assisted to set appropriate expectations and avoid any confusion or misrepresentation. Additionally, \\nthe AI system could provide context about the data sources and algorithms used in generating the \\ncontent, such as the types of travel data, user reviews, and language models employed.\\nFurthermore, the AI system should transparently communicate any potential biases or limitations \\nin the generated content. For instance, if the training data primarily focused on popular tourist \\ndestinations or mainstream travel experiences, the AI-generated content might lack representation \\nof off-the-beaten-path or niche travel opportunities. By acknowledging these limitations, users can \\nbetter understand the scope and potential blind spots of the AI-generated content.\\nGuidelines on how to interpret and utilize AI-generated content responsibly can also foster trust. \\nFor example, the AI system could suggest that users fact-check or verify specific details, such as \\nopening hours, admission fees, or local customs, before relying solely on AI-generated information. \\nAdditionally, the system could recommend cross-referencing the content with other reliable sources \\nor seeking local expertise when planning their travel itineraries.\\nIn the news and journalism domain, where AI-generated content is becoming increasingly prevalent, \\neffective output communication is paramount. AI-generated news articles should be clearly marked \\nas such, with information about the data sources and any potential biases or limitations. For instance, \\nif the AI system was trained on a specific set of news sources or time periods, it might have inherent \\nbiases in its reporting or framing of events.Building Trust in Generative AI Systems 198\\nAdditionally, guidelines on fact-checking and verifying the information can help users engage with \\nthe AI-generated content responsibly. News organizations could provide resources or checklists for \\nusers to cross-reference the AI-generated articles with other credible sources, fact-check claims, and \\nevaluate the article’s objectivity and balance.\\nBy implementing effective output communication strategies, developers and organizations can promote \\ntransparency, manage user expectations, and empower users to engage with AI-generated content \\ncritically and responsibly. This approach fosters trust, mitigates potential misunderstandings or misuse, \\nand paves the way for the responsible adoption of generative AI technologies across various domains.\\nUser control and consent\\nUser control and consent refer to features that allow users to have more freedom in customizing and \\ninfluencing the generative process, as well as soliciting explicit consent regarding data usage and \\ncontent creation. This can help build trust and ensure user commitment.\\nIn the travel agent scenario, consider a generative AI system that creates personalized travel itineraries \\nor recommendations based on the user’s preferences and historical data. Providing users with control \\nover the generative process can help build trust and ensure that the AI-generated content aligns with \\ntheir specific needs and expectations.\\nFor instance, the AI system could allow users to adjust parameters such as travel style (e.g., adventure, \\nrelaxation, or culture), budget range, duration, or desired activities. By giving users the ability to fine-\\ntune these parameters, they can better influence the AI’s recommendations and have a sense of control \\nover the generated output. This level of customization can increase user satisfaction and trust in the \\nAI system, as they feel that their preferences are being accurately reflected in the recommendations.\\nAdditionally, seeking explicit consent from users regarding the use of their personal data or travel \\nhistories can foster transparency and build trust. The AI system could present clear and easily \\nunderstandable information about the data being collected, how it will be used, and any potential \\nrisks or limitations. Users could then provide informed consent, allowing the AI system to leverage \\ntheir data while respecting their privacy and autonomy.\\nIn the creative writing domain, an AI-powered writing assistant could allow users to adjust parameters \\nsuch as tone (e.g., formal, casual, or humorous), style (e.g., descriptive, concise, or narrative), or \\ncontent boundaries (e.g., family-friendly or explicit content). By giving users this level of control, \\nthey can better align the AI-generated content with their desired creative vision, fostering a sense of \\nownership and trust in the AI system.\\nFurthermore, seeking consent for using personal writing samples or data can promote transparency \\nand build trust between users and the AI system. The AI system could clearly explain how the user’s \\ndata will be utilized, such as for training or personalization purposes, and provide options for users \\nto control the level of access or revoke consent at any time.Techniques for establishing trust 199\\nIn the field of personalized healthcare, AI systems could allow users to adjust preferences related to \\ntreatment approaches (e.g., conventional, alternative, or integrative), risk tolerance, or specific dietary \\nor lifestyle considerations. By giving users control over these parameters, the AI-generated treatment \\nplans or recommendations can better align with their personal values and preferences, fostering trust \\nand commitment to the AI system’s recommendations.\\nBy incorporating user control and consent features, developers and organizations can create AI \\nsystems that are not only accurate and efficient but also transparent, respectful of user autonomy, and \\nresponsive to individual preferences and needs. This approach can foster trust, user commitment, and \\nresponsible adoption of generative AI technologies across various domains.\\nEthical development and responsibility\\nFairness, privacy, and intellectual property rights are among the ethical considerations that should \\nbe heavily emphasized during the development and deployment process of generative AI systems to \\ngarner trust from users and other stakeholders. Developers should prioritize practices such as privacy-\\npreserving techniques, responsible data handling, and respecting intellectual property rights. Ensuring \\nthat the AI system does not perpetuate harmful biases or discriminate against certain groups is also \\ncrucial for building trust and responsible adoption.\\nIn the travel agent scenario, consider a generative AI system that creates personalized travel \\nrecommendations and itineraries. Ethical development and responsibility should be at the forefront \\nto ensure that the AI system operates fairly, respects user privacy, and avoids infringing on intellectual \\nproperty rights.\\nFairness and non-discrimination are essential principles that should guide the development of such an \\nAI system. The training data and algorithms used to generate recommendations should be carefully \\nevaluated to identify and mitigate potential biases or discriminatory patterns. For example, if the \\ntraining data predominantly features travel experiences catered to specific demographic groups or \\nincome levels, the AI system may inadvertently perpetuate biases in its recommendations, excluding \\nor underrepresenting certain communities or travel preferences.\\nDevelopers should implement techniques such as debiasing algorithms, adversarial training, and diverse \\ndata collection strategies to ensure that the AI system generates fair and inclusive recommendations, \\nregardless of factors such as race, gender, age, or socioeconomic status. By prioritizing fairness and \\nnon-discrimination, users can trust that the AI system treats them equally and does not reinforce \\nharmful stereotypes or biases.\\nPrivacy is another critical ethical consideration in the development of generative AI systems. Users \\nmay be hesitant to share personal data or travel histories if they lack confidence in the AI system’s \\nability to protect their privacy. Developers should implement privacy-preserving techniques, such \\nas differential privacy, secure multi-party computation, or encrypted data processing, to ensure that \\nuser data is handled responsibly and protected from unauthorized access or misuse.Building Trust in Generative AI Systems 200\\nAdditionally, responsible data handling practices should be established to ensure that user data is \\ncollected, stored, and processed in compliance with relevant privacy laws and regulations. Transparent \\ndata policies and user consent mechanisms can further build trust by giving users control over how \\ntheir data is used by the AI system.\\nIntellectual property rights are also a significant concern in the realm of generative AI systems. When \\ncreating travel content or recommendations, the AI system should respect copyrights, trademarks, \\nand other intellectual property rights. Developers should implement techniques to detect and prevent \\nthe unauthorized use of copyrighted materials or the generation of content that infringes on existing \\nintellectual property.\\nFurthermore, the AI system should provide proper attribution and credit when using or referencing \\nthird-party content or data sources. This not only respects intellectual property rights but also \\nfosters transparency and trust among users, who can verify the sources and credibility of the \\ninformation presented.\\nBy prioritizing ethical development practices and addressing concerns related to fairness, privacy, and \\nintellectual property rights, developers can create generative AI systems that are not only powerful and \\nefficient but also trustworthy and socially responsible. Users and stakeholders can have confidence in the \\nintegrity of the AI system, promoting widespread adoption and responsible use of these technologies.\\nBy implementing these techniques, developers and researchers can create generative AI systems that \\nare transparent, accountable, and aligned with user expectations and ethical principles, fostering trust \\nand enabling widespread responsible adoption of these powerful technologies.\\nBuilding on the foundation of fairness and accountability, let’s explore, in the next couple of sections, \\nhow we can implement some of these practices in real life.\\nImplementing transparency and explainability\\nTransparency and explainability are cardinal characteristics of any trustworthy AI system. Indeed, \\nexplanations of how AI models arrive at their decisions in building content would provide insight \\nfor the users into the reasoning that led to such output, thereby fostering trust and confidence in the \\nreliability of the system.\\nConsider the travel agent scenario, where a generative AI system recommends personalized travel \\nitineraries based on user preferences and historical data. Transparency and explainability are crucial \\nfor building trust in such a system. Users may want to understand why certain destinations or activities \\nwere recommended over others, and how the AI factored in their preferences, budget constraints, \\nand travel histories.\\nAs we saw earlier, techniques such as saliency maps, feature importance, and natural language explanations \\nare some of the XAI techniques that could be used to facilitate transparency and interpretability in \\nan AI system. These methods provide insight into the input features or data points most valued in \\ndriving decisions derived from the AI and how changes in these features would affect the output.Handling uncertainty and biases 201\\nFor instance, saliency maps can highlight the specific aspects of a user’s profile or preferences that \\nwere most influential in generating a particular travel recommendation. This visual representation can \\nhelp users understand the reasoning behind the AI’s decisions and ensure that the recommendations \\nalign with their true preferences.\\nFeature importance techniques can quantify the relative importance of different input features, such \\nas travel history, budget, or desired activities, in shaping the AI’s recommendations. This information \\ncan help users identify any potential biases or misalignments in the AI’s decision-making process and \\nprovide feedback for further improvement.\\nNatural language explanations can provide textual justifications for the AI’s recommendations, \\nexplaining the rationale behind suggesting specific destinations, accommodations, or activities. These \\nexplanations can be particularly valuable for non-technical users, making the AI’s decision-making \\nprocess more accessible and understandable.\\nAnother facet of transparency is the disclosure of limitations and potential risks relevant to generative \\nAI systems. In other words, users should be cognizant of the fact that as powerful as this technology \\nis, it is not perfect and is subject to uncertainties and biases.\\nFor example, a travel recommendation AI system may have limitations in understanding nuanced or \\ncontext-specific preferences, or it may be biased toward popular destinations due to the nature of its \\ntraining data. Developers should set realistic expectations and provide clear guidelines on how the \\ntechnology should be used, acknowledging its strengths and limitations.\\nIn the healthcare domain, transparency and explainability are particularly crucial when AI systems \\nare used for tasks such as diagnosis or treatment recommendations. Physicians and patients need \\nto understand the reasoning behind the AI’s decisions, especially when they contradict established \\nmedical knowledge or guidelines. XAI techniques can help explain the factors that influenced the \\nAI’s decision, allowing healthcare professionals to evaluate the recommendation’s validity and build \\ntrust in the system.\\nHandling uncertainty and biases\\nUncertainty and biases are inherent in AI systems, including generative AI models. Uncertainty might \\narise due to various reasons, such as incompleteness or ambiguity in data, inherently unpredictable \\nevents, or limitations in the model’s knowledge or training process.\\nIn the travel agent scenario, consider a generative AI system that recommends personalized travel \\nitineraries based on user preferences and historical data. Uncertainty can arise from ambiguous or \\nvague user inputs, incomplete or outdated travel information in the training data, or unforeseen events \\nsuch as weather disruptions or local conflicts.\\nTo handle uncertainty, developers could consider probabilistic modeling, Bayesian inference, and \\nuncertainty quantification approaches in generative AI systems. These techniques allow the modelsBuilding Trust in Generative AI Systems 202\\nto yield probabilities or confidence intervals instead of deterministic outputs, update beliefs as new \\ndata arrives, and estimate uncertainties associated with their predictions.\\nFor example, when a user provides a broad prompt such as “I want a romantic trip, ” the AI system \\ncould present multiple potential itinerary options with associated confidence scores or uncertainty \\nestimates, allowing the user to understand the model’s level of confidence and make informed decisions.\\nBiases, on the other hand, can manifest in AI systems due to various factors, including the training \\ndata, algorithmic design, or societal biases. These biases can lead to unfair or discriminatory outcomes, \\nperpetuating historical inequities and undermining trust in the system.\\nIn the travel agent scenario, biases could arise if the training data predominantly features travel \\nexperiences catered to specific demographic groups, income levels, or cultural perspectives. As a result, \\nthe AI system’s recommendations might inadvertently exclude or underrepresent certain communities, \\ntravel preferences, or destinations.\\nAddressing bias in AI systems requires a multilayered approach, including the use of representative and \\ndiverse training data, frequent monitoring and evaluation of model performance, and incorporating \\nfeedback from a diverse range of stakeholders. This helps identify and mitigate potential biases, \\nensuring that the AI system generates fair and inclusive recommendations.\\nFor instance, in the travel recommendation system, developers could implement debiasing algorithms \\nto reduce biases related to factors such as race, gender, or socioeconomic status. Additionally, they \\ncould incorporate human supervision, where travel experts or diverse user groups review and provide \\nfeedback on the AI’s recommendations, helping to identify and correct any biases or oversights.\\nBy addressing the issues of uncertainty and bias, generative AI systems can earn the trust of users \\nand ensure that the technology is used responsibly and ethically. Users can have confidence in the \\nreliability and fairness of the AI-generated outputs, promoting widespread adoption and positive \\nimpact across various domains.\\nSummary\\nTo conclude, trust is the bedrock of generative AI’s successful adoption and responsible use. Transparency \\nand explainability empower users to comprehend the rationale behind AI decisions, fostering confidence \\nand reliability. Advanced techniques, such as saliency maps, feature importance analysis, and natural \\nlanguage explanations, enhance interpretability while addressing uncertainties and biases ensure \\nrobust and equitable outcomes.\\nClear communication, supported by labeling, context, and guidance, equips users to engage with AI \\noutputs responsibly. A comprehensive approach to mitigating bias, ethical development practices, and \\nuser-centric features such as control and consent mechanisms further solidify trust.\\nBy embracing these principles, developers can unlock the transformative potential of generative \\nAI, driving meaningful innovation and societal progress. As this technology evolves, maintaining aQuestions 203\\nsteadfast focus on user trust will pave the way for harmonious collaboration between humans and \\nAI, shaping a future built on accountability, fairness, and shared success.\\nAs we delve deeper into the complexities of generative AI, the next chapter explores critical topics \\nincluding potential risks and challenges, strategies for ensuring safe and responsible AI, ethical \\nguidelines and frameworks, and the vital need to address privacy and security concerns.\\nQuestions\\n1. Why is trust crucial for the adoption of Generative AI systems?\\n2. What role does transparency and explainability play in building trust in AI?\\n3. How do uncertainty and bias affect generative AI systems?\\n4. How can AI developers foster trust through ethical development practices?\\n5. What steps can organizations take to improve user trust in AI-generated outputs?\\nAnswers\\n1. Trust is essential for the widespread and responsible adoption of generative AI. If users lack \\nconfidence in the system’s decision-making process, they will be reluctant to rely on its outputs. \\nTrust influences how users interact with AI, whether they share feedback, provide data, or even \\nadopt the technology in the first place. A lack of trust can lead to skepticism, resistance, and \\neven misuse of AI systems.\\n2. Transparency and explainability help users understand how an AI system arrives at its decisions, \\nmaking it more trustworthy. Transparency operates at two levels:\\n \\x82 Algorithmic transparency – Openness about the model’s architecture, training data, and \\nbiases ensures that AI systems can be assessed for reliability and fairness.\\n \\x82 Presentation transparency (explainability) – AI should clearly communicate its reasoning \\nso users can interpret and trust the output. Techniques like attention visualization, saliency \\nmaps, and natural language explanations help users understand AI-generated decisions.\\n3. Uncertainty and bias can significantly impact the fairness and reliability of generative AI:\\n \\x82 Uncertainty arises when AI lacks sufficient data, receives vague inputs, or encounters \\nunpredictable scenarios. Addressing it requires probabilistic modeling and confidence \\nscoring to communicate uncertainty effectively.\\n \\x82 Bias can be introduced through training data, algorithm design, or societal influences. If not \\nmitigated, biases can lead to unfair or discriminatory outcomes, excluding certain groups \\nor perspectives. Techniques like debiasing algorithms, adversarial training, and diverse data \\ncollection help reduce bias and improve fairness.Building Trust in Generative AI Systems 204\\n4. Ethical AI development requires fairness, privacy, and intellectual property protection:\\n \\x82 Fairness: AI models should be trained on diverse and representative data to avoid biases.\\n \\x82 Privacy: User data should be handled responsibly, following privacy-preserving techniques \\nlike differential privacy and encryption.\\n \\x82 Intellectual property protection : AI-generated content should respect copyrights and \\nprovide proper attribution.\\nBy implementing these principles, developers can build AI systems that users trust and \\nadopt responsibly.\\n5. Organizations can enhance trust by clearly communicating AI-generated outputs, ensuring \\nusers understand their limitations and how to interpret them. Key strategies include:\\n \\x82 Labeling AI-generated content to set clear expectations.\\n \\x82 Providing explanations for recommendations or decisions, ensuring users understand why \\nan output was generated.\\n \\x82 Allowing user control and consent so they can customize AI behavior and influence \\nits decision-making.\\nJoin our communities on Discord and Reddit\\nHave questions about the book or want to contribute to discussions on Generative AI and LLMs? \\nJoin our Discord server at https://packt.link/I1tSU and our Reddit channel at https://\\npackt.link/ugMW0 to connect, share, and collaborate with like-minded enthusiasts.9\\nManaging Safety and \\n Ethical Considerations\\nIn the previous chapter, we explored the pivotal role of trust in facilitating the successful adoption \\nand acceptance of generative AI systems. We examined ways to foster trust, highlighting the role of \\ntransparency, explainability, addressing biases and uncertainties, and clear communication of AI outputs \\nto improve user understanding and confidence. As generative AI technologies rapidly advance, fueled \\nby immense interest and excitement across diverse domains from creative industries to healthcare, a \\nsense of urgency has arisen to address the safety and ethical implications of these powerful systems. \\nThe discussion now turns to potential risks and challenges associated with generative AI, strategies for \\nsafe and responsible deployment, ethical guidelines, and considerations regarding privacy and security.\\nThe remarkable capabilities of generative AI systems have sparked both awe and concern, highlighting \\nthe need for a proactive approach to mitigating potential risks and ensuring responsible development \\nand deployment. While these technologies hold immense potential for driving innovation and positive \\nchange, their misuse or unintended consequences could have far-reaching implications. This chapter \\nis divided into the following main sections:\\n• Understanding potential risks and challenges\\n• Ensuring safe and responsible AI\\n• Exploring ethical guidelines and frameworks\\n• Addressing privacy and security concerns\\nBy the end of this chapter, you will understand the key risks and challenges of generative AI, including \\nmisinformation and bias concerns, know strategies for safe deployment, and have gained insight into \\ncrucial ethical considerations around privacy and data protection. Y ou will also discover frameworks \\nand guidelines for responsible AI development that balance innovation with societal well-being.Managing Safety and Ethical Considerations 206\\nUnderstanding potential risks and challenges\\nThe landscape of AI has evolved significantly with the emergence of large language models (LLMs) \\nthat power both generative AI and agentic systems. While generative AI focuses primarily on creating \\ncontent based on prompts and patterns, agentic systems built on these same LLMs take this capability \\nfurther by incorporating decision-making, planning, and goal-oriented behavior. This combination \\nof generative capabilities with agency creates a powerful but potentially risky synergy.\\nAgentic systems leverage the generative capabilities of LLMs to not just produce content but also to \\nactively analyze situations, formulate strategies, and take action toward specific objectives. This means \\nthat any inherent risks in generative AI systems – such as biases, hallucinations, or the generation \\nof misleading information – become particularly critical when the system is empowered to act \\nautonomously or semi-autonomously based on this generated content.\\nGenerative AI systems are powered by massive language models, which, while incredibly powerful, \\nalso exhibit a range of vulnerabilities and risks. These risks can be broadly classified into the following \\nkey areas.\\nAdversarial attacks\\nOne of the significant risks associated with generative AI systems is their susceptibility to adversarial \\nattacks. Malicious individuals can exploit flaws in these systems by crafting carefully designed inputs \\nor perturbations that corrupt the data in a way that leads to harmful outputs or extracts confidential \\ninformation. These adversarial attacks can have serious consequences, such as data breaches, \\nunauthorized access to sensitive information, or the generation of malicious or misleading content.\\nWhen these vulnerabilities extend to agentic systems, the risks become even more pronounced as \\nthese systems not only generate responses but also execute actions based on their understanding. An \\nadversarial attack on an agentic system could potentially manipulate its decision-making process, causing \\nit to take harmful actions or make dangerous choices autonomously. For instance, an agentic system \\nmanaging supply chain operations could be tricked into making catastrophic inventory decisions, or \\na trading agent could be manipulated into executing harmful financial transactions.\\nIn the travel industry, consider a scenario where an agentic AI system is used by a travel agency to not \\nonly provide personalized travel recommendations but also to automatically book flights, hotels, and \\nactivities. An adversarial attack on such a system could potentially lead to disastrous consequences. \\nBeyond just recommending unsafe destinations, the system could actively make bookings in dangerous \\nareas, confirm reservations with fraudulent providers, or execute financial transactions that compromise \\nclients’ security.\\nAdditionally, adversarial attacks could be used to extract sensitive information, such as customer \\ntravel histories, credit card details, or personal preferences, from the system. This risk is amplified in \\nagentic systems because they often have broader access to execute transactions and make decisions, \\npotentially exposing more sensitive data and control points to attackers.Understanding potential risks and challenges 207\\nReal-world examples of adversarial attacks on AI systems have already been documented. In 2017, \\nresearchers demonstrated how minor perturbations to images could fool state-of-the-art computer \\nvision models into misclassifying objects, such as a stop sign being recognized as a speed limit sign. \\nSimilarly, in the natural language processing domain, researchers have shown how carefully crafted \\ninput sequences can cause language models to generate harmful or inappropriate content. When these \\nvulnerabilities are exploited in agentic systems, the impact could extend beyond content generation \\nto actual real-world actions and decisions.\\nSimilarly, in a medical context, an adversarial attack on an agentic AI system used for diagnosis or \\ntreatment recommendations could potentially lead to life-threatening errors or data leaks. Imagine \\na scenario where an adversarial input causes the AI to not only misdiagnose a condition but also \\nautomatically schedule incorrect treatments, order wrong medications, or make dangerous adjustments \\nto medical devices under its control.\\nThese examples highlight the severe consequences that adversarial attacks can have on both generative \\nand agentic AI systems, underscoring the importance of robust security measures and ongoing \\nresearch into defense mechanisms against such attacks. Techniques such as adversarial training, \\ninput sanitization, and anomaly detection can help mitigate the risks, but it is an ongoing challenge \\nthat requires vigilance and collaboration within the AI community. For agentic systems, additional \\nsafeguards such as action verification, decision auditing, and multi-step authentication processes \\nbecome crucial to prevent malicious exploitation of their autonomous capabilities.\\nBias and discrimination\\nWe are aware that generative AI models are trained on vast datasets that may carry inherent biases and \\nhistorical prejudices. When these models form the foundation for agentic systems, the implications of \\nbias become even more critical as these systems not only generate content but also make autonomous \\ndecisions that can directly impact people’s lives.\\nThe issue of bias in AI systems has been a long-standing concern, and both generative AI models and \\nthe agentic systems built upon them are susceptible to this challenge. These models learn from their \\ntraining data, and if that data contains biases or reflects societal prejudices, the AI will inevitably absorb \\nand perpetuate those biases not just in its outputs but in its decision-making processes and actions too.\\nFor instance, consider an agentic AI system used not just for screening job candidates but also for \\nmaking autonomous hiring decisions, scheduling interviews, and managing employee assignments. If \\nbiased, such a system could systematically discriminate against certain demographic groups throughout \\nthe entire employment life cycle, from initial screening to promotion decisions. This automated \\nperpetuation of bias could be particularly harmful as it operates at scale and may be harder to detect \\nthan human bias.\\nIn the travel industry, bias in agentic AI systems could manifest beyond mere recommendations \\nto actual booking decisions and resource allocations. An autonomous travel management system \\nmight systematically direct certain demographic groups to specific neighborhoods or price ranges,Managing Safety and Ethical Considerations 208\\neffectively implementing digital redlining. It might also autonomously negotiate different rates or \\nterms for different users based on biased assumptions, creating a form of algorithmic discrimination \\nin pricing and service delivery.\\nIn 2018, researchers found that commercial facial recognition systems exhibited higher error rates for \\nidentifying women and people with darker skin tones. When such biased systems are integrated into \\nagentic AI that controls access to buildings, financial services, or healthcare resources, these technical \\nshortcomings transform into systemic barriers that actively restrict opportunities and services for \\ncertain groups.\\nAddressing bias in agentic AI systems requires an expanded approach beyond what’s needed for \\ntraditional generative AI. While diverse training data and debiasing algorithms remain important, \\nadditional measures are needed to ensure fairness in autonomous decision-making. This includes \\nimplementing decision auditing systems, creating accountability frameworks for autonomous actions, \\nand developing real-time bias detection mechanisms that can intervene before discriminatory actions \\nare taken.\\nMoreover, involving diverse stakeholders becomes even more crucial when developing agentic systems, \\nas these stakeholders can help identify potential negative impacts across the full range of autonomous \\nactions the system might take. Regular audits of not just the system’s outputs but also its decision-\\nmaking patterns and action histories are essential for detecting and correcting systematic biases.\\nBy proactively addressing biases in both generative and agentic AI systems, organizations can ensure \\nthese technologies serve as tools for promoting equity rather than reinforcing discrimination. This is \\nparticularly critical for agentic systems, as their ability to autonomously act on biased assumptions \\ncan multiply the harmful effects of discrimination and create self-reinforcing cycles of inequity.\\nMisinformation and hallucinations\\nGenerative AI systems have a tendency to produce information that may be factually incorrect or \\ninconsistent with reality, a phenomenon known as hallucination. When these systems are integrated \\ninto autonomous agents, the implications become even more serious, as hallucinated information can \\ndirectly influence real-world decisions and actions taken by the agent. The hallucination problem in \\nboth generative and agentic AI systems stems from their underlying architecture. While incredibly \\npowerful, these models lack a true understanding of the world and cannot reliably distinguish between \\nfactual information and fabricated content. In agentic systems, this limitation is particularly concerning \\nbecause the agent may act upon hallucinated information without human verification, potentially \\ncausing cascading errors or harmful decisions.\\nIn the realm of autonomous decision-making, an agentic system that hallucinates could take actions \\nbased on non-existent information or false assumptions. For instance, an autonomous trading agent \\nmight execute large financial transactions based on hallucinated market trends, or a healthcare \\nmanagement agent might schedule treatments based on incorrectly generated medical histories. \\nThese scenarios are far more dangerous than simple content generation errors, as they involve direct \\nreal-world consequences.Understanding potential risks and challenges 209\\nFor example, consider an agentic AI system deployed in emergency response management. If the system \\nhallucinates information about the severity or location of an emergency, it could autonomously dispatch \\nresources to the wrong location or make inappropriate response decisions, potentially putting lives at \\nrisk. Unlike a generative system that merely produces incorrect text, an agentic system’s hallucinations \\ncan lead to immediate, real-world actions with serious consequences.\\nIn the travel industry, hallucinations in agentic AI systems could go beyond just providing incorrect \\ninformation – they could result in actual bookings being made based on non-existent flights or hotels, \\nautonomous rerouting of travelers based on hallucinated weather conditions, or emergency evacuations \\ntriggered by fabricated security threats.\\nReal-world examples of hallucinations in AI systems have been documented across various domains. In \\n2022, researchers found that large language models such as GPT-3 can produce hallucinated scientific \\nclaims that sound plausible but are entirely fabricated. For agentic systems built on these models, such \\nhallucinations could lead to automated decisions in research resource allocation, experimental design, \\nor data analysis that could compromise scientific integrity.\\nAddressing hallucinations in agentic AI systems requires additional safeguards beyond those used \\nfor generative AI. While fact-checking and knowledge grounding remain important, agentic systems \\nalso need real-time verification mechanisms, action validation protocols, and fallback procedures \\nfor cases where information reliability is uncertain. Moreover, implementing uncertainty-aware \\ndecision-making processes that can appropriately handle cases where the agent is not confident about \\nits information is crucial.\\nWhen deploying agentic systems, organizations must implement robust monitoring systems that can \\ndetect and prevent actions based on hallucinated information before they occur. This might include \\nmulti-step verification processes for critical decisions, confidence thresholds for autonomous actions, \\nand human oversight mechanisms for high-stakes situations. By proactively addressing hallucinations \\nin agentic AI systems, organizations can better ensure that autonomous agents make decisions based \\non reliable information. This is particularly critical as these systems become more prevalent in domains \\nwhere incorrect actions could have significant consequences for safety, security, or business operations.\\nData privacy violations\\nGenerative AI models are trained on vast amounts of data, which may inadvertently include personally \\nidentifiable information (PII) or sensitive data. In agentic systems, this risk is compounded because \\nthese systems not only process and generate information but also actively access, manipulate, and \\nmake decisions about personal data as part of their autonomous operations.\\nThe sheer volume of data required to train and operate these systems increases the likelihood of \\nprivacy violations. For agentic systems, this risk extends beyond training data to include operational \\ndata that they actively collect and use, such as user interactions, transaction histories, and real-time \\nbehavioral data that helps them make decisions.Managing Safety and Ethical Considerations 210\\nFor example, an agentic AI system in healthcare might not only have access to historical medical \\nrecords for training but also actively manage patient scheduling, treatment plans, and medical device \\nsettings. If such a system mishandles private information, it could autonomously share sensitive medical \\ndetails with unauthorized parties, schedule appointments that reveal confidential conditions, or make \\ntreatment decisions that inadvertently expose protected health information.\\nIn the travel industry, privacy violations could occur when agentic systems go beyond simple data \\nexposure to actively making privacy-compromising decisions. An autonomous travel assistant might \\nnot just leak travel itineraries but could also make bookings that reveal sensitive personal information, \\nautomatically share location data with third parties, or create patterns of behavior that expose confidential \\nbusiness travel or personal relationships. The risks became evident in 2019 when OpenAI’s language \\nmodel was found to have memorized and reproduced portions of its training data such as personal \\ninformation like emails, home addresses, and phone numbers. For agentic systems, similar issues \\ncould lead to automated decisions being made based on memorized private information, potentially \\ncausing systematic privacy violations at scale.\\nAddressing data privacy violations in agentic AI systems requires an enhanced approach beyond \\ntraditional generative AI safeguards. While robust data governance and sanitization remain crucial, \\nagentic systems also need real-time privacy monitoring, decision auditing systems, and automatic \\nprivacy-preserving mechanisms that prevent unauthorized data access or sharing during autonomous \\noperations. Additionally, techniques such as differential privacy must be adapted for dynamic decision-\\nmaking scenarios. Organizations need to implement privacy-aware decision protocols that ensure \\nautonomous actions don’t inadvertently reveal sensitive information through patterns of behavior or \\nchains of decisions, even when individual actions appear privacy-compliant.\\nTo safeguard privacy in these systems, new frameworks must extend beyond traditional data protection \\nmeasures. Teams deploying agentic AI need to scrutinize how autonomous decisions could compromise \\nprivacy across time – watching for subtle patterns that might reveal sensitive information through a \\nseries of seemingly innocent actions. This means rethinking privacy from the ground up: privacy isn’t \\njust about protecting data anymore, but about understanding how chains of autonomous decisions \\ncould inadvertently reveal what should stay hidden.\\nThe most successful deployments of agentic AI will likely be those that make privacy an integral part \\nof their system’s “nervous system” rather than an afterthought. This means building systems that \\ninstinctively protect privacy at every decision point, much like how humans naturally modulate their \\nbehavior to protect sensitive information in different contexts. When privacy becomes part of the \\nagent’s core decision-making process rather than just a compliance checkbox, we can better ensure these \\npowerful systems enhance rather than endanger our privacy rights in an increasingly automated world.\\nIntellectual property risks\\nThe integration of generative AI capabilities into agentic systems introduces complex intellectual \\nproperty challenges that go far beyond traditional content generation concerns. When autonomous \\nagents are empowered to not only create content but also make decisions about how to use, modify, \\nand deploy intellectual property, the stakes become significantly higher.Understanding potential risks and challenges 211\\nThe increasing use of autonomous agents in content generation raises significant concerns about \\nintellectual property (IP) infringement, necessitating robust detection and mitigation strategies. \\nAI-generated content tracking systems such as Copyleaks for plagiarism detection, Google’s SynthID \\nfor watermarking AI-generated images, and Truepic for verifying digital authenticity help identify \\nunauthorized use of copyrighted material. Dataset auditing tools such as Hugging Face’s Dataset \\nCard Standard, LAION’s transparency efforts, and Adobe’s Content Authenticity Initiative (CAI) \\nensure that datasets used by autonomous agents comply with licensing and provenance requirements. \\nAutomated copyright violation detection services, including Microsoft’s Azure Content Moderator, \\nAmazon Rekognition for identifying copyrighted images and logos, and Meta’s Rights Manager for \\nmonitoring IP violations across social platforms, further enhance compliance efforts. Additionally, \\nlegal and policy compliance frameworks, such as WIPO PROOF for timestamping IP ownership (now \\ndiscontinued), IBM’s AI Governance Toolkit for assessing infringement risks, and OpenAI’s licensing \\nagreements that impose API-level restrictions, provide structured safeguards against IP violations. \\nBy integrating these methodologies, organizations can ensure that autonomous agents operate within \\nethical and legal boundaries, minimizing the risks associated with unauthorized content generation \\nand distribution.\\nThe fundamental challenge stems from both the training and operational aspects of these systems. \\nDuring training, agentic AI systems, like their generative counterparts, ingest vast amounts of potentially \\ncopyrighted material – from code and design files to creative works and proprietary business processes. \\nBut unlike purely generative systems, agents can actively implement this learned information in ways \\nthat could systematically violate intellectual property rights at scale and at machine speed.\\nConsider an autonomous software development agent that doesn’t just suggest code snippets but \\nactively writes and deploys applications. Such a system might inadvertently incorporate proprietary \\nalgorithms or protected code patterns across thousands of projects before any violation is detected. \\nSimilarly, in creative industries, an agentic system managing content production could autonomously \\nremix and repurpose copyrighted materials in ways that create complex chains of derivative works, \\neach with its own potential infringement issues.\\nThe real-world implications are already emerging. The 2022 lawsuit against Stability AI’s Stable \\nDiffusion image generator highlighted concerns about training data usage ( https://jipel.\\nlaw.nyu.edu/andersen-v-stability-ai-the-landmark-case-unpacking-the-\\ncopyright-risks-of-ai-image-generators/), but agentic systems raise even thornier \\nquestions. What happens when an AI agent autonomously creates and executes marketing campaigns \\nusing style elements it learned from copyrighted works? Or when it modifies and redistributes protected \\ncontent based on its understanding of fair use?\\nAddressing these challenges requires a radical rethinking of intellectual property protection in an \\nage of autonomous systems. Organizations must develop new frameworks that can anticipate and \\nprevent potential IP violations before they occur, rather than just detecting them after the fact. This \\nmeans implementing real-time monitoring systems that can track the provenance of agent-generated \\ncontent and decision trees that can evaluate IP implications before autonomous actions are taken.Managing Safety and Ethical Considerations 212\\nTechnical innovation will play a crucial role in this evolution. We’re seeing the emergence of new \\napproaches such as blockchain-based content tracking, automated license verification systems, and \\nAI agents specifically designed to audit other agents for potential IP violations. These tools, combined \\nwith traditional legal safeguards, form the foundation of a new approach to IP protection in the age \\nof autonomous systems.\\nAs we navigate this complex landscape, flexibility and adaptation will be key. The legal frameworks \\ngoverning intellectual property were designed for a world of human creators and human decision-\\nmakers. As agentic AI systems become more prevalent, these frameworks will need to evolve – not \\njust to protect existing rights but also to foster innovation in a world where machines are increasingly \\nactive participants in the creative process.\\nEnsuring safe and responsible AI\\nThe deployment of LLM-based agentic systems introduces unique safety and responsibility challenges \\nthat go beyond those of traditional generative AI. While generative AI primarily focuses on content \\ncreation, agentic systems can autonomously plan, decide, and act, making their safe deployment \\nsignificantly more complex and critical. Core safety considerations for agentic systems include \\nthe following:\\n• Action boundaries : Defining strict action boundaries is critical to ensuring that agentic \\nsystems operate within safe and ethical constraints. These boundaries can be enforced using \\npolicy-based governance frameworks such as OpenAI’s Function Calling API and Amazon \\nBedrock Guardrails, which allow agents to interact with external systems while adhering to \\npredefined operational limits. Additionally, role-based access control (RBAC) and context-\\naware permissions can be implemented to restrict agents from taking unauthorized actions, \\nparticularly in high-risk domains such as finance and healthcare.\\n• Decision verification : Agentic systems must incorporate multi-step validation processes \\nfor critical decisions, ensuring robustness and alignment with human oversight. This can be \\nachieved using neural-symbolic reasoning, constraint satisfaction models, and logical verification \\ntechniques that validate each decision against predefined ethical and operational constraints \\nbefore execution. Techniques such as tree search algorithms and Monte Carlo simulations can be \\napplied to evaluate multiple possible outcomes and ensure optimal decision-making in real time.\\n• Rollback capabilities : The ability to undo or reverse autonomous actions is essential for \\nmitigating unintended consequences. This can be implemented through event sourcing and \\nstate management frameworks such as Apache Kafka and Temporal.io, which maintain an \\nimmutable log of agent actions, enabling controlled rollbacks. Version control for decision \\nstates, combined with checkpointing mechanisms, can allow systems to revert to a stable state \\nwhen anomalies or failures are detected.Ensuring safe and responsible AI 213\\n• Real-time monitoring: Continuous monitoring of agent behavior is crucial for detecting \\ndeviations and preventing harmful actions. Anomaly detection models such as Facebook’s \\nAI Anomaly Detection Pipeline and Amazon CloudWatch anomaly detection use machine \\nlearning-based pattern recognition to track behavioral shifts in real time. Additionally, drift  \\ndetection algorithms can identify when an agent’s behavior diverges from expected patterns, \\ntriggering alerts or initiating corrective actions. Explainable AI (XAI) techniques further enhance \\nmonitoring by providing human-readable insights into why an agent made a particular decision.\\n• Reinforcement learning feedback loops: Incorporating human-in-the-loop oversight through \\nreinforcement learning from human feedback  (RLHF) helps fine-tune agentic decision-\\nmaking. By continuously integrating feedback from human reviewers, agents can improve their \\nbehavior over time while maintaining safety and ethical alignment. In high-stakes environments, \\nhybrid AI-human workflows can be used to escalate decisions that require human judgment.\\n• Performance metrics: Evaluating agentic systems requires more than just output quality; it \\nmust also assess decision consistency, ethical alignment, risk assessment, and adaptability. AI \\nauditing tools such as IBM’s AI Fairness 360 and Google’s Explainable AI provide comprehensive \\nevaluation frameworks that measure not only accuracy but also transparency, robustness, and \\nfairness. Additionally, causal inference models can help quantify the impact of agent decisions, \\nensuring alignment with ethical and regulatory standards.\\nBy integrating these technologies and methodologies, organizations can deploy agentic systems that are \\nsafe, transparent, and aligned with regulatory and ethical considerations, reducing the risks associated \\nwith autonomous decision-making while maintaining operational efficiency.\\nLet’s examine how these safety measures manifest in practical deployments. Consider an agentic system \\nmanaging a corporate travel program – beyond just generating recommendations, it actively books \\nflights, adjusts schedules, and manages expenses. A system like this demands layered safety protocols \\nthat address both its generative and autonomous aspects, as highlighted here:\\n• Action boundaries might include financial limits on booking changes without approval, \\nrestrictions on booking destinations flagged as high risk, and rules about when schedule \\nchanges can be made autonomously\\n• Decision verification could involve multi-step checks before finalizing expensive bookings \\n– perhaps requiring human approval for transactions above certain thresholds or automated \\ncross-verification with company travel policies\\n• The system’s rollback capabilities would need to account for real-world constraints, such as \\nairline cancellation policies or hotel booking deadlines, ensuring that autonomous actions \\ndon’t incur unnecessary penalties\\n• Real-time monitoring in this context would track patterns of bookings and expenses, flagging \\nunusual activities such as multiple booking changes in short succession or deviations from \\ntypical corporate travel patternsManaging Safety and Ethical Considerations 214\\n• Performance metrics would go beyond simple measures such as successful bookings to evaluate \\ndecision quality – for instance, assessing whether the system consistently makes cost-effective \\nchoices while respecting traveler preferences and company policies\\nThis travel management example demonstrates how safety measures must be carefully tailored to both \\nprotect against potential risks and ensure efficient operation. The system needs to balance autonomy \\n(such as automatically rebooking disrupted flights) with appropriate caution (such as requiring approval \\nfor significant itinerary changes), all while maintaining clear audit trails and explanation capabilities \\nfor its decisions. Figure 9.1 shows the safety measures for this agentic travel management system:\\nFigure 9.1 – Safety measures for agentic travel management system\\nTesting for agentic systems must be more comprehensive than traditional generative AI testing. \\nWhile generative AI testing focuses on output quality, agentic system testing must evaluate entire \\ndecision chains and action sequences. This includes simulating complex scenarios where the agent \\nmust make interconnected decisions, handle unexpected situations, and maintain safety constraints \\nacross multiple actions.\\nHuman oversight takes on new dimensions with agentic systems. Rather than simply reviewing \\ngenerated content, humans must monitor decision patterns, intervene in complex situations, and help \\nrefine the system’s understanding of acceptable actions. This creates a need for new oversight tools \\nand frameworks that can track and evaluate autonomous behavior in real time.Ensuring safe and responsible AI 215\\nThe concept of safe learning becomes crucial for agentic systems. These systems must be able to learn \\nfrom experience without compromising safety during operation. This might involve creating sandboxed \\nenvironments where agents can safely explore new strategies or implementing gradual automation \\nwhere human oversight is reduced as the system proves its reliability. Critical implementation strategies \\ninclude the following:\\n• Progressive autonomy: Starting with heavily restricted action capabilities and gradually \\nexpanding them based on demonstrated reliability\\n• Contextual safety bounds: Implementing different safety protocols based on the risk level of \\nspecific actions\\n• Continuous validation: Regular assessment of decision patterns to identify potential safety risks\\n• Emergency protocols: Clear procedures for rapid human intervention when needed\\nTrust building with agentic systems requires more than just transparency – it needs demonstrable \\nreliability in autonomous operation. Organizations must develop clear frameworks for communicating \\nboth the capabilities and limitations of their agentic systems, helping stakeholders understand when \\nand how to rely on autonomous decisions.\\nThe ethical deployment of agentic systems also requires careful consideration of societal impact. These \\nsystems must be designed to respect not just individual privacy and rights but also broader social \\nvalues and norms. Implementing explicit ethical constraints in the decision-making process involves \\nencoding predefined ethical rules, fairness constraints, and compliance policies into the system’s logic \\nusing techniques such as constraint programming, rule-based ethics engines, and reinforcement \\nlearning with ethical reward models. For example, symbolic AI approaches can integrate formal ethics \\nrules (e.g., Asimov’s laws of robotics and GDPR privacy requirements) directly into decision-making \\npipelines, ensuring that agents adhere to predefined ethical boundaries. Additionally, differential \\nprivacy mechanisms and bias mitigation algorithms (such as IBM’s AI Fairness 360) can enforce \\nfairness and privacy compliance at runtime.\\nTo ensure ethical adaptability, organizations can implement community feedback loops using human-\\nin-the-loop (HITL) systems, where flagged decisions are reviewed and incorporated into future \\nmodel refinements. Additionally, governance frameworks should include periodic ethical audits, the \\nestablishment of red-teaming exercises to stress-test decision-making under edge cases, and mechanisms \\nfor incorporating stakeholder feedback into system improvements. As agentic systems become \\nmore prevalent, these comprehensive governance measures will be critical in balancing automation \\nwith ethical responsibility, ensuring that AI-driven decisions align with societal expectations and \\nregulatory requirements.\\nBy understanding and addressing these unique challenges of agentic systems, organizations can work \\ntoward deployments that not only leverage the power of autonomous operation but do so in a way \\nthat prioritizes safety, responsibility, and ethical considerations throughout the system’s life cycle.Managing Safety and Ethical Considerations 216\\nExploring ethical guidelines and frameworks\\nAs generative AI systems become increasingly sophisticated and integrated into various aspects of \\nsociety, it is crucial to establish robust ethical guidelines and frameworks to ensure their responsible \\ndevelopment and deployment. A sound ethical framework should encompass a range of principles and \\nguidelines that prioritize human well-being, accountability, privacy protection, and inclusive governance.\\nHuman-centric design\\nAt the core of ethical AI development lies the principle of human-centric design. Generative AI systems \\nshould be designed with a focus on enhancing human well-being and delivering positive experiences. \\nThis requires developing intuitive, accessible, and inclusive solutions that are aligned with human \\nvalues, such as fairness, dignity, and respect for individual autonomy.\\nFor example, in the context of a travel agency, a human-centric generative AI system would prioritize \\npersonalized recommendations that cater to diverse preferences, cultural sensitivities, and accessibility \\nneeds, ensuring that all users can benefit from the technology in a meaningful and respectful manner.\\nAccountability and responsibility\\nOrganizations developing and deploying generative AI systems must be held accountable for the outputs \\nand potential impacts of these technologies. This involves establishing clear lines of responsibility, \\ncomprehensive documentation of decision-making processes, and mechanisms for reviewing and \\naddressing ethical implications.\\nImplementing review boards or advisory committees comprising interdisciplinary experts, including \\nethicists, legal professionals, and representatives from potentially affected communities, can help \\norganizations navigate complex ethical challenges and ensure responsible decision-making.\\nPrivacy and data protection\\nUser privacy and data protection should be embedded as foundational principles in the development \\nof generative AI systems. Organizations must adopt a privacy-by-design approach, practicing data \\nminimization, anonymizing sensitive data, and ensuring that data handling practices comply with \\nrelevant privacy laws and regulations. A privacy-by-design approach ensures that AI systems embed \\nprivacy protections at every stage, minimizing risks while complying with laws such as General Data \\nProtection Regulation (GDPR), California Consumer Privacy Act (C C PA), and Health Insurance \\nPortability and Accountability Act (HIP AA). This includes data minimization (collecting only essential \\ninformation), anonymization (using techniques such as k-anonymity and pseudonymization), and \\nprivacy-preserving machine learning (PPML) methods such as federated learning, homomorphic \\nencryption, and secure multi-party computation (SMPC). For example, in a healthcare AI assistant, \\npatient data can be encrypted and processed locally using federated learning, while role-based access \\ncontrol (RBAC) ensures that only authorized personnel can access sensitive data. Additionally,Addressing privacy and security concerns 217\\nautomated audit logs and explainability tools track decisions for accountability. These techniques help \\norganizations deploy AI responsibly, ensuring privacy without sacrificing functionality.\\nIn the travel industry, this could involve implementing robust data governance frameworks, obtaining \\nexplicit consent from users for data collection and usage, and implementing secure data storage and \\nprocessing mechanisms to protect sensitive information such as travel histories, preferences, and \\npayment details.\\nInvolvement of diverse stakeholders\\nEthical AI development requires the involvement of diverse stakeholders, including ethicists, technologists, \\npolicymakers, and representatives from potentially affected communities. This collaborative approach \\nfosters inclusive dialogue, identifies potential blind spots or unintended consequences, and promotes \\nmore equitable and socially responsible approaches to AI governance.\\nFor instance, in the development of a generative AI system for travel recommendations, engaging \\nwith stakeholders from diverse cultural backgrounds, disability rights advocates, and environmental \\norganizations could help identify potential biases, accessibility barriers, or sustainability concerns, \\nleading to more inclusive and responsible solutions.\\nBy adhering to these ethical guidelines and frameworks, organizations can foster trust, accountability, \\nand responsible innovation in the development and deployment of generative AI technologies. This \\napproach not only mitigates potential risks and unintended consequences but also unlocks the full \\npotential of these powerful technologies to drive positive societal impact while upholding fundamental \\nhuman rights and values.\\nAddressing privacy and security concerns\\nAs generative AI systems become increasingly prevalent across various domains, addressing privacy and \\nsecurity concerns is of utmost importance. Organizations must take proactive measures to safeguard \\nsensitive data, protect against potential breaches, and ensure the resilience of their AI systems against \\nmalicious attacks.\\nIn the context of a travel agency employing a generative AI system for personalized recommendations \\nand itinerary planning, implementing a comprehensive data governance framework is crucial. This \\nframework should outline data handling practices, access controls, and compliance measures to \\nprotect private information within the organization, such as customer travel histories, preferences, \\nand payment details.\\nAccess controls and role-based permissions can help ensure that only authorized personnel can access \\nand modify sensitive data used for training or generating recommendations. Additionally, adhering \\nto relevant data protection laws and industry-specific regulations, such as the GDPR or the Payment \\nCard Industry Data Security Standard (PCI DSS), is essential to maintain compliance and avoid \\npotential legal liabilities.Managing Safety and Ethical Considerations 218\\nIncorporating security considerations into the AI development life cycle is also vital. This includes \\nconducting regular security risk assessments to identify potential vulnerabilities, implementing \\nsecure coding standards to mitigate coding errors or vulnerabilities, and performing regular testing \\nand audits to detect and address any security weaknesses in the AI system. For example, the travel \\nagency could employ penetration testing techniques to simulate potential attack scenarios and assess \\nthe resilience of their generative AI system against adversarial attacks or data breaches. This proactive \\napproach can help identify and address security gaps before they are exploited by malicious actors.\\nEducating users about the potential risks associated with generative AI and providing training on safe \\nusage practices can empower them to make informed decisions and recognize potential threats. In the \\ntravel agency scenario, this could involve educating customers about the importance of safeguarding \\ntheir personal information, recognizing phishing attempts or suspicious communications, and reporting \\nany concerns or incidents promptly.\\nOrganizations should also establish robust incident response plans to deal with potential security breaches \\nor data leaks effectively. These plans should outline clear protocols for rapid response, containment, \\ninvestigation, and mitigation strategies to limit the damage and protect affected individuals or entities.\\nIn the event of a data breach involving customer information, the travel agency should be prepared \\nto swiftly notify affected individuals, regulatory authorities, and stakeholders, while implementing \\nmeasures to secure the compromised systems and prevent further data loss.\\nAdditionally, techniques such as adversarial training and anomaly detection can help improve the \\nresilience of generative AI systems against adversarial attacks specifically. Adversarial training involves \\nexposing the AI model to carefully crafted adversarial examples during the training process, enhancing \\nits ability to recognize and defend against such attacks. Anomaly detection algorithms can identify and \\nflag suspicious or anomalous inputs or outputs, enabling timely intervention and mitigation efforts. \\nBy prioritizing privacy and security considerations throughout the AI development and deployment \\nlife cycle, organizations can foster trust and confidence in their generative AI systems, while ensuring \\ncompliance with relevant regulations and safeguarding sensitive data and intellectual property.\\nSummary\\nIn this chapter, we discovered that while advanced intelligent agentic systems hold immense potential \\nto drive innovation, enhance creativity, and revolutionize various industries, their deployment and \\ndevelopment must be approached with utmost care and responsibility. Armed with awareness of \\nthe potential risks and challenges associated with generative AI, organizations and stakeholders can \\nproactively implement measures to ensure safety, uphold ethical principles, and address privacy and \\nsecurity concerns. By doing so, they can harness the transformative power of these technologies in a \\ntrustworthy and accountable manner, fostering confidence among users and stakeholders. Embracing \\na proactive and responsible approach to generative AI development involves implementing robust \\ntesting and monitoring frameworks, adhering to ethical guidelines and frameworks that prioritize \\nhuman well-being, accountability, and inclusive governance, and establishing comprehensive data \\ngovernance and security protocols to safeguard sensitive information and intellectual property.Questions 219\\nIt is crucial to address the uncertainties and biases in AI systems. By employing techniques such as \\nprobabilistic modeling, uncertainty quantification, and debiasing algorithms, developers can improve the \\nreliability and fairness of generative AI models, fostering trust and responsible adoption. Collaboration \\namong stakeholders, including developers, researchers, policymakers, and ethicists, is essential for \\nnavigating the challenges and ethical implications of generative AI. An inclusive, multidisciplinary \\napproach helps identify blind spots, mitigate unintended consequences, and align solutions with \\nhuman values. Agentic systems heighten AI risks by autonomously acting on biased or compromised \\ninformation, making robust safety measures, including action boundaries, decision verification, and \\nreal-time monitoring, critical. Effective deployment requires balancing autonomy with appropriate \\nhuman oversight, especially for high-stake decisions. Privacy protection must extend beyond data \\nsafeguards to account for the potential exposure of sensitive information through autonomous \\ndecisions. Additionally, intellectual property frameworks must evolve to handle AI agents as active \\ncreators, with real-time monitoring and verification systems in place.\\nIn the next chapter, we will explore some of the common use cases and applications of LLM-based \\nintelligent agents using various patterns and techniques that we’ve learned so far.\\nQuestions\\n1. How do the risks of hallucination differ between generative AI and agentic systems? Why are \\nhallucinations potentially more dangerous in agentic systems?\\n2. What are the core safety considerations that need to be implemented when deploying \\nLLM-based agentic systems, and how do they manifest in a practical example such as a travel \\nmanagement system?\\n3. How does bias in agentic AI systems differ from bias in traditional generative AI systems, and \\nwhat additional measures are needed to address it?\\n4. What unique challenges do agentic systems pose for data privacy compared to traditional \\ngenerative AI systems, and how should organizations address these challenges?\\n5. How do intellectual property risks evolve when moving from generative AI to agentic systems, \\nand what new approaches are needed to address these risks?\\nAnswers\\n1. In generative AI, hallucinations primarily result in incorrect content generation, but in agentic \\nsystems, hallucinated information can directly influence real-world decisions and actions. For \\nexample, while a generative AI might simply produce incorrect text, an agentic system might \\nexecute financial transactions based on hallucinated market trends or make medical decisions \\nbased on fabricated patient histories. This is more dangerous because it leads to immediate \\nreal-world consequences without human verification.Managing Safety and Ethical Considerations 220\\n2. Core safety considerations include action boundaries, decision verification, rollback capabilities, \\nreal-time monitoring, and performance metrics. In a travel management system, they manifest \\nas financial limits on booking changes, multi-step checks for expensive bookings, mechanisms \\nto handle cancellation policies, tracking of booking patterns for anomalies, and evaluation of \\ndecision quality against company policies and traveler preferences. These measures ensure both \\nprotection against risks and efficient operation.\\n3. Bias in agentic systems goes beyond generating biased content to actively making biased \\ndecisions that affect people’s lives. For example, while a generative AI might produce biased text, \\nan agentic system could systematically discriminate in hiring decisions or resource allocations. \\nAdditional measures needed include decision auditing systems, accountability frameworks \\nfor autonomous actions, real-time bias detection mechanisms, and regular audits of decision-\\nmaking patterns and action histories.\\n4. Agentic systems not only process and generate information but actively access, manipulate, \\nand make decisions about personal data during operations. They need enhanced safeguards \\nincluding real-time privacy monitoring, decision auditing systems, and privacy-aware decision \\nprotocols. Organizations must scrutinize how chains of autonomous decisions could reveal \\nsensitive information over time, even when individual actions appear privacy-compliant, and \\nmake privacy an integral part of the system’s decision-making process.\\n5. Agentic systems can actively implement learned information and make decisions about intellectual \\nproperty use at machine speed and scale. For example, they might autonomously incorporate \\nproprietary code across thousands of projects or create complex chains of derivative works. \\nNew approaches needed include real-time monitoring systems for content provenance, decision \\ntrees for evaluating IP implications before actions, blockchain-based content tracking, and \\nautomated license verification systems. Legal frameworks need to evolve to handle machines \\nas active participants in the creative process.\\nJoin our communities on Discord and Reddit\\nHave questions about the book or want to contribute to discussions on Generative AI and LLMs? \\nJoin our Discord server at https://packt.link/I1tSU and our Reddit channel at https://\\npackt.link/ugMW0 to connect, share, and collaborate with like-minded enthusiasts.10\\nCommon Use Cases and \\nApplications\\nBuilding upon our previous examination of risks and challenges in LLM-based agent systems, from \\nadversarial attacks to ethical concerns, we now turn our attention to their practical applications. This \\nchapter explores how agentic systems are transforming various domains by combining LLMs with \\ngoal-directed behavior and autonomous decision-making capabilities. We’ll see how these agents can \\nunderstand context, formulate plans, and take action to achieve specific objectives while maintaining \\nmeaningful interactions with humans.\\nAs we explore these applications, we will focus on how agents leverage LLMs not just as language \\nprocessors but also as core reasoning engines that enable sophisticated planning and execution \\nacross different domains. This represents a fundamental shift from traditional AI systems, as these \\nagents can now adapt their behavior, learn from interactions, and operate with increasing levels of \\nautonomy while maintaining alignment with human intentions. The chapter begins by exploring \\nthe transformative impact of LLM-based agents in creative and artistic domains, followed by their \\nadvancements in natural language processing and conversational systems. It then delves into the \\nintegration of these agents within robotics and autonomous systems, culminating in their role in \\ndecision support and optimization.\\n The chapter is structured into four main sections:\\n• Creative and artistic applications\\n• Natural language processing and conversational agents\\n• Robotics and autonomous systems\\n• Decision support and optimizationCommon Use Cases and Applications 222\\nBy the end of this chapter, you will understand how LLM-based agents are reshaping our approach \\nto automation and human-AI collaboration across different domains. This knowledge will help you \\nidentify opportunities for deploying agentic systems in your own fields while maintaining awareness \\nof the unique capabilities and considerations that come with these more autonomous and interactive \\nAI systems.\\nCreative and artistic applications\\nThe integration of LLM-based agents in creative fields marks a significant evolution beyond simple \\ngenerative AI tools. This section explores how agentic systems are transforming creative workflows \\nthrough their ability to understand context, maintain creative direction, and actively collaborate \\nwith human artists. Unlike traditional AI tools that simply generate content, these agents can engage \\nin sustained creative dialogues, adapt to changing requirements, and balance multiple artistic and \\ntechnical constraints simultaneously.\\nEvolution of creative and artistic agents\\nThe development of creative and artistic agents represents a paradigm shift in how AI systems \\ncontribute to the creative process. Early generative AI tools focused primarily on producing static \\noutputs based on predefined prompts, offering limited interaction and adaptability. Modern agentic \\nsystems, however, have evolved to actively participate in dynamic and iterative creative processes. \\nThey leverage advanced capabilities such as context retention, adaptive learning, and multi-modal \\nintegration to function as true collaborators rather than passive tools. These agents not only generate \\ncontent but also understand artistic intent, refine outputs based on feedback, and align with human \\ncollaborators’ vision. This evolution underscores a broader trend in AI development, moving from \\nstatic generation to interactive, context-aware, and adaptive systems that complement and enhance \\nhuman creativity in unprecedented ways. Key areas where agentic systems are making an impact \\ninclude the following:\\n• Artistic collaboration: Agents that can assist artists by maintaining a consistent style, artistic \\nintent, and thematic coherence across multiple iterations, enabling seamless integration of \\nhuman creativity with AI-generated enhancements\\n• Music composition: Systems that are designed to understand and apply musical theory, \\nadapt to different genres, and collaborate in real time with performers or composers to create \\nharmonious and innovative compositions\\n• Writing and narrative development: Agents that can co-create with authors by maintaining \\ncharacter consistency, plot coherence, and narrative flow, offering creative suggestions while \\npreserving the author’s unique voice and storytelling styleCreative and artistic applications 223\\nReal-world applications\\nThe practical implementation of agentic systems in creative fields has already begun to show promising \\nresults. Adobe’s Firefly agent system demonstrates how multiple specialized agents can maintain \\ncreative consistency across complex projects. In this system, different agents work in concert: one \\nmaintains brand identity and style guidelines, another ensures consistent asset representation across \\nvarious media, and a third handles technical specifications and format requirements. This represents \\na significant evolution from simple generative tools to a collaborative system that maintains creative \\ncontext and adapts to user feedback in real time.\\nSimilarly, Universal Music Group’s AI-powered music production system showcases how agentic \\nsystems can maintain creative coherence in musical composition. The system employs specialized agents \\nfor different aspects of music creation: melody agents that understand musical themes and motifs, \\nharmony agents that maintain tonal consistency, and orchestration agents that handle instrumental \\narrangement. These agents work together while preserving the composer’s creative intent and style \\npreferences throughout the production process, demonstrating how multiple agents can collaborate \\non complex creative tasks while maintaining artistic vision.\\nTo better understand how agentic systems can transform complex creative workflows, let’s examine a \\ndetailed use case from the film industry. This example demonstrates how multiple agents can collaborate \\nto bridge the gap between creative vision and technical execution, a challenge that has long plagued \\nthe pre-visualization process in film production.\\nProblem statement\\nFilm directors and storyboard artists spend considerable time iterating on pre-visualization sequences, \\nrequiring constant communication between multiple departments to align creative vision with \\ntechnical feasibility. Traditional tools lack the ability to understand and adapt to creative intent while \\nconsidering technical constraints. The goal is to create a multi-agent system that assists in translating \\nthe director’s creative vision into technically feasible pre-visualization sequences while maintaining \\nartistic coherence and production constraints.\\nThe agentic system approach is as follows:\\n• Director agent:\\n \\x82 Processes natural language descriptions of scenes\\n \\x82 Maintains overall creative vision and style consistency\\n \\x82 Communicates artistic intent to other agentsCommon Use Cases and Applications 224\\n• Technical supervisor agent:\\n \\x82 Evaluates technical feasibility\\n \\x82 Considers budget and resource constraints\\n \\x82 Proposes alternative solutions when needed\\n• Visualization agent:\\n \\x82 Generates initial storyboards and 3D previews\\n \\x82 Adapts output based on feedback from other agents\\n \\x82 Maintains visual consistency across scenes\\nThe agents work together through the following means:\\n• Shared context understanding via LLM capabilities\\n• Continuous feedback loops between creative and technical requirements\\n• Real-time adaptation to changes in either creative direction or technical constraints\\nEnvironment and external systems\\nThe multi-agent system operates within a production environment that includes the following:\\n• Asset management database: Stores 3D models, textures, and previous storyboards\\n• Production management system: Tracks budgets, schedules, and resource allocation\\n• Rendering farm API: Manages compute resources for 3D visualization\\n• Camera and equipment database: Technical specifications and availability\\n• Reference library: Archive of past productions, style guides, and mood boards\\n• Version control system: Maintains history of iterations and changes\\n• Collaboration platform: Enables real-time feedback from team members\\nWhy this is better\\nCurrent pre-visualization tools operate in isolation, requiring human intermediaries to translate \\nbetween creative and technical requirements. An agentic system approach provides several advantages:\\n• Continuous alignment between creative vision and technical feasibility\\n• Reduced iteration cycles through real-time collaboration\\n• Ability to maintain creative consistency while adapting to constraints\\n• More efficient resource utilization through automated technical validationNatural language processing and conversational agents 225\\nThis approach highlights how agentic systems go beyond simple content generation to actively contribute \\nto creative decision-making processes, addressing multiple constraints and objectives with nuanced \\nunderstanding. Their success in pre-visualization underscores their broader applicability in creative \\ndomains that require complex collaboration, iterative refinement, and the ability to adapt to evolving \\nartistic visions. By retaining context, understanding intent, and balancing competing priorities, these \\nsystems are emerging as indispensable creative partners rather than mere tools.\\nHaving explored their transformative impact on creative workflows, we now shift our focus to one of the \\nmost groundbreaking applications of agentic systems: natural language processing and conversational \\ninterfaces. These systems excel at understanding nuanced language, maintaining context in complex \\ndialogues, and executing tasks effectively, making them essential for fostering meaningful human-AI \\ninteractions – a topic we’ll delve into in the next section.\\nNatural language processing and conversational agents\\nBuilding on our exploration of creative applications, we now turn to perhaps the most natural domain \\nfor LLM-based agents: language understanding and conversation. While traditional language models \\ncan process and generate text, agentic systems add crucial capabilities: maintaining context over long \\ninteractions, executing complex tasks through dialogue, and adapting their responses based on user \\nneeds and feedback.\\nEvolution of language agents\\nToday’s conversational agents represent a significant leap beyond simple chatbots or virtual assistants. \\nThese systems can maintain complex dialogues, understand nuanced contexts, and execute sophisticated \\ntasks through natural conversation. For example, Anthropic’s Claude and OpenAI’s ChatGPT \\ncan engage in detailed technical discussions while maintaining consistency across multiple turns, \\nadapting responses based on the user’s level of expertise and previous interactions. Key capabilities \\nthat distinguish modern language agents from traditional chatbots are as follows:\\n• Context retention: Modern language agents excel at maintaining coherent and meaningful \\ndiscussions, even as conversations evolve across multiple topics and sessions. This ability to \\nremember prior exchanges allows them to provide more personalized and contextually relevant \\nresponses over time.\\n• Task execution: These agents go beyond simple Q&A functionality by translating natural \\nlanguage instructions into actionable steps, enabling seamless task completion in areas such \\nas scheduling, data retrieval, or system configuration. This capability bridges the gap between \\ncommunication and execution.\\n• Adaptive interaction: Modern agents dynamically adjust their communication style, tone, \\nand complexity to suit user preferences, expertise levels, or situational needs, fostering more \\nengaging and accessible interactions for diverse audiences.Common Use Cases and Applications 226\\n• Multi-modal understanding: Unlike traditional chatbots, modern agents can process and \\nrespond to combinations of text, images, code, and structured data, enabling them to tackle \\nmore complex queries and integrate diverse forms of information for a richer, more nuanced \\nunderstanding of user requests.\\nReal-world applications\\nCurrent implementations demonstrate the versatility of language agents across different domains. \\nFor instance, Salesforce’s Agentforce (formerly the Einstein virtual assistant) helps customer service \\nrepresentatives by maintaining context across multiple customer interactions while accessing relevant \\ndatabase information in real time. Similarly, GitHub’s Copilot Chat can maintain technical discussions \\nabout code while executing relevant development tasks. Let’s take a look at a use case involving an \\nenterprise knowledge management system.\\nProblem statement\\nLarge organizations struggle with knowledge fragmentation across departments, making it difficult \\nfor employees to access and utilize institutional knowledge effectively. Traditional search systems \\nand documentation fail to capture context and connections between different pieces of information.\\nTo solve the problem, create a multi-agent system that can understand, organize, and retrieve corporate \\nknowledge while maintaining context and handling complex queries that span multiple domains \\nand documents.\\nHere’s the agentic system approach:\\n• Query understanding agent:\\n \\x82 Processes natural language questions\\n \\x82 Identifies implicit context and requirements\\n \\x82 Breaks down complex queries into subtasks\\n• Knowledge navigation agent:\\n \\x82 Maps relationships between different knowledge sources\\n \\x82 Maintains context across multiple documents\\n \\x82 Tracks information provenance\\n• Response synthesis agent:\\n \\x82 Combines information from multiple sources\\n \\x82 Adapts response detail level to user role\\n \\x82 Maintains consistency across multiple interactionsNatural language processing and conversational agents 227\\nThe agents collaborate through the following means:\\n• A shared understanding of organizational context\\n• Continuous learning from user interactions\\n• Dynamic adaptation to different user roles and needs\\nEnvironment and external systems\\nThe knowledge management system interfaces with multiple corporate systems and data sources:\\n• Internal systems:\\n \\x82 Document management system: SharePoint, Confluence, and internal wikis\\n \\x82 Communication platforms: Slack and MS Teams\\n \\x82 Project management tools: Jira and Asana project documentation\\n \\x82 Email servers: Archived email threads and attachments\\n \\x82 Code repositories: GitHub and GitLab documentation and discussions\\n \\x82 HR systems: Training materials and policy documents\\n \\x82 Customer relationship management: Customer interaction histories and support tickets\\n• External APIs and services:\\n \\x82 Industry news APIs: Bloomberg or Reuters for market updates\\n \\x82 Research databases: Academic papers and patent databases\\n \\x82 Regulatory databases: Compliance documentation and legal updates\\n \\x82 Cloud storage: Google Drive or OneDrive for shared documents\\n \\x82 Translation services: For multilingual document processing\\n \\x82 Web monitoring: Social media and competitor websites\\n• Access control layer:\\n \\x82 Role-based access management system\\n \\x82 Security classification database\\n \\x82 User authentication service\\n \\x82 Audit logging system\\n \\x82 Compliance monitoring toolsCommon Use Cases and Applications 228\\nWhy this is better\\nTraditional knowledge management systems rely on exact keyword matches and predefined categories. \\nAn agentic approach offers several advantages:\\n• Natural language understanding of complex queries\\n• Context-aware information retrieval\\n• Dynamic connection of related information\\n• Personalized responses based on user role and expertise\\nThis approach to knowledge management demonstrates how agentic systems can transform information \\naccess and utilization within organizations, making institutional knowledge more accessible and \\nactionable. As we’ve seen how language agents can revolutionize information access and communication, \\nwe now turn our attention to their physical world applications in robotics and autonomous systems. \\nThe ability to combine language understanding with physical control creates new possibilities for \\nhuman-robot interaction, which we’ll explore in the next section.\\nRobotics and autonomous systems\\nMoving from language-based interactions to physical world applications, we now explore how \\nLLM-based agents are transforming robotics and autonomous systems. While traditional robots rely \\non pre-programmed behaviors and rigid control systems, agentic systems enable robots to understand \\nnatural language instructions, reason about their environment, and adapt their behavior dynamically. \\nThis integration of language models with physical control systems represents a fundamental shift in \\nhow robots interact with both humans and their environment.\\nEvolution of robotic agents\\nThe marriage of LLMs with robotics has created systems that can bridge the gap between human \\nintent and physical action. Unlike traditional robotic systems that operate on fixed rules, modern \\nrobotic agents can understand context, learn from experience, and make autonomous decisions while \\nmaintaining alignment with human objectives. Here are the key capabilities that distinguish modern \\nrobotic agents:\\n• Natural language understanding for physical tasks\\n• Contextual reasoning about environmental constraints\\n• Real-time adaptation to changing conditions\\n• Learning from demonstration and feedback\\n• Multi-modal integration of vision, language, and controlRobotics and autonomous systems 229\\nReal-world applications\\nCurrent implementations showcase the versatility of agentic systems across various domains. At Boston \\nDynamics, robots such as Atlas demonstrate how language-based instruction can be translated into \\ncomplex physical movements. Similarly, UC Berkeley’s robotic systems show how generative models \\nenable real-time adaptation to cluttered environments, while MIT’s RoboBrain system illustrates \\nhow agents can creatively solve physical manipulation tasks by drawing on vast knowledge bases. \\nLet’s consider a real use case and evaluate how an agentic system may help implement such a system.\\nProblem statement\\nTraditional manufacturing cells struggle with product variation and unexpected disruptions. Current \\nsystems require extensive reprogramming for new products and can’t effectively handle unexpected \\nsituations such as equipment failures or supply chain disruptions. Human operators must constantly \\nintervene to manage changes and optimize workflows. The goal is to create a multi-agent system \\nthat orchestrates a flexible manufacturing cell, capable of adapting to product variations, handling \\ndisruptions, and optimizing processes while maintaining quality standards and safety protocols.\\nLet’s look at the agentic system approach:\\n• Planning and coordination agent:\\n \\x82 Understands natural language production requirements\\n \\x82 Develops and adapts manufacturing sequences\\n \\x82 Coordinates between different robotic systems\\n \\x82 Maintains overall production goals\\n• Robot control agent:\\n \\x82 Translates high-level instructions into motion primitives\\n \\x82 Manages real-time sensor feedback\\n \\x82 Adapts movements based on environmental changes\\n \\x82 Ensures safe human-robot interaction\\n• Quality and optimization agent:\\n \\x82 Monitors production quality in real time\\n \\x82 Suggests process improvements\\n \\x82 Predicts maintenance needs\\n \\x82 Optimizes resource utilizationCommon Use Cases and Applications 230\\n• Exception handling agent:\\n \\x82 Detects anomalies and disruptions\\n \\x82 Generates recovery strategies\\n \\x82 Manages unexpected human interventions\\n \\x82 Maintains safety protocols during exceptions\\nThe agents collaborate through the following means:\\n• A shared understanding of the manufacturing context\\n• Real-time sensor data integration\\n• Continuous feedback loops for process optimization\\n• Dynamic task reallocation during disruptions\\nEnvironment and external systems\\nThe manufacturing system interfaces with several systems:\\n• Manufacturing infrastructure:\\n \\x82 Robotic arms and end effectors: Multiple robot types with different capabilities\\n \\x82 Vision systems: Cameras and 3D sensors for part recognition and quality control\\n \\x82 PLC systems: Programmable logic controllers (PLCs) for equipment control\\n \\x82 Material handling systems: Conveyors, automated guided vehicles (AGVs), and storage systems\\n• Information systems:\\n \\x82 Manufacturing execution system (MES): Production scheduling and tracking\\n \\x82 Enterprise resource planning (ERP): Resource and inventory management\\n \\x82 Quality management system (QMS): Quality data and specifications\\n \\x82 Digital twin platform: Real-time simulation and prediction\\n \\x82 Maintenance management system: Equipment health monitoringDecision support and optimization 231\\n• External interfaces:\\n \\x82 Supply chain management system: Material availability and logistics\\n \\x82 Customer order system: Product specifications and requirements\\n \\x82 Compliance database: Safety standards and regulatory requirements\\n \\x82 Knowledge base: Historical production data and best practices\\nWhy this is better\\nTraditional robotic manufacturing systems rely on rigid programming and require extensive human \\nintervention for adaptations. An agentic system approach offers several transformative advantages:\\n• Natural language interaction for production changes and problem-solving\\n• Real-time adaptation to product variations without reprogramming\\n• Autonomous handling of disruptions and exceptions\\n• Continuous optimization based on historical and real-time data\\n• Seamless integration of human expertise when needed\\n• Proactive quality control and maintenance prediction\\nThis approach fundamentally transforms manufacturing flexibility by enabling robots to understand \\ncontext, adapt to changes, and make autonomous decisions while maintaining alignment with production \\ngoals and safety requirements. The success of agentic systems in manufacturing demonstrates their \\npotential in complex physical environments where multiple systems must coordinate while adapting \\nto changing conditions. By combining language understanding with physical control and real-time \\noptimization, these systems are evolving from simple automation tools to intelligent collaborators in \\nthe manufacturing process.\\nAs we conclude our exploration of robotics and autonomous systems, we turn our attention to how \\nagentic systems are transforming business operations through decision support and optimization. \\nThe ability to process complex data streams while maintaining business context makes these systems \\nparticularly valuable for strategic decision-making, which we’ll examine in the next section.\\nDecision support and optimization\\nHaving explored the physical world applications of agentic systems, we now turn to their role in \\naugmenting human decision-making and solving complex optimization problems. While traditional \\ndecision support systems rely on fixed rules and static analysis, LLM-based agents can understand \\ncontext, reason about trade-offs, and provide adaptive recommendations while maintaining alignment \\nwith business objectives and constraints.Common Use Cases and Applications 232\\nEvolution of decision support agents\\nThe integration of LLMs with decision support systems has transformed how organizations process \\ninformation and make strategic choices. Modern decision agents can analyze multiple data streams, \\nunderstand complex business contexts, and generate actionable insights while maintaining awareness \\nof organizational goals and constraints. Key capabilities that distinguish modern decision support \\nagents are as follows:\\n• Multi-modal data analysis and synthesis\\n• Context-aware recommendation generation\\n• Real-time adaptation to changing conditions\\n• Explanation of reasoning and trade-offs\\n• Integration of domain expertise with data-driven insights\\nReal-world applications\\nCurrent implementations demonstrate the versatility of agentic systems across various domains:\\n• Financial sector:\\n \\x82 JPMorgan Chase’s LOXM system analyzes market data, news, and social media to identify \\ninvestment opportunities\\n \\x82 Two Sigma’s Venn system combines market analysis with reinforcement learning for \\ninvestment strategies\\n• Healthcare:\\n \\x82 University of Michigan’s HealthPal provides personalized treatment recommendations by \\nanalyzing medical records and genetic data\\n \\x82 Stanford’s DeepPill system optimizes drug therapies based on patient profiles and medical history\\n• Industrial applications:\\n \\x82 Siemens’ MindSphere optimizes manufacturing processes through real-time analysis \\nand adaptation\\n \\x82 ExxonMobil’s Energy Outlook uses predictive modeling for long-term resource planning\\nThe complexity of modern supply chains offers a compelling example of how agentic systems can \\ntransform traditional business processes. Let’s examine a real-world implementation where multiple \\nagents work together to orchestrate a global supply chain network, demonstrating how these systems \\ncan handle complex, multi-stakeholder environments while maintaining business objectives.Decision support and optimization 233\\nProblem statement\\nGlobal supply chains face unprecedented complexity with multiple stakeholders, variable lead times, and \\nfrequent disruptions. Traditional optimization tools struggle to handle the dynamic nature of modern \\nsupply chains and can’t effectively balance competing objectives such as cost, speed, and sustainability. \\nHuman planners are overwhelmed by the volume of data and the speed of required decisions. Here, \\nwe aim to create a multi-agent system that orchestrates end-to-end supply chain optimization, capable \\nof real-time decision-making while balancing multiple objectives and adapting to disruptions.\\nThe agentic system approach is as follows:\\n• Strategic planning agent:\\n \\x82 Analyzes market trends and demand patterns\\n \\x82 Develops long-term sourcing strategies\\n \\x82 Balances cost, risk, and sustainability goals\\n \\x82 Maintains alignment with business objectives\\n• Operational optimization agent:\\n \\x82 Manages day-to-day logistics operations\\n \\x82 Optimizes routing and resource allocation\\n \\x82 Handles real-time scheduling adjustments\\n \\x82 Coordinates with multiple carriers and warehouses\\n• Risk management agent:\\n \\x82 Monitors global events and disruptions\\n \\x82 Assesses impact on supply chain operations\\n \\x82 Generates contingency plans\\n \\x82 Provides early warning signals\\n• Sustainability optimization agent:\\n \\x82 Tracks environmental impact metrics\\n \\x82 Optimizes for carbon footprint reduction\\n \\x82 Suggests alternative routing and sourcing\\n \\x82 Ensures compliance with environmental regulationsCommon Use Cases and Applications 234\\nThe agents collaborate through the following means:\\n• A shared understanding of the supply chain context\\n• Real-time data integration and analysis\\n• Continuous scenario planning and risk assessment\\n• Dynamic re-optimization based on changing conditions\\nEnvironment and external systems\\nThe supply chain system interfaces with multiple corporate systems and data sources:\\n• Core infrastructure:\\n \\x82 ERP systems:\\n \\x8f SAP and Oracle for business operations data\\n \\x8f Inventory management systems\\n \\x8f Production planning systems\\n \\x82 Transportation management systems (TMSs):\\n \\x8f Real-time fleet tracking\\n \\x8f Carrier management platforms\\n \\x8f Route optimization engines\\n \\x82 Warehouse management systems (WMSs):\\n \\x8f Inventory tracking and optimization\\n \\x8f Labor management\\n \\x8f Order fulfillment systems\\n• External data sources:\\n \\x82 Market intelligence platforms:\\n \\x8f Bloomberg or Reuters for market data\\n \\x8f Industry-specific news feeds\\n \\x8f Social media monitoring systemsDecision support and optimization 235\\n \\x82 Weather and environmental systems:\\n \\x8f Global weather forecasting\\n \\x8f Natural disaster tracking\\n \\x8f Environmental impact monitoring\\n \\x82 Supplier networks:\\n \\x8f Supplier performance databases\\n \\x8f Capacity and capability tracking\\n \\x8f Risk assessment platforms\\n• Integration layer:\\n \\x82 API management system\\n \\x82 Real-time data streaming platform\\n \\x82 Event processing engine\\n \\x82 Document management system\\n \\x82 Blockchain network for traceability\\nWhy this is better\\nTraditional supply chain optimization systems operate with limited context and struggle to adapt to \\nrapid changes. An agentic system approach provides several transformative advantages:\\n• Natural language interaction for strategy development and problem-solving\\n• Real-time adaptation to multiple changing variables\\n• Proactive risk identification and mitigation\\n• Balanced optimization across multiple competing objectives\\n• Integration of human expertise at strategic decision points\\n• Continuous learning and improvement from historical decisions\\nThis approach fundamentally transforms supply chain management by enabling intelligent, context-\\naware decision-making that considers multiple stakeholders and objectives while maintaining alignment \\nwith business goals and sustainability requirements.\\nThe success of agentic systems in supply chain optimization demonstrates their potential in complex \\nbusiness environments where multiple factors must be balanced while adapting to constant change. By \\ncombining language understanding with advanced optimization techniques and real-time adaptation, \\nthese systems are evolving from simple decision-support tools to trusted strategic advisors.Common Use Cases and Applications 236\\nSummary\\nIt is now time to conclude our deep dive into the applications of agentic systems powered by LLMs. \\nIn this chapter, we witnessed their transformative impact across diverse domains. These systems \\nrepresent more than just technological advancement – they mark a fundamental shift in how AI can \\nunderstand, reason about, and participate in complex human endeavors.\\nThroughout this chapter, we explored four key domains where agentic systems are reshaping \\npossibilities: creative applications, natural language processing, robotics, and decision support. \\nWhile these domains showcase significant developments, they represent only a fraction of the areas \\nin which agentic systems are making an impact. From education and scientific research to healthcare \\nand environmental protection, these systems are finding novel applications across numerous fields \\nnot covered in this chapter.\\nThe real-world applications we’ve explored – from collaborative film pre-visualization to manufacturing \\ncell orchestration, and from enterprise knowledge management to supply chain optimization – \\ndemonstrate how agentic systems are becoming valuable partners rather than just tools. They show \\nus that the future of AI lies not in replacing human capabilities but in augmenting them through \\nintelligent collaboration.\\nIn the final chapter, we’ll review key concepts of agentic systems, explore emerging tools and research, \\nand discuss the possibilities and challenges of artificial general intelligence and artificial superintelligence, \\nconcluding with the challenges and opportunities ahead as these technologies evolve.\\nQuestions\\n1. How do agentic systems in creative applications differ from traditional generative AI tools? \\nDiscuss with an example from the chapter.\\n2. In the context of manufacturing cell orchestration, explain how multiple agents work together \\nand why this approach is more effective than traditional automation systems.\\n3. Compare and contrast the role of agentic systems in robotics versus decision support systems. \\nHow do their approaches to maintaining context differ?\\n4. Using the enterprise knowledge management use case from the chapter, explain how different \\nagents collaborate to solve complex information retrieval problems.\\n5. The chapter discussed the supply chain optimization network as a use case. What are the key \\nadvantages of using an agentic system approach in this context, and how do the different agents \\ncomplement each other?Answers 237\\nAnswers\\n1. Agentic systems in creative applications maintain context and creative vision across multiple \\niterations, unlike traditional tools that simply generate content. For example, in the film \\npre-visualization use case, the director agent maintains creative vision while collaborating with \\nthe technical supervisor and visualization agents to ensure both artistic integrity and technical \\nfeasibility. This enables continuous alignment between creative goals and practical constraints, \\nsomething traditional generative tools cannot achieve.\\n2. In manufacturing cell orchestration, four specialized agents (planning and coordination, robot \\ncontrol, quality and optimization, and exception handling) work together through shared \\ncontext understanding and continuous feedback loops. This approach is more effective because \\nit enables real-time adaptation to product variations and disruptions while maintaining quality \\nstandards. Traditional automation systems lack this flexibility and require human intervention \\nfor changes or unexpected situations.\\n3. In robotics, agentic systems focus on translating language understanding into physical actions while \\nmaintaining safety and operational constraints. For example, the robot control agent translates \\nhigh-level instructions into motion primitives while ensuring safe human-robot interaction. Motion \\nprimitives are fundamental movement patterns in robotics, such as grasping or turning, used as \\nbuilding blocks for complex actions. A robot control agent translates high-level commands into \\nthese primitives to ensure safe and efficient execution while maintaining operational constraints.\\nIn decision support systems, agents focus on processing multiple information streams while \\nmaintaining business context and strategic objectives. While both maintain context, robotics \\nagents must bridge the physical-digital divide, while decision support agents must balance \\nmultiple competing objectives.\\n4. In the enterprise knowledge management system, three agents collaborate:\\n \\x82 The query-understanding agent processes natural language questions and identifies the \\nimplicit context\\n \\x82 The knowledge navigation agent maps relationships between different information sources\\n \\x82 The response synthesis agent combines information while adapting to user roles\\nThese agents share organizational context and learn from user interactions, enabling them \\nto handle complex queries that span multiple domains and documents more effectively than \\ntraditional search systems.\\n5. The supply chain optimization network demonstrates the advantages of agentic systems through \\nfour specialized agents (strategic planning, operational optimization, risk management, and \\nsustainability optimization) that work together to balance multiple objectives. Key advantages \\ninclude natural language interaction for strategy development, real-time adaptation to changes, \\nproactive risk identification, and balanced optimization across competing objectives. The agents \\ncomplement each other by maintaining different aspects of the supply chain context – from \\nlong-term strategy to day-to-day operations, risk management, and sustainability goals.Common Use Cases and Applications 238\\nJoin our communities on Discord and Reddit\\nHave questions about the book or want to contribute to discussions on Generative AI and LLMs? \\nJoin our Discord server at https://packt.link/I1tSU and our Reddit channel at https://\\npackt.link/ugMW0 to connect, share, and collaborate with like-minded enthusiasts.11\\nConclusion and Future Outlook\\nThis final chapter brings together everything we’ve learned in this book about AI-powered systems \\nthat can act on their own (agentic systems). We will start by going over the main ideas we’ve covered, \\nmaking sure you have a solid understanding of how these systems work. We will then look at what’s \\nnew and exciting in this field, exploring fresh ideas and research that could change how we think \\nabout and use these technologies.\\nWe will also talk about artificial general intelligence (AGI) – the idea of creating AI that can think \\nand learn like humans across many different tasks. While AGI remains a concept with no practical \\nimplementation yet, current AI systems are narrow AI, meaning they excel at specific tasks but lack \\ngeneral reasoning abilities. Despite significant advancements in deep learning and large language \\nmodels, true AGI requires breakthroughs in reasoning, adaptability, and self-learning beyond predefined \\ntasks. We’ll explore recent progress, the challenges that make AGI difficult to achieve, and what future \\ndevelopments might bring us closer to this vision.\\nBut with great progress come important questions. We’ll discuss real challenges such as making these \\nsystems work at a larger scale, understanding how they make decisions, and how they might affect \\nsociety. By looking at both the problems and opportunities, you’ll be better prepared to work with \\nand think about these technologies. This chapter is structured into four main sections:\\n• Recap of key concepts\\n• Emerging trends and research directions\\n• Artificial general intelligence\\n• Challenges and opportunities\\nBy the end of this chapter, you’ll have a clear picture of where AI systems are today and where they’re \\nheading. Y ou’ll understand both their potential and their limitations, helping you be part of the \\nconversation about how to develop these technologies responsibly.Conclusion and Future Outlook 240\\nRecap of key concepts\\nOur journey through the world of AI agents started with the building blocks of generative AI. We \\nlearned how these systems can create new content, from images to text, using different approaches \\nsuch as Generative Adversarial Networks (GANs) and autoregressive models. This foundation helped \\nus understand not just how these AI systems work but also their current limitations.\\nWe then explored what makes an AI system agentic – meaning it can act on its own. These systems need \\nthree key abilities: they must react to their environment, take initiative to reach goals, and work well \\nwith other agents. Think of it like teaching a computer to be both independent and a good team player.\\nThe book then showed us how these agents think and make decisions. They need ways to store \\nknowledge, learn from experience, and plan their actions. Just like humans use their memory and \\npast experiences to make choices, AI agents need similar capabilities to work effectively.\\nOne of the most interesting aspects we covered was how agents can think about their own actions – \\nwhat we call reflection and introspection. This self-awareness helps them improve over time and make \\nbetter decisions. We also learned how agents can use tools and make plans, much like how humans \\nuse calculators or make to-do lists to solve problems more efficiently.\\nA key practical framework we introduced was the Coordinator-Worker-Delegator model. This approach \\nsplits tasks between different types of agents:\\n• Coordinators who manage the overall process\\n• Workers who handle specific tasks\\n• Delegators who decide who should do what\\nWe spent time understanding how to build these systems responsibly, focusing on trust and safety. \\nThis included making sure AI systems can explain their decisions, protect privacy, and follow ethical \\nguidelines. These considerations are crucial as AI becomes more integrated into our daily lives.\\nFinally, we explored real-world applications across different fields – from creative tasks such as art \\nand music to practical uses in robotics and decision-making systems. These examples showed how \\nAI agents are already making a difference in various industries.\\nIn the next section, we’ll explore what’s new in this field and where it’s heading. We’ll look at exciting \\ndevelopments that could shape the future of AI agents and how they might change the way we work \\nand live.\\nThis recap gives you a strong foundation for understanding what’s next. By knowing these basics, you \\nwill be better prepared to understand the cutting-edge developments we’ll discuss in the coming sections.Emerging trends and research directions 241\\nEmerging trends and research directions\\nLet’s explore the latest developments that are shaping the future of AI agents and generative systems. \\nWe’ll look at three main areas where exciting progress is happening: how AI understands multiple \\ntypes of input, improvements in language understanding, and new ways AI learns from experience, \\nbefore ending the section with a review of their practical implications.\\nMulti-modal intelligence – integrating diverse inputs\\nAI systems are increasingly capable of processing and integrating multiple forms of data—text, images, \\naudio, and video—simultaneously. This multi-modal approach mirrors human perception, allowing for \\nmore comprehensive understanding and interaction. For instance, models such as OpenAI’s GPT-4o \\ncan process and generate text, images, and audio, enabling functionalities such as the following:\\n• Visual interpretation: Analyzing images to provide detailed descriptions\\n• Image generation: Creating visuals from textual prompts\\n• Speech processing: Understanding voice commands and responding appropriately\\n• Interactive responses: Combining visual and textual information to generate contextually \\nrelevant outputs\\nThese capabilities enhance user interaction, making AI more intuitive and versatile.\\nAdvanced language comprehension\\nLanguage models have achieved remarkable progress, leading to more nuanced and context-aware \\nAI interactions. Key advancements include the following:\\n• Few-shot learning: Enabling models to learn and adapt from minimal examples, improving \\nefficiency in handling new tasks\\n• Enhanced contextual understanding : Allowing AI to maintain coherence over extended \\nconversations, providing more relevant and accurate responses\\n• Domain expertise: Developing specialized models tailored to specific fields, such as medicine \\nor law, to offer expert-level insights\\n• Natural conversational abilities: Incorporating elements such as humor and subtle nuances \\nto make interactions more human-like\\nFor example, OpenAI’s o1 model focuses on enhanced reasoning capabilities, outperforming previous \\nmodels in complex tasks that require step-by-step logical processes. Unlike earlier AI systems that \\noften relied on pattern matching and statistical inference, o1 incorporates structured reasoning \\ntechniques to break down problems, analyze multiple possibilities, and arrive at more accurate andConclusion and Future Outlook 242\\ncoherent conclusions. This improvement brings AI closer to advanced problem-solving, but it still \\nfalls short of true AGI, as it lacks human-like adaptability, intuition, and self-directed learning across \\ndiverse domains.\\nExperiential learning – reinforcement learning innovations\\nAdvancements in reinforcement learning (RL) are transforming how AI systems learn from interactions \\nand experiences. Notable developments include the following:\\n• Autonomous skill enhancement: AI agents independently practicing tasks to achieve proficiency \\nwithout human intervention\\n• Adaptive learning: Modifying strategies based on past errors to improve future performance\\n• Real-world applications:\\n \\x82 Robotics: Training robots to perform intricate physical tasks through trial and error, \\nenhancing adaptability in dynamic environments\\n \\x82 Gaming: Developing AI that devises novel strategies, surpassing traditional human approaches\\n• Improved decision-making:\\n \\x82 Uncertainty management : Handling incomplete or ambiguous information to make \\ninformed choices\\n \\x82 Transparent reasoning : Providing explanations for decisions to build trust and \\nfacilitate understanding\\nFor instance, Google’s DeepMind has developed AI models such as RoboCat, capable of controlling \\nrobotic arms and adapting to new tasks and hardware with minimal human intervention.\\nPractical implications across industries\\nThese AI advancements are driving innovation and efficiency in various sectors:\\n• Healthcare: AI systems analyzing medical data to assist in diagnostics and treatment planning\\n• Finance: Predicting market trends and managing risks through sophisticated data analysis\\n• Entertainment : Creating more immersive and responsive gaming experiences with \\nAI-driven characters\\n• Creative arts: Assisting in the creation of art, music, and design, expanding the boundaries \\nof creative expressionArtificial general intelligence 243\\nFor example, as we discussed in the previous chapter, AI-generated music and art are becoming \\nincreasingly prevalent, with models capable of producing original compositions and artworks based \\non minimal input. The convergence of multi-modal intelligence, advanced language comprehension, \\nand experiential learning is propelling AI toward more sophisticated and human-like capabilities, \\nwith profound implications for technology and society.\\nArtificial general intelligence\\nLet’s break down what AGI means and why it matters to the future of intelligent systems.\\nWhat makes AGI different\\nToday’s AI is like a collection of very specialized tools – great at specific jobs but unable to adapt to \\nnew situations. AGI aims to create something different: machines that can think, learn, and solve \\nproblems the way humans do. Imagine an AI that could write a symphony one day and solve complex \\nengineering problems the next, all while understanding the deeper meaning behind both tasks.\\nThe big challenge\\nBuilding AGI is challenging because we still don’t fully understand how human intelligence works. \\nUnlike AI models, humans don’t just process information – they reason, adapt, and transfer knowledge \\nseamlessly across domains. Think about how a child learns: they can quickly pick up new skills, grasp \\ncause and effect, and apply lessons from one situation to a completely different one. Replicating this \\nin machines requires solving some major challenges:\\nLearning to learn\\nTo build AGI, we need AI systems that go beyond memorization and truly generalize knowledge \\nacross tasks. This involves the following:\\n• Understanding abstract concepts : Recognizing deeper meanings, analogies, and \\nhigh-level reasoning\\n• Applying knowledge to new situations : Adapting learned principles to unfamiliar tasks \\nwithout retraining\\n• Developing common sense reasoning: Making intuitive judgments based on everyday experiences\\n• Building on previous experiences: Retaining and refining knowledge over time, rather than \\nstarting from scratch for each taskConclusion and Future Outlook 244\\nReal-world understanding\\nHuman intelligence is deeply connected to perception, context, and adaptability – qualities that are \\ndifficult for AI to replicate. Key challenges include the following:\\n• Processing information like humans do: Integrating multiple sensory inputs and reasoning \\nbeyond structured data\\n• Making sense of messy, real-world data : Handling incomplete, contradictory, or \\nambiguous information\\n• Understanding context and nuance: Interpreting meaning based on cultural, emotional, and \\nsituational cues\\n• Dealing with unexpected situations: Responding flexibly to novel problems that were never \\nexplicitly programmed\\nOvercoming these hurdles requires breakthroughs in areas such as causal reasoning, self-supervised \\nlearning, and embodied AI – moving beyond pattern recognition to develop truly adaptive, self-\\nimproving systems. While current AI models excel at narrow tasks, true AGI remains a distant goal, \\nrequiring a fundamental shift in how machines learn, reason, and interact with the world.\\nWhen we combine AGI with autonomous agents, we create something truly revolutionary – systems \\nthat can think deeply while acting independently in the world. These combined systems would make \\ncomplex decisions on their own, understanding not just the technical aspects but also the social and \\nethical implications of their choices. They would learn continuously from every interaction, whether \\nwith humans or other systems, growing more capable over time. Most importantly, they would work \\nas true partners with humans, understanding our goals and values while bringing their own unique \\ncapabilities to help solve problems.\\nThe impact of combining AGI with agentic systems could transform how we approach major challenges. \\nImagine scientists working with AI partners that truly grasp the nuances of research goals, offering novel \\ninsights and spotting connections humans might miss. In medicine, these systems could revolutionize \\ndiagnosis by connecting seemingly unrelated symptoms with rare conditions, drawing on a vast knowledge \\nbase while considering each patient’s unique circumstances. For environmental challenges, they could \\ndevelop comprehensive solutions that balance complex global factors, from economic impacts to \\necosystem effects. In education, they could create truly personalized learning experiences, understanding \\neach student’s needs, learning style, and interests to deliver exactly the right content at the right time.\\nThe journey toward combining AGI with agentic systems brings up crucial questions about safety, \\ncontrol, and ethics. We need to ensure these powerful systems align with human values and operate \\nwithin appropriate bounds. This isn’t just science fiction anymore – serious researchers and organizations \\nare making real progress toward these goals. The key lies in understanding both the enormous potential \\nand the very real limitations of these systems as we work toward this ambitious vision.Challenges and opportunities 245\\nIn the next section, we’ll dive into these challenges and opportunities, exploring how we can develop \\nthese transformative systems responsibly while maximizing their benefits for humanity.\\nChallenges and opportunities\\nAs we look to the future of AI agents and generative systems, we face both exciting possibilities and \\nimportant challenges to solve. One of the biggest challenges is making learning systems that can handle \\nmassive amounts of complex data efficiently. With data growing exponentially, our current learning \\nmethods are starting to show their limits. To solve this, researchers are developing new approaches \\nsuch as meta-learning, transfer learning, and few-shot learning.\\nMeta-learning is particularly interesting because it teaches AI systems how to learn better. Instead \\nof just learning specific tasks, these systems learn the process of learning itself. This means they can \\npick up new skills much faster with less training data. A good example is the model-agnostic meta-\\nlearning (MAML) system, which works across different types of tasks from image recognition to \\nlanguage processing.\\nTransfer learning is like teaching AI to apply what it learns in one area to solve problems in another. \\nThink of how a person who learns to play piano might find it easier to learn guitar – the basic music \\nknowledge transfers over. In AI, we see this when models trained on huge image datasets can quickly \\nadapt to specific tasks such as medical imaging.\\nFew-shot learning addresses another critical limitation: the need for extensive labeled datasets. Unlike \\ntraditional methods, few-shot learning aims to train models using only a handful of examples. This \\napproach is invaluable in scenarios where collecting vast amounts of labeled data is impractical, such \\nas rare disease diagnoses or highly specialized industrial applications. By mimicking human-like \\nlearning from minimal examples, few-shot learning pushes the boundaries of what AI can achieve.\\nThese advanced learning paradigms come with both challenges and opportunities. They require \\ninnovative architectures, computational efficiency, and careful consideration of generalization and \\nbias. However, their potential to enable more adaptable, resource-efficient, and impactful AI systems \\npositions them as pivotal elements in the future of generative AI and autonomous agents.\\nAnother major challenge is making AI systems that can explain their decisions clearly. As these systems \\nget more complex, it becomes harder to understand how they reach their conclusions. This lack of \\ntransparency can make people hesitant to trust AI, especially in important areas such as healthcare \\nor financial decisions. To address this, we’re developing new ways to visualize and understand how \\nAI makes decisions, such as attention maps that show which parts of an input the AI focuses on most.\\nMaking AI systems reliable and secure in the real world is also crucial. They need to work well even \\nwhen faced with unexpected situations or attempts to trick them. This means building safeguards and \\nconstantly monitoring how they perform.Conclusion and Future Outlook 246\\nBut there are also huge opportunities ahead. One of the most exciting is creating AI that interacts \\nwith humans more naturally. Think about how virtual assistants such as Siri and Alexa have already \\nchanged how we interact with technology. Future systems could be even better, understanding not \\njust our words but also our gestures, expressions, and the context of our conversations.\\nWe could also see personalized AI tutors that adapt perfectly to each person’s learning style. Imagine \\na teaching assistant that knows exactly how to explain complex ideas in a way that makes sense to \\nyou, using examples from topics you’re interested in.\\nThe key to moving forward is finding the right balance between pushing innovation and developing these \\nsystems responsibly. We need to solve the technical challenges while making sure these technologies \\nhelp rather than harm society. By focusing on making AI systems that are scalable, understandable, \\nreliable, and human-friendly, we can unlock their potential to improve our lives in meaningful ways.\\nSummary\\nAs we wrap up our journey through the world of AI-powered systems that can think and act on \\ntheir own, we find ourselves at an exciting turning point in technology. What we’ve explored in this \\nbook isn’t just about new software or algorithms – it’s about creating intelligent systems that could \\nfundamentally change how we solve problems and interact with technology.\\nThroughout this book, we covered the building blocks of these systems: how they learn, how they \\nmake decisions, and how they can work together. We saw how they can look at their own actions \\nand improve, use tools to solve problems, and work in teams with different agents handling different \\nparts of complex tasks. We also tackled the crucial questions of trust and safety, making sure these \\npowerful tools help rather than harm.\\nThe future ahead is both challenging and thrilling. Y es, we need to solve tough problems such as \\nmaking these systems work with huge amounts of data, helping them explain their decisions clearly, \\nand keeping them secure. But the opportunities are incredible – imagine AI assistants that truly \\nunderstand us, educational tools that adapt perfectly to how each person learns, and systems that can \\nhelp us tackle global challenges such as climate change and disease.\\nThe idea of AGI – AI that can think and learn as humans do – might seem like a distant dream. But \\nthe work we’re doing today in building these autonomous systems that can reason, learn, and adapt \\nis laying the groundwork for that future. Each breakthrough in how AI agents learn from experience, \\nwork together, and understand the world brings us closer to that goal.\\nBut perhaps most importantly, we learned that creating these systems isn’t just a technical challenge \\n– it’s a human one. We need to build them thoughtfully, making sure they align with our values and \\nserve the greater good. The future of AI isn’t about replacing human intelligence but about creating \\ntools that enhance our own capabilities and help us solve problems in new ways.Join our communities on Discord and Reddit 247\\nAs you close this book, remember that you’re now part of this journey. Whether you’re a developer, \\nresearcher, or someone interested in where technology is heading, you have the knowledge to help shape \\nhow these systems develop and how they’re used to benefit society. The field of AI and autonomous \\nsystems is moving quickly, but the principles we’ve covered – about how these systems learn, how \\nthey should be designed responsibly, and how they can work alongside humans – will remain relevant \\nas the technology evolves. The future isn’t just about what these systems can do – it’s about what we \\nchoose to do with them.\\nLooking ahead, the possibilities are boundless. We’re not just building better software; we’re working \\ntoward a future where artificial intelligence can help us tackle our biggest challenges and open up new \\nopportunities we haven’t even imagined yet. That’s the real promise of AI agents – not just smarter \\nmachines but better solutions to human problems.\\nJoin our communities on Discord and Reddit\\nHave questions about the book or want to contribute to discussions on Generative AI and LLMs? \\nJoin our Discord server at https://packt.link/I1tSU and our Reddit channel at https://\\npackt.link/ugMW0 to connect, share, and collaborate with like-minded enthusiasts.Index\\nA\\nabductive reasoning  59-61\\napplications  60\\nactivity planning worker  147\\nadaptive agents\\nlearning mechanisms  61, 62\\nadvanced language comprehension  241\\nagency  29, 30\\nexample, in agents  32-34\\nkey elements  29\\nagent behavior  154, 155\\nagent capabilities\\nagentic AI, building  69, 71\\nenhancing, with generative AI  68, 69\\nAgent Communication Language (ACL)  152\\nagentic system approach\\ndirector agent  223\\ntechnical supervisor agent  224\\nvisualization agent  224\\nagentic systems (AI)  28\\nagentic systems (AI) architecture\\ndeliberative architectures  36, 37\\nexploring  36\\nhybrid architectures  39, 40\\nreactive architectures  38\\nagentic systems (AI), safety considerations\\naction boundaries  212\\ndecision verification  212\\nperformance metrics  213\\nreal-time monitoring  213\\nreinforcement learning feedback loops  213\\nrollback capabilities  212\\nagent roles\\nAnalyst agent  144\\nManager agent  144\\nReflector agent  145\\nSearcher agent  145\\nTask Interpreter agent  145\\nagents\\nanalysis and intelligence worker agents  148\\ncore travel worker agents  147\\ndelegator agent  149-151\\ndesigning, with role assignments  143-145\\nroles and responsibilities  146\\ntravel planning agent  146\\nAI agents\\nchallenges and opportunities  245, 246\\nAI planning and tool usage\\nintegrating  126\\nplanning process  128\\ntools reasoning  126, 127\\nAI trust\\nestablishing, techniques  191\\nalgorithmic level  191\\nAmazon Web Services (AWS)  69Index\\n250\\nanalysis and intelligence worker agents  148\\ntravel data analyst worker  148\\ntravel experience worker  148\\ntravel opportunity worker  149\\nAnalyst agent  144\\nA* planning  117, 118\\napplication programming \\ninterfaces (APIs)  113\\nartificial general intelligence (AGI)  243\\nchallenge  243\\nfeatures  243\\nhuman intelligence  244\\nartificial intelligence (AI)  3\\ntrust  190, 191\\nAutoGen\\nimplementing  130-132\\nversus CrewAI  134\\nversus LangGraph  134\\nautomated guided vehicles (AGVs)  230\\nautonomy  30, 31\\nexample, in agents  32-34\\nfunctional autonomy  30\\nhierarchical autonomy  31\\noperational autonomy  30\\nautoregressive models  7\\nB\\nbehavior-based architectures  38\\nbidirectional communication flows\\ndownward flow  140\\nupward flow  140\\nC\\nCalifornia Consumer Privacy \\nAct (CCP A)  216\\nchain of thought (CoT)  15\\ncommunication and collaboration \\nagents  151\\ncommunication  152\\ncoordination mechanism  152\\nknowledge sharing  153\\nnegotiation and conflict resolution  152\\ncommunication protocols  156\\nconstraint satisfaction problems \\n(CSPs)  67, 68\\nContent Authenticity Initiative (CAI)  211\\ncontext management  173, 177, 178\\ncontext hierarchy  177\\ncontext switching  178\\ndecision-making processes  179\\ncontextual awareness  165\\nexamples  166\\nconversational agents  225\\nevolution  225\\ncoordinator-worker-delegator (CWD)  137\\ncore travel worker agents  147\\nactivity planning worker  147\\nflight booking worker  147\\nhotel booking worker  147\\ntransportation worker  148\\ncreative and artistic agents\\nartistic collaboration  222\\nevolution  222\\nmusic composition  222\\nwriting and narrative development  222\\ncreative and artistic applications  222\\nadvantages  224, 225\\nenvironment and external systems  224\\nimplementing  223\\nproblem statement  223\\nCrewAI\\nimplementing  129, 130\\nversus AutoGen  134\\nversus LangGraph  134Index\\n251\\nCWD approach\\nagent behavior  154, 155\\ncommunication protocols  156\\nimplementing, in generative AI systems  154\\ninstruction formatting  155\\ninteraction patterns  156\\noutput templates  155\\nsystem prompt  155\\nsystem prompts  154\\nCWD model  138\\ncoordinators  139\\ndelegators  139\\nfor intelligent travel agent  141-143\\nkey principles  140\\nworkers  139\\nD\\ndatabase tools  113\\ndecision support agents\\nagentic systems  232\\nevolution  232\\ndecision support agents, agentic systems\\nadvantages  235\\nenvironment and external systems  234, 235\\nproblem statement  233\\ndeductive reasoning  57\\ndomain application  57, 58\\ndelegator agent  149-151\\ndeliberative architectures  36, 37\\ndeliberative layer  39\\ndigital twin platform  230\\ndiscriminator  6\\ndocstrings\\nusing  111\\nDrift  99\\nE\\nedge cost  65\\nemerging trends and research directions  241\\nadvanced language comprehension  241\\nexperiential learning  242\\nmulti-modal intelligence  241\\npractical implications, across \\nindustries  242, 243\\nenterprise resource planning (ERP)  230\\nenvironment modeling  169\\ndynamic elements  170\\nstatic elements  169\\nepisodic memory  176\\nimplementation  176\\nexperiential learning  242\\nExplainable AI (XAI)  191, 213\\nExplainable AI (XAI) techniques\\nattention visualization  191\\nnatural language explanations  191\\nsaliency maps  191\\nF\\nFast Forward (FF)  117, 118\\nfeedback loops  157\\nfirst-order logic  53, 55\\nFlight Booking Assistant  10\\nfocused instruction, for \\nintelligent agents  162\\ncontextual awareness  165-167\\nobjectives, defining  162\\ntask specifications  163, 164\\nframes  54, 55\\nfunction calling  109-111Index\\n252\\nG\\nGeneral Data Protection \\nRegulation (GDPR)  216\\ngenerative adversarial networks \\n(GANs)  3, 6, 240\\ngenerative AI  3, 4\\nadversarial attacks  206, 207\\nagent capabilities, enhancing with  68, 69\\nbias and discrimination  207, 208\\nchallenges and limitations  20\\ncomputational resources  22\\ndata privacy  21, 22\\ndata privacy violations  209, 210\\nethical AI development, exploring  216\\nethical and social implications  23\\ngeneralization and creativity  23\\nintellectual property risks  210-212\\nmisinformation and hallucinations  208, 209\\nprivacy and security considerations  217, 218\\nquality data and bias  21\\nrisks and challenges  206\\nsafety and responsibility  212-215\\ngenerative AI applications  16-20\\nautonomous workflows and robotics  17\\ncode generation  17\\nhealthcare and drug discovery  17\\nimages and videos  16\\nmusic and audio generation  16\\ntext and content generation  16\\ngenerative AI, ethical AI development\\naccountability and responsibility  216\\ndiverse stakeholders  217\\nhuman-centric design  216\\nprivacy and data protection  216, 217\\ngenerative AI models\\nautoregressive models  7\\ngenerative adversarial networks (GANs)  6\\nLLM-powered AI agents  10-16\\ntransformer architecture  7\\ntypes  4\\nvariational autoencoders (V AEs)  5\\ngenerative AI systems\\nused, for implementing CWD approach  154\\ngenerator  6\\nGoogle Cloud Platform (GCP)  69\\ngpt-4o-mini model  85\\ngraph-based planning algorithms  65, 66\\ngraph search  65\\noptimal path finding  66\\ngraphics processing units (GPUs)  22\\nGraphPlan  117, 118\\nH\\nhallucination  208\\nhardware interface tools  113\\nHealth Insurance Portability and \\nAccountability Act (HIP AA)  216\\nheuristic search  66\\nhierarchical planning  67\\nhierarchical task network \\n(HTN)  117, 122-125\\nhierarchical task networks (HTNs)  137\\nhuman-in-the-loop (HITL)  215\\nhybrid architectures  39, 40\\ndeliberative layer  39\\nexternal modules planning  40\\nmemory-augmented planning  40\\nmultiplan selection  40\\nreactive layer  39Index\\n253\\nreflection and refinement  40\\ntask decomposition  40\\nI\\nintelligent agent\\ncharacteristics  35, 36\\nreviewing  35, 36\\nintelligent agent, key attributes\\nproactiveness  35\\nreactivity  35\\nsocial ability  35\\ninductive reasoning  58, 59\\napplications  59\\ninput structuring  155\\ninstruction formatting  155\\ninput structuring  155\\nintegrated development \\nenvironments (IDEs)  17\\nintegration and interaction patterns\\nevent-driven updates  171\\nstate validation and consistency  171, 173\\nintegration tools  113\\nintellectual property (IP)  211\\nintelligent agents\\ndecision-making  62\\nintrospection  82\\nknowledge representation  52\\nplanning  62\\nreasoning  56\\ninteraction patterns  156\\nfeedback loops  157\\nmessage passing protocols  156\\nstate management  156\\nintrospection\\nin intelligent agents  82\\nK\\nkey performance indicators (KPIs)  99\\nknowledge-based architectures  36\\nknowledge representation approaches, \\nin intelligent agents\\nframes  54, 55\\nlogic-based representations  55, 56\\nsemantic works  52, 53\\nL\\nLangGraph\\nimplementing  132, 133\\nversus AutoGen  134\\nversus CrewAI  134\\nlarge language models (LLMs)  8, 206\\nlarge language models (LLMs) types\\nautoregressive LLMs  9\\ndomain-specific LLMs  10\\nencoder-decoder LLMs  9\\nencoder-only LLMs  9\\ninstruction-tuned LLMs  9\\nmultimodal LLMs  9\\nlearning mechanisms, adaptive agents\\nreinforcement learning  62\\nsupervised learning  61\\ntransfer learning  62\\nunsupervised learning  61\\nless practical planning algorithms  117\\nA* planning  118\\nGraphPlan  118\\nMCTS  118\\nSTRIPS  117\\nLLM-based planning  117, 120-122\\nLLMFastForward class\\ncreate_relaxed_plan  119\\nselect_next_action  119Index\\n254\\nLLM-powered AI agents  10-16\\nlogic-based representations\\nin real-world applications  56\\nlong-term memory  175\\nimplementation  175, 176\\nM\\nmaintenance management system  230\\nManager agent  144\\nmanufacturing execution system (MES)  230\\nmemory architectures  173\\ndecision-making processes  179\\nepisodic memory (interaction \\nhistory)  176, 177\\nlong-term memory (knowledge \\nbase)  175, 176\\nshort-term memory (working \\nmemory)  174, 175\\nmessage passing protocols  156\\nmeta-reasoning  83-92\\nMicrosoft Azure  69\\nmodel-agnostic meta-learning \\n(MAML) system  245\\nmoderately practical planning \\nalgorithm  118, 119\\nmodern language agents\\nadaptive interaction  225\\ncontext retention  225\\nmulti-modal  226\\ntask execution  225\\nMonte Carlo Tree Search  \\n(MCTS)  66, 67, 117, 118\\nmost practical planning algorithms  119, 120\\nhierarchical task network (HTN)  122-125\\nLLM-based planning  120-122\\nmulti-agent systems (MASs)  40, 41\\ncharacteristics  42\\ndefining  42\\nexamples  41\\ninteraction mechanisms  43-48\\nMulti-Armed Bandit (MAB)  92\\nmulti-attribute tradeoffs  64\\nmulti-modal intelligence  241\\nimage interpretation  241\\ninteractive responses  241\\nspeech processing  241\\nvisual interpretation  241\\nN\\nnamed entity recognition (NER)  9\\nnatural language processing (NLP)  7, 225\\nadvantages  228\\nenvironment and external systems  227\\nproblem statement  226\\nnatural language understanding (NLU)  9\\nO\\noutput templates  155\\nP\\nparallel processing  181\\nPayment Card Industry Data Security \\nStandard (PCI DSS)  217\\npersonally identifiable \\ninformation (PII)  209\\nplanning algorithms  65\\nconstraint satisfaction  67\\ngraph-based planning  65, 66\\nheuristic search  66\\nhierarchical planning  67\\nMonte Carlo tree search  66Index\\n255\\nplanning algorithms for agents  117\\nless practical planning algorithms  117\\nmoderately practical planning algorithm  118\\nmost practical planning algorithms  119, 120\\npresentation level  191\\nprivacy-preserving machine \\nlearning (PPML)  216\\nprogrammable logic controllers (PLCs)  230\\npropositional logic  55\\nQ\\nquality management system (QMS)  230\\nR\\nreactive architectures\\nadvantages  39\\nkey properties and characteristics  38\\nreactive layer  39\\nreasoning, intelligent agents  56\\nabductive reasoning  59-61\\ndeductive reasoning  57, 58\\ninductive reasoning  58, 59\\nreflection, in LLM agents\\nadaptation  79\\nenhanced decision-making  78, 79\\nethical consideration  80, 81\\nhuman-computer interaction  81, 82\\nsignificance  78\\nreflective capabilities\\nimplementing  83\\nreflective capabilities, techniques\\nmeta-reasoning  83-92\\nself-explanation  92-96\\nself-modeling  96-98\\ntraditional reasoning  83\\nreflective intelligent agents\\nuse cases and examples  98-103\\nReflector agent  145\\nreinforcement learning from human \\nfeedback (RLHF)  213\\nreinforcement learning (RL)  62, 92, 242\\nrobotic process automation (RP A)  20\\nrobotics  28\\nrobotics and autonomous systems  228\\nrobotic agents, evolution  228\\nuse case  229\\nrobotics and autonomous systems, use case\\nadvantages  231\\nenvironment and external systems  230, 231\\nproblem statement  229\\nrole-based access control (RBAC)  212, 216\\nS\\nSearcher agent  145\\nsecure multi-party computation (SMPC)  216\\nself-explanation  92-96\\nself-governance  29\\nkey aspects  29\\nself-modeling  96-98\\nsemantic networks  52, 53\\nsequential processing  180\\nshort-term memory  174\\nimplementing  174, 175\\nsmall language models (SLMs)  22\\nspecialized modal/temporal logics  55\\nStanford Research Institute Problem \\nSolver (STRIPS)  117\\nstate management  156\\nstate-space graph  65\\nstate space representation  167, 168Index\\n256\\nstate spaces and environment modeling  167\\nadaptation  173\\nenvironment modeling  169, 170\\nintegration and interaction patterns  171-173\\nmonitoring  173\\nstate space representation  167, 168\\nstimulus-response architectures  38\\nSTRIPS  117\\nsupervised learning  61\\nsymbolic architectures  36\\nsystem prompts  154, 155\\nsystems engineering  28\\nT\\nTask Interpreter agent  145\\ntechniques, for establishing AI trust\\nethical development and \\nresponsibility  199, 200\\noutput communication  197\\ntransparency and explainability  191-196\\nuncertainty and biases, dealing with  196\\nuser control and consent  198, 199\\ntool calling  109-111\\ntools for agents\\ndefining  111\\nDirect LLM integration  112\\nframework approach  111\\ntools types  113-116\\napplication programming \\ninterfaces (APIs)  113\\ndatabase tools  113\\nhardware interface tools  113\\nintegration tools  113\\nutility functions  113\\ntools types, key concepts\\nagent configuration  115\\nexecution flow  115\\ntask specification  115\\ntool, defining  115\\ntool integration  115\\ntools types, key considerations\\nerror handling and fallbacks  114\\ntool composition and chaining  114\\ntool security and access control  114\\ntool selection and decision-making  114\\ntool state management  114\\ntool updates and versioning  114\\ntool usage\\nconcept, in agents  108, 109\\nfunction calling  109-111\\ntool calling  109-111\\ntools for agents, defining  111\\ntools significance, in agent systems  116\\ntools types  113-116\\ntraditional reasoning  83\\ntransfer learning  62\\ntransformer architecture  7\\nBidirectional Encoder Representations \\nfrom Transformers (BERT)  8\\nGenerative Pre-trained \\nTransformer (GPT)  8\\nkey components  8\\nPixelCNN  8\\nPixelSNAIL  8\\nText-To-Text Transfer Transformer (T5)  8\\ntransparency  92\\ntransparency and explainability  191-194\\nimplementing  200, 201\\ntransportation worker  148\\ntravel data analyst worker  148\\ntravel experience worker  148\\ntravel opportunity worker  149\\ntravel planning agent  146Index\\n257\\nU\\nuncertainty and biases\\ndealing with  196\\nhandling  201, 202\\nunsupervised learning  61\\nutility function  63, 64, 113\\nV\\nvariational autoencoders (V AEs)  3, 5\\nVisual Studio Code (VS Code)  17\\nW\\nweather_lookup tool  110\\nworkflow optimization  182\\nwith dynamic workflows  182-184\\nZ\\nZendesk  99packtpub.com\\nSubscribe to our online digital library for full access to over 7,000 books and videos, as well as \\nindustry leading tools to help you plan your personal development and advance your career. For more \\ninformation, please visit our website.\\nWhy subscribe?\\n• Spend less time learning and more time coding with practical eBooks and Videos from over \\n4,000 industry professionals\\n• Improve your learning with Skill Plans built especially for you\\n• Get a free eBook or video every month\\n• Fully searchable for easy access to vital information\\n• Copy and paste, print, and bookmark content\\nDid you know that Packt offers eBook versions of every book published, with PDF and ePub files \\navailable? Y ou can upgrade to the eBook version at packtpub.com and as a print book customer, you \\nare entitled to a discount on the eBook copy. Get in touch with us at customercare@packtpub.\\ncom for more details.\\nAt www.packtpub.com, you can also read a collection of free technical articles, sign up for a range \\nof free newsletters, and receive exclusive discounts and offers on Packt books and eBooks.Other Books Y ou May Enjoy\\nIf you enjoyed this book, you may be interested in these other books by Packt:\\nGenerative AI on Google Cloud with LangChain\\nLeonid Kuligin, Jorge Zaldívar, Maximilian Tschochohei\\nISBN: 978-1-83588-932-9\\n• Build enterprise-ready applications with LangChain and Google Cloud\\n• Navigate and select the right Google Cloud generative AI tools\\n• Apply modern design patterns for generative AI applications\\n• Plan and execute proof-of-concepts for enterprise AI solutions\\n• Gain hands-on experience with LangChain’s and Google Cloud’s AI products\\n• Implement advanced techniques for text generation and summarization\\n• Leverage Vertex AI Search and other tools for scalable AI solutions261\\nOther Books You May Enjoy\\nLLM Engineer’s Handbook\\nPaul Iusztin, Maxime Labonne\\nISBN: 978-1-83620-007-9\\n• Implement robust data pipelines and manage LLM training cycles\\n• Create your own LLM and refine it with the help of hands-on examples\\n• Get started with LLMOps by diving into core MLOps principles such as orchestrators and \\nprompt monitoring\\n• Perform supervised fine-tuning and LLM evaluation\\n• Deploy end-to-end LLM solutions using AWS and other tools\\n• Design scalable and modularLLM systems\\n• Learn about RAG applications by building a feature and inference pipeline262\\nPackt is searching for authors like you\\nIf you’re interested in becoming an author for Packt, please visit authors.packtpub.com and \\napply today. W e have worked with thousands of developers and tech professionals, just like you, to \\nhelp them share their insight with the global tech community. Y ou can make a general application, \\napply for a specific hot topic that we are recruiting an author for, or submit your own idea.\\nShare Your Thoughts\\nNow you’ve finished Building Agentic Systems with Generative AI, we’ d love to hear your thoughts! \\nIf you purchased the book from Amazon, please click here to go straight to the \\nAmazon review page for this book and share your feedback or leave a review on the site that \\nyou purchased it from.\\nY our review is important to us and the tech community and will help us make sure we’re delivering \\nexcellent quality content.263\\nDownload a free PDF copy of this book\\nThanks for purchasing this book!\\nDo you like to read on the go but are unable to carry your print books everywhere?\\nIs your eBook purchase not compatible with the device of your choice?\\nDon’t worry, now with every Packt book you get a DRM-free PDF version of that book at no cost.\\nRead anywhere, any place, on any device. Search, copy, and paste code from your favorite technical \\nbooks directly into your application.\\nThe perks don’t stop there, you can get exclusive access to discounts, newsletters, and great free content \\nin your inbox daily.\\nFollow these simple steps to get the benefits:\\n1. Scan the QR code or visit the link below\\nhttps://packt.link/free-ebook/9781803238753\\n2. Submit your proof of purchase\\n3. That’s it! We’ll send your free PDF and other benefits to your email directly'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e6019386",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_spliter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=50)\n",
    "\n",
    "splitted_text = text_spliter.split_text(text=my_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4026c6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(splitted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "60051b3d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Types of generative AI models 4\\nV AEs 5\\nGANs 6\\nAutoregressive models and Transformer \\narchitecture 7\\nLLM-powered AI agents 10\\nApplications of generative AI 16\\nChallenges and limitations of',\n",
       " 'Challenges and limitations of \\ngenerative AI 20\\nQuality of data and bias 21\\nData privacy 21\\nComputational resources 22\\nEthical and social implications 23\\nGeneralization and creativity 23\\nSummary 23',\n",
       " 'Generalization and creativity 23\\nSummary 23\\nQuestions 24\\nAnswers 24\\nFurther reading 24\\nReferences 24\\n2\\nPrinciples of Agentic Systems 27\\nTechnical requirements 28\\nUnderstanding self-governance,',\n",
       " 'Understanding self-governance, \\nagency, and autonomy 28\\nSelf-governance 29\\nAgency 29\\nAutonomy 30\\nExample of agency and autonomy in agents 32\\nReviewing intelligent agents and \\ntheir characteristics 35']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splitted_text[1:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e5dada72",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [Document(page_content= page, metadata={'page': idx + 1}) for idx, page in enumerate(splitted_text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18f61263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a574ffbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4107"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c870667e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'page': 112}, page_content='books directly into your application.\\nThe perks don’t stop there, you can get exclusive access to discounts, newsletters, and great free content \\nin your inbox daily.'),\n",
       " Document(metadata={'page': 113}, page_content='in your inbox daily.\\nFollow these simple steps to get the benefits:\\n1. Scan the QR code or visit the link below\\nhttps://packt.link/free-ebook/9781803238753\\n2. Submit your proof of purchase'),\n",
       " Document(metadata={'page': 114}, page_content='2. Submit your proof of purchase\\n3. That’s it! We’ll send your free PDF and other benefits to your email directlyPart 1:  \\nFoundations of Generative AI \\nand Agentic Systems'),\n",
       " Document(metadata={'page': 115}, page_content='Foundations of Generative AI \\nand Agentic Systems\\nThis part establishes the fundamental concepts of generative AI and agentic systems, providing you')]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[111:115]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd515e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_google = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "972248e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_embedding = embeddings_google.embed_documents(splitted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ea38c8fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_embedding[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "73f090f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4107"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(doc_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8e82108c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0019197484944015741,\n",
       " -0.03459292650222778,\n",
       " -0.022346975281834602,\n",
       " 0.007919039577245712,\n",
       " 0.018920546397566795,\n",
       " 0.014931164681911469,\n",
       " 0.016531774774193764,\n",
       " -0.013601112179458141,\n",
       " 0.039461903274059296,\n",
       " 0.016655653715133667,\n",
       " 0.006153702270239592,\n",
       " -0.0020256040152162313,\n",
       " 0.00026220324798487127,\n",
       " -0.010781124234199524,\n",
       " 0.04188596084713936,\n",
       " -0.06157964840531349,\n",
       " 0.02037241868674755,\n",
       " 0.012514863163232803,\n",
       " -0.01759234443306923,\n",
       " 0.009225876070559025,\n",
       " 0.001658369554206729,\n",
       " -0.004596306476742029,\n",
       " -0.025957491248846054,\n",
       " -0.0852944403886795,\n",
       " 0.019545400515198708,\n",
       " 0.004433842841535807,\n",
       " 0.07050349563360214,\n",
       " -0.04253770783543587,\n",
       " -0.03977356106042862,\n",
       " 0.05072292685508728,\n",
       " -0.03641685098409653,\n",
       " 0.016198743134737015,\n",
       " -0.05046018958091736,\n",
       " -0.03821072354912758,\n",
       " 0.030100740492343903,\n",
       " -0.030484454706311226,\n",
       " 0.013301295228302479,\n",
       " -0.020517561584711075,\n",
       " 0.051493171602487564,\n",
       " -0.005375204607844353,\n",
       " -0.03245998173952103,\n",
       " -0.0561162605881691,\n",
       " 0.005986612755805254,\n",
       " 0.022175852209329605,\n",
       " -0.005557798780500889,\n",
       " -0.013717489317059517,\n",
       " 0.004924483131617308,\n",
       " 0.010727032087743282,\n",
       " -0.020598646253347397,\n",
       " -0.10104640573263168,\n",
       " 0.06059707701206207,\n",
       " -0.019523881375789642,\n",
       " 0.01763107441365719,\n",
       " -0.009502512402832508,\n",
       " 0.020414389669895172,\n",
       " -0.05456061661243439,\n",
       " 0.029223980382084846,\n",
       " 0.041717030107975006,\n",
       " -0.000363436178304255,\n",
       " 0.0021764866542071104,\n",
       " 0.0031908180098980665,\n",
       " -0.019002534449100494,\n",
       " -0.02266981266438961,\n",
       " 0.0652732327580452,\n",
       " -0.010384071618318558,\n",
       " -0.023201612755656242,\n",
       " -0.008374353870749474,\n",
       " 0.00811635609716177,\n",
       " 0.031313709914684296,\n",
       " 0.007383454591035843,\n",
       " -0.010435249656438828,\n",
       " 0.01381015032529831,\n",
       " 0.048853062093257904,\n",
       " -0.053491685539484024,\n",
       " -0.03606784716248512,\n",
       " 0.0242450088262558,\n",
       " -0.030382299795746803,\n",
       " 0.03220541775226593,\n",
       " 0.0016560202930122614,\n",
       " 0.02957799844443798,\n",
       " 0.03247807174921036,\n",
       " -0.08766394853591919,\n",
       " -0.015716584399342537,\n",
       " -0.02958252839744091,\n",
       " -0.06022414192557335,\n",
       " -0.014125950634479523,\n",
       " 0.014335926622152328,\n",
       " -0.01964104361832142,\n",
       " 0.011493177153170109,\n",
       " 0.0006780565599910915,\n",
       " -0.05295121297240257,\n",
       " -0.03442325070500374,\n",
       " 0.014186966232955456,\n",
       " -0.07587798684835434,\n",
       " -0.010498923249542713,\n",
       " 0.06311863660812378,\n",
       " 0.011368505656719208,\n",
       " -0.03064330294728279,\n",
       " -0.02630913257598877,\n",
       " -0.0157372634857893,\n",
       " -0.02702363394200802,\n",
       " -0.037144359201192856,\n",
       " -0.0018898777198046446,\n",
       " 0.024280015379190445,\n",
       " 0.036810871213674545,\n",
       " 0.019956082105636597,\n",
       " -0.018941715359687805,\n",
       " 0.07129500806331635,\n",
       " 0.00573234586045146,\n",
       " 0.000768576399423182,\n",
       " -0.061876751482486725,\n",
       " 0.010340454056859016,\n",
       " -0.02939811535179615,\n",
       " -0.06375850737094879,\n",
       " 0.07765123248100281,\n",
       " -0.03480968996882439,\n",
       " -0.00961744599044323,\n",
       " 0.055189989507198334,\n",
       " 0.04127585515379906,\n",
       " 0.01638897880911827,\n",
       " -0.028794342651963234,\n",
       " -0.009022587910294533,\n",
       " 0.05066235363483429,\n",
       " 0.053097497671842575,\n",
       " -0.01023948471993208,\n",
       " 0.02913616970181465,\n",
       " -0.012051609344780445,\n",
       " 0.002432666951790452,\n",
       " 0.07446487993001938,\n",
       " -0.010762404650449753,\n",
       " -0.030168497934937477,\n",
       " 0.021718664094805717,\n",
       " -0.03611815348267555,\n",
       " 0.03987423703074455,\n",
       " 0.004436905030161142,\n",
       " 0.038831692188978195,\n",
       " 0.022711828351020813,\n",
       " -0.010198126547038555,\n",
       " 0.030219528824090958,\n",
       " 0.03663575276732445,\n",
       " -0.014381024986505508,\n",
       " 0.01227600034326315,\n",
       " -0.011712090112268925,\n",
       " 0.0017515233485028148,\n",
       " -0.03651813417673111,\n",
       " 0.05500632897019386,\n",
       " -0.030950365588068962,\n",
       " -0.014069292694330215,\n",
       " 0.002144315978512168,\n",
       " -0.023184647783637047,\n",
       " -0.04773265868425369,\n",
       " -0.016564838588237762,\n",
       " -0.06546855717897415,\n",
       " -0.0013234808575361967,\n",
       " 0.05924268066883087,\n",
       " 0.013262188993394375,\n",
       " -0.011707309633493423,\n",
       " 0.04341992363333702,\n",
       " -0.010128285735845566,\n",
       " 0.032465655356645584,\n",
       " 0.06326580047607422,\n",
       " 0.04300224781036377,\n",
       " 0.02798055298626423,\n",
       " 0.07736794650554657,\n",
       " -0.06465070694684982,\n",
       " -0.03015723079442978,\n",
       " 0.036227110773324966,\n",
       " 0.022671042010188103,\n",
       " -0.039013445377349854,\n",
       " -0.03578512370586395,\n",
       " -0.0568474605679512,\n",
       " 0.04451723396778107,\n",
       " -0.0672389566898346,\n",
       " -0.07163067162036896,\n",
       " -0.05434060096740723,\n",
       " -0.04150886461138725,\n",
       " -0.012937433086335659,\n",
       " 0.010748328641057014,\n",
       " -0.030361011624336243,\n",
       " -0.04970000684261322,\n",
       " -0.05350393429398537,\n",
       " -0.010614847764372826,\n",
       " -0.01774621196091175,\n",
       " 0.08106926083564758,\n",
       " -0.015303714200854301,\n",
       " -0.01589084602892399,\n",
       " 0.05539000779390335,\n",
       " -0.05526633560657501,\n",
       " -0.045767106115818024,\n",
       " 0.009330514818429947,\n",
       " -0.008375290781259537,\n",
       " -0.018351370468735695,\n",
       " 0.00757678272202611,\n",
       " -0.02341379038989544,\n",
       " -0.028908725827932358,\n",
       " 0.011173132807016373,\n",
       " 0.0435880646109581,\n",
       " -0.0013396244030445814,\n",
       " -0.000787288008723408,\n",
       " -0.006006138864904642,\n",
       " -0.01696670614182949,\n",
       " 0.05392884835600853,\n",
       " -0.025579046458005905,\n",
       " -0.01032976619899273,\n",
       " 0.0037625457625836134,\n",
       " -0.026281103491783142,\n",
       " 0.029810402542352676,\n",
       " -0.028027696534991264,\n",
       " -0.0040636854246258736,\n",
       " 0.05113334208726883,\n",
       " -0.040221620351076126,\n",
       " 0.03275159373879433,\n",
       " 0.013502394780516624,\n",
       " 0.00054668087977916,\n",
       " 0.010711737908422947,\n",
       " -0.011732099577784538,\n",
       " 0.06257220357656479,\n",
       " 0.02758350409567356,\n",
       " 0.009146396070718765,\n",
       " -0.0351128913462162,\n",
       " 0.05664144456386566,\n",
       " -0.024824220687150955,\n",
       " -0.023439573124051094,\n",
       " 0.028025828301906586,\n",
       " 0.02155088074505329,\n",
       " 0.05309949815273285,\n",
       " -0.031973641365766525,\n",
       " 0.02473263628780842,\n",
       " 0.01968006230890751,\n",
       " -0.055424876511096954,\n",
       " -0.0253368578851223,\n",
       " 0.04278147965669632,\n",
       " 0.04177778586745262,\n",
       " -0.00020482632680796087,\n",
       " 0.05586642026901245,\n",
       " -0.008126829750835896,\n",
       " 0.045395247638225555,\n",
       " 0.01699184812605381,\n",
       " -0.013591266237199306,\n",
       " 0.015198629349470139,\n",
       " -0.03235449641942978,\n",
       " 0.03895047679543495,\n",
       " 0.03841134533286095,\n",
       " 0.039979398250579834,\n",
       " -0.0433003194630146,\n",
       " -0.052282337099313736,\n",
       " -0.02239215187728405,\n",
       " -0.011683216318488121,\n",
       " 0.023642614483833313,\n",
       " 0.013724284246563911,\n",
       " -0.017965907230973244,\n",
       " -0.03533085435628891,\n",
       " 0.011948500759899616,\n",
       " 0.0003304056590422988,\n",
       " -0.01479287538677454,\n",
       " 0.03202090039849281,\n",
       " -0.05619524419307709,\n",
       " -0.07570433616638184,\n",
       " 0.03061356022953987,\n",
       " 0.012840713374316692,\n",
       " 0.017304087057709694,\n",
       " 0.023334715515375137,\n",
       " -0.02395991049706936,\n",
       " -0.049041248857975006,\n",
       " 0.011735273525118828,\n",
       " 0.022406140342354774,\n",
       " 0.007270997390151024,\n",
       " -0.019038349390029907,\n",
       " 0.02733818255364895,\n",
       " 0.03936440497636795,\n",
       " 0.00019706958846654743,\n",
       " -0.04153415188193321,\n",
       " 0.03597239777445793,\n",
       " -0.007116638123989105,\n",
       " 0.031807783991098404,\n",
       " -0.015522882342338562,\n",
       " -0.020173978060483932,\n",
       " 0.01078061480075121,\n",
       " 0.015683619305491447,\n",
       " -0.021105166524648666,\n",
       " 0.03599243983626366,\n",
       " 0.043283719569444656,\n",
       " 0.08165206015110016,\n",
       " -0.025000743567943573,\n",
       " -0.037545062601566315,\n",
       " 0.020405542105436325,\n",
       " -0.007201011758297682,\n",
       " -0.005151377059519291,\n",
       " -0.028408553451299667,\n",
       " -0.029469463974237442,\n",
       " 0.01570572704076767,\n",
       " 0.053361956030130386,\n",
       " -0.03860139846801758,\n",
       " -0.025865253061056137,\n",
       " -0.09922236949205399,\n",
       " -0.01687142439186573,\n",
       " -0.008256549946963787,\n",
       " 0.03706321492791176,\n",
       " -0.03246248513460159,\n",
       " -0.008331160061061382,\n",
       " 0.024726418778300285,\n",
       " -0.03188484534621239,\n",
       " 0.0049592298455536366,\n",
       " -0.06296516209840775,\n",
       " 0.003617827780544758,\n",
       " 0.020678887143731117,\n",
       " -0.006997507996857166,\n",
       " -0.04960193112492561,\n",
       " 0.06219683215022087,\n",
       " -0.012856599874794483,\n",
       " 0.027437755838036537,\n",
       " -0.07131556421518326,\n",
       " -0.03663361817598343,\n",
       " -0.04565480723977089,\n",
       " 0.03644789382815361,\n",
       " 0.0042669763788580894,\n",
       " -0.04103510454297066,\n",
       " 0.0003855001996271312,\n",
       " 0.011925342492759228,\n",
       " 0.05507729947566986,\n",
       " -0.0073281945660710335,\n",
       " 0.06549657881259918,\n",
       " -0.0012609210098162293,\n",
       " -0.025522151961922646,\n",
       " -0.006741704419255257,\n",
       " 0.01916346698999405,\n",
       " -0.0500493124127388,\n",
       " 0.04357470944523811,\n",
       " 0.0213706586509943,\n",
       " 0.046283554285764694,\n",
       " 0.010855872184038162,\n",
       " -0.015950722619891167,\n",
       " -0.0003381379647180438,\n",
       " 0.025592681020498276,\n",
       " 0.016255002468824387,\n",
       " -0.02410564385354519,\n",
       " -0.0430021807551384,\n",
       " 0.011040668934583664,\n",
       " 0.011009668000042439,\n",
       " 0.006162719335407019,\n",
       " 0.00380296865478158,\n",
       " 0.013568898662924767,\n",
       " -0.04409113898873329,\n",
       " -0.015778040513396263,\n",
       " 0.050045356154441833,\n",
       " 0.007574259769171476,\n",
       " -0.023230930790305138,\n",
       " -0.027249548584222794,\n",
       " 0.06889726966619492,\n",
       " 0.02255699224770069,\n",
       " 3.826445390586741e-05,\n",
       " 0.06863942742347717,\n",
       " -0.04367920383810997,\n",
       " 0.043198276311159134,\n",
       " -0.011157390661537647,\n",
       " -0.02979041263461113,\n",
       " 0.02924118936061859,\n",
       " 0.006755650043487549,\n",
       " 0.059896644204854965,\n",
       " -0.038843780755996704,\n",
       " -0.057950545102357864,\n",
       " 0.015933608636260033,\n",
       " 0.0076618199236691,\n",
       " -0.020761733874678612,\n",
       " 0.019596852362155914,\n",
       " 0.023068483918905258,\n",
       " 0.017121942713856697,\n",
       " -0.023727862164378166,\n",
       " -0.033765748143196106,\n",
       " 0.005377471912652254,\n",
       " -0.03354291617870331,\n",
       " -0.0045090620405972,\n",
       " 0.05686059594154358,\n",
       " -0.021425630897283554,\n",
       " -0.013495431281626225,\n",
       " -0.033747244626283646,\n",
       " -0.0027751538436859846,\n",
       " -0.06157710775732994,\n",
       " 0.03127870708703995,\n",
       " 0.055514462292194366,\n",
       " -0.028103899210691452,\n",
       " 0.02093672938644886,\n",
       " -0.009658116847276688,\n",
       " 0.0772540494799614,\n",
       " -0.020579874515533447,\n",
       " 0.03840423747897148,\n",
       " 0.01773468218743801,\n",
       " 0.027691273018717766,\n",
       " 0.004460095427930355,\n",
       " 0.008566725067794323,\n",
       " 0.026011958718299866,\n",
       " 0.0450517013669014,\n",
       " 0.06615285575389862,\n",
       " 0.028973346576094627,\n",
       " 0.03802376985549927,\n",
       " 0.010858648456633091,\n",
       " -0.02201208658516407,\n",
       " -0.055307649075984955,\n",
       " -0.02628597617149353,\n",
       " -0.011438393965363503,\n",
       " -0.010979128070175648,\n",
       " 0.020904073491692543,\n",
       " -0.024006180465221405,\n",
       " -0.003275916213169694,\n",
       " 0.007306718733161688,\n",
       " -0.06314131617546082,\n",
       " -0.013200941495597363,\n",
       " -0.04693705216050148,\n",
       " -0.0005555492825806141,\n",
       " -0.005260044243186712,\n",
       " 0.0004742769815493375,\n",
       " 0.017889123409986496,\n",
       " 0.07472892850637436,\n",
       " -0.054283443838357925,\n",
       " -0.011203589849174023,\n",
       " 0.010050124488770962,\n",
       " 0.022457057610154152,\n",
       " -0.014836188405752182,\n",
       " 0.003018473507836461,\n",
       " 0.038712892681360245,\n",
       " -0.012809891253709793,\n",
       " -0.003860263619571924,\n",
       " 0.0259805079549551,\n",
       " -0.0008274390711449087,\n",
       " -0.007722897920757532,\n",
       " -0.004954071715474129,\n",
       " -0.0005895320209674537,\n",
       " -0.00968464370816946,\n",
       " -0.014497671276330948,\n",
       " -0.02348017878830433,\n",
       " 0.04740598052740097,\n",
       " 0.056405264884233475,\n",
       " -0.013657893985509872,\n",
       " 0.03358747437596321,\n",
       " 0.0030990787781774998,\n",
       " -0.030273759737610817,\n",
       " -0.018745064735412598,\n",
       " 0.02396950125694275,\n",
       " -0.03301628306508064,\n",
       " -0.02622244507074356,\n",
       " 0.03725283965468407,\n",
       " -0.030524225905537605,\n",
       " -0.010728343389928341,\n",
       " -0.04989379271864891,\n",
       " -0.07677403092384338,\n",
       " -0.048713989555835724,\n",
       " 0.0017561104614287615,\n",
       " -0.015450623817741871,\n",
       " 0.022446012124419212,\n",
       " -0.1000673770904541,\n",
       " 0.04246510565280914,\n",
       " -0.05506227910518646,\n",
       " 0.021902291104197502,\n",
       " -0.08558565378189087,\n",
       " -0.05013461038470268,\n",
       " -0.03777189552783966,\n",
       " 0.002682108199223876,\n",
       " 0.039240941405296326,\n",
       " -0.045491404831409454,\n",
       " -0.004052856471389532,\n",
       " 0.009643811732530594,\n",
       " -0.08930665254592896,\n",
       " -0.010610278695821762,\n",
       " -0.047378744930028915,\n",
       " 0.03612753376364708,\n",
       " -0.05083410441875458,\n",
       " -0.04747680574655533,\n",
       " -0.0027254766318947077,\n",
       " 0.04489777237176895,\n",
       " 0.07472477853298187,\n",
       " 0.012980750761926174,\n",
       " -0.043985478579998016,\n",
       " 0.028104254975914955,\n",
       " 0.012390374206006527,\n",
       " 0.003746268106624484,\n",
       " 0.0036429024767130613,\n",
       " -0.08604119718074799,\n",
       " 0.02252836525440216,\n",
       " -0.03108208067715168,\n",
       " 0.01166883111000061,\n",
       " 0.007881070487201214,\n",
       " -0.003930240869522095,\n",
       " 0.042811889201402664,\n",
       " 0.04728958383202553,\n",
       " -0.038752082735300064,\n",
       " -0.045758455991744995,\n",
       " 0.03137222304940224,\n",
       " 0.021728793159127235,\n",
       " -0.0008985612075775862,\n",
       " 0.022141102701425552,\n",
       " 0.020188288763165474,\n",
       " 0.017089320346713066,\n",
       " -0.03227720037102699,\n",
       " -0.04749695211648941,\n",
       " -0.019048476591706276,\n",
       " 0.017789900302886963,\n",
       " -0.028690339997410774,\n",
       " 0.0759597048163414,\n",
       " 0.06133127585053444,\n",
       " 0.05385544151067734,\n",
       " -0.031237980350852013,\n",
       " -0.05207988619804382,\n",
       " -0.021001681685447693,\n",
       " -0.051244914531707764,\n",
       " 0.03672469034790993,\n",
       " -0.08527690917253494,\n",
       " -0.007683408912271261,\n",
       " 0.015526879578828812,\n",
       " -0.023966049775481224,\n",
       " -0.030827993527054787,\n",
       " -0.03050650656223297,\n",
       " -0.0018564308993518353,\n",
       " -0.00827782228589058,\n",
       " -0.040713969618082047,\n",
       " 0.06152964383363724,\n",
       " -0.044968381524086,\n",
       " -0.0305522158741951,\n",
       " 0.032792165875434875,\n",
       " 0.0938878282904625,\n",
       " 0.006485416553914547,\n",
       " 0.02215723879635334,\n",
       " 0.007178764324635267,\n",
       " -0.08037304878234863,\n",
       " 0.013681027106940746,\n",
       " 0.01817512884736061,\n",
       " -0.023474324494600296,\n",
       " 0.014110824093222618,\n",
       " -0.0010026571108028293,\n",
       " -0.05321142449975014,\n",
       " 0.024926682934165,\n",
       " -0.04635872691869736,\n",
       " 0.0776679515838623,\n",
       " -0.09310171008110046,\n",
       " 0.018719902262091637,\n",
       " -0.032644953578710556,\n",
       " -0.0077797588892281055,\n",
       " 0.007505381014198065,\n",
       " 0.0015626605600118637,\n",
       " 0.003639841452240944,\n",
       " -0.007686757016927004,\n",
       " 0.015551814809441566,\n",
       " -0.0647420585155487,\n",
       " 0.03315017744898796,\n",
       " 0.023094788193702698,\n",
       " -0.025478288531303406,\n",
       " 0.03574446961283684,\n",
       " 0.04314281418919563,\n",
       " -0.09056081622838974,\n",
       " 0.024228541180491447,\n",
       " -0.02966069057583809,\n",
       " 0.01642606221139431,\n",
       " 0.03913706913590431,\n",
       " 0.021287772804498672,\n",
       " 0.02102797105908394,\n",
       " 0.0617128387093544,\n",
       " -0.0589350163936615,\n",
       " -0.04415752366185188,\n",
       " -0.010528373531997204,\n",
       " -0.006207231432199478,\n",
       " -0.002974236384034157,\n",
       " -0.0369395837187767,\n",
       " -0.012167143635451794,\n",
       " -0.007246517110615969,\n",
       " -0.03386063873767853,\n",
       " 0.07760274410247803,\n",
       " 0.001269361237064004,\n",
       " -0.0001867993560153991,\n",
       " -0.012265706434845924,\n",
       " 0.026758715510368347,\n",
       " 0.013508116826415062,\n",
       " -0.05632145330309868,\n",
       " -0.024915888905525208,\n",
       " 0.004613563884049654,\n",
       " 0.004779590293765068,\n",
       " 0.038834769278764725,\n",
       " -0.0695909634232521,\n",
       " -0.021396096795797348,\n",
       " -0.012821916490793228,\n",
       " 0.020019521936774254,\n",
       " 0.05467687547206879,\n",
       " 0.04071936383843422,\n",
       " 0.021475594490766525,\n",
       " -0.013116412796080112,\n",
       " 0.0037032118998467922,\n",
       " -0.015871787443757057,\n",
       " 0.0037203431129455566,\n",
       " -0.014110816642642021,\n",
       " 0.06248129531741142,\n",
       " 0.0469023622572422,\n",
       " 0.027898402884602547,\n",
       " -0.09735354781150818,\n",
       " 0.05927963927388191,\n",
       " -0.046863358467817307,\n",
       " 0.028366316109895706,\n",
       " -0.028304049745202065,\n",
       " 0.005418742075562477,\n",
       " 0.019995717331767082,\n",
       " -0.0065920050255954266,\n",
       " -0.0113084577023983,\n",
       " 0.031278956681489944,\n",
       " 0.004556328523904085,\n",
       " -0.04196611046791077,\n",
       " 0.0748126208782196,\n",
       " -0.052276164293289185,\n",
       " 0.008982851170003414,\n",
       " 0.05614232271909714,\n",
       " -0.0023599802516400814,\n",
       " 0.01361167337745428,\n",
       " -0.0015488213393837214,\n",
       " -0.007857591845095158,\n",
       " -0.017615830525755882,\n",
       " -0.03358864411711693,\n",
       " 0.03989892080426216,\n",
       " 0.010101228021085262,\n",
       " -0.03396662324666977,\n",
       " -0.03298313170671463,\n",
       " 0.0253371000289917,\n",
       " 0.024148957803845406,\n",
       " -0.006789711769670248,\n",
       " -0.04154348373413086,\n",
       " -0.007413347251713276,\n",
       " -0.0045693241991102695,\n",
       " 0.0013393904082477093,\n",
       " 0.03484112769365311,\n",
       " 0.0700196698307991,\n",
       " 0.001367612392641604,\n",
       " -0.06839483231306076,\n",
       " 0.023275433108210564,\n",
       " 0.06785406917333603,\n",
       " 0.05528242141008377,\n",
       " 0.033554039895534515,\n",
       " 0.059078317135572433,\n",
       " 0.00829631183296442,\n",
       " -0.04286019131541252,\n",
       " -0.06567440181970596,\n",
       " 0.013585805892944336,\n",
       " -0.028540361672639847,\n",
       " -3.829506385955028e-05,\n",
       " 0.026342596858739853,\n",
       " 0.01789642684161663,\n",
       " -0.04652268812060356,\n",
       " 0.040898360311985016,\n",
       " 0.03244810178875923,\n",
       " 0.019191117957234383,\n",
       " 0.008442536927759647,\n",
       " 0.045109257102012634,\n",
       " 0.00020986224990338087,\n",
       " -0.08373188972473145,\n",
       " -0.05246494337916374,\n",
       " 0.05784226208925247,\n",
       " -0.037844862788915634,\n",
       " 0.0031697365920990705,\n",
       " 0.005566755775362253,\n",
       " -0.040902554988861084,\n",
       " -0.008366604335606098,\n",
       " 0.03102676197886467,\n",
       " -0.04729524999856949,\n",
       " -0.06602319329977036,\n",
       " 0.060862116515636444,\n",
       " 0.01214942429214716,\n",
       " -0.042059119790792465,\n",
       " -0.01912056840956211,\n",
       " -0.022074785083532333,\n",
       " -0.03451498970389366,\n",
       " 0.01756124198436737,\n",
       " -0.014736061915755272,\n",
       " -0.042990509420633316,\n",
       " -0.08812236040830612,\n",
       " -0.03576335683465004,\n",
       " 0.005459128879010677,\n",
       " -0.026189299300312996,\n",
       " 0.04912841320037842,\n",
       " 0.027884922921657562,\n",
       " -0.026435185223817825,\n",
       " 0.035881150513887405,\n",
       " -0.004243545234203339,\n",
       " -0.029026396572589874,\n",
       " 0.020349936559796333,\n",
       " -0.03500816226005554,\n",
       " 0.009029240347445011,\n",
       " -0.02569490484893322,\n",
       " -0.02969208173453808,\n",
       " -0.006451814901083708,\n",
       " -0.025887085124850273,\n",
       " 0.0027189876418560743,\n",
       " -0.015032095834612846,\n",
       " 0.01586204394698143,\n",
       " -0.02553941123187542,\n",
       " -0.03818116709589958,\n",
       " -0.007624796126037836,\n",
       " 0.014618152752518654,\n",
       " -0.07601423561573029,\n",
       " -0.021286290138959885,\n",
       " 0.017329640686511993,\n",
       " 0.039091866463422775,\n",
       " 0.01600774936378002,\n",
       " -0.07599209994077682,\n",
       " 0.0031679547391831875,\n",
       " 0.005016553681343794,\n",
       " 0.06559748947620392,\n",
       " -0.03295622020959854,\n",
       " -0.057152364403009415,\n",
       " 0.012268148362636566,\n",
       " -0.008523061871528625,\n",
       " 0.007188992574810982,\n",
       " 0.013038607314229012,\n",
       " -0.01689084805548191,\n",
       " -0.007283166982233524,\n",
       " -0.0005069095641374588,\n",
       " 0.013018489815294743,\n",
       " 0.06250333786010742,\n",
       " -0.029583942145109177,\n",
       " -0.05864501744508743,\n",
       " 0.017226530238986015,\n",
       " 0.009294659830629826,\n",
       " 0.06448269635438919,\n",
       " -0.003460303181782365,\n",
       " -0.009757384657859802,\n",
       " -0.03865562006831169,\n",
       " 0.013008279725909233,\n",
       " 0.012498768977820873,\n",
       " 0.03334014117717743,\n",
       " 0.0505300834774971,\n",
       " -0.05716383829712868,\n",
       " -0.00420408695936203,\n",
       " -0.014902450144290924,\n",
       " -0.01974816992878914,\n",
       " -0.04135269671678543,\n",
       " 0.03598718345165253,\n",
       " -0.04451953247189522,\n",
       " 0.037388887256383896,\n",
       " -0.03712347894906998,\n",
       " 0.0016851130640134215,\n",
       " 0.053171172738075256,\n",
       " -0.019225196912884712,\n",
       " 0.055926065891981125,\n",
       " -0.024332372471690178,\n",
       " -0.013610292226076126,\n",
       " -0.00273122382350266,\n",
       " -0.0736190527677536,\n",
       " -0.013516424223780632,\n",
       " -0.007174328435212374,\n",
       " -0.0045121158473193645,\n",
       " 0.04707945138216019,\n",
       " 0.04199932515621185,\n",
       " -0.056072548031806946,\n",
       " 0.024408120661973953,\n",
       " 0.014103087596595287,\n",
       " 0.0010939708445221186,\n",
       " -0.08501657098531723,\n",
       " -0.02084890939295292,\n",
       " 0.013191116973757744,\n",
       " 0.03383628651499748,\n",
       " 0.1140831857919693,\n",
       " 0.04157295450568199,\n",
       " -0.012701539322733879,\n",
       " 0.009359286166727543,\n",
       " -0.010677296668291092,\n",
       " -0.003614515997469425,\n",
       " 0.03672255575656891,\n",
       " -0.06287632882595062,\n",
       " 0.021802745759487152,\n",
       " -0.014224981889128685,\n",
       " 0.0147164948284626,\n",
       " -0.0026344233192503452,\n",
       " 0.051483090966939926,\n",
       " -0.002490570303052664,\n",
       " 0.03196214884519577]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = 'what is agentic ai'\n",
    "embed_query = embeddings_google.embed_query(query)\n",
    "embed_query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad4658e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.66592274, 0.67545977, 0.59952191, ..., 0.5543564 , 0.53533525,\n",
       "        0.50260981]], shape=(1, 4107))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_similarity([embed_query], doc_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "30276563",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.81740634, 0.80565443, 0.89496063, ..., 0.94407907, 0.96401627,\n",
       "        0.99738585]], shape=(1, 4107))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "euclidean_distances([embed_query], doc_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d4abd48d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone\n",
    "\n",
    "# Create client instance\n",
    "pc = Pinecone(api_key=PINECONE_API_KEY, environment=PINECONE_INDEX_ENVIRONMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "275c3ad6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.has_index(PINECONE_INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "54ab47e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dimension = len(doc_embedding[0])\n",
    "embedding_dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "332717f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not pc.has_index(PINECONE_INDEX_NAME):\n",
    "    pc.create_index(name=PINECONE_INDEX_NAME, \n",
    "                    dimension=embedding_dimension,\n",
    "                    metric='cosine',\n",
    "                    spec=ServerlessSpec(cloud=PINECONE_CLOUD, region=PINECONE_INDEX_ENVIRONMENT)\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bce8ec1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pc.has_index(PINECONE_INDEX_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3784fd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_index = pc.Index(PINECONE_INDEX_NAME)\n",
    "pinecone_vs = PineconeVectorStore(index=pc_index, embedding=embeddings_google)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6dcc802d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(self, index: 'Optional[Any]' = None, embedding: 'Optional[Embeddings]' = None, text_key: 'Optional[str]' = 'text', namespace: 'Optional[str]' = None, distance_strategy: 'Optional[DistanceStrategy]' = <DistanceStrategy.COSINE: 'COSINE'>, *, pinecone_api_key: 'Optional[str]' = None, index_name: 'Optional[str]' = None)\n"
     ]
    }
   ],
   "source": [
    "# help(PineconeVectorStore)\n",
    "# or\n",
    "from inspect import signature\n",
    "print(signature(PineconeVectorStore.__init__))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9619a1f",
   "metadata": {},
   "source": [
    "(self, index: 'Optional[Any]' = None, embedding: 'Optional[Embeddings]' = None, text_key: 'Optional[str]' = 'text', namespace: 'Optional[str]' = None, distance_strategy: 'Optional[DistanceStrategy]' = <DistanceStrategy.COSINE: 'COSINE'>, *, pinecone_api_key: 'Optional[str]' = None, index_name: 'Optional[str]' = None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "577d47cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from uuid import uuid4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "eb754a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "uuids = [str(uuid4()) for _ in range(len(documents))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2a652dfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43e4bab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(uuids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8609989b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4107"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17a0293f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commented this cell code to avoid duplicate record loading into the DB. This is working and essential code\n",
    "# batch_size = 500\n",
    "# start = 0\n",
    "# end = batch_size\n",
    "\n",
    "# while start < len(documents):\n",
    "#     if end > len(documents):\n",
    "#         end = len(documents)\n",
    "    \n",
    "#     temp_doc = documents[start:end]\n",
    "#     temp_uuids = uuids[start:end]\n",
    "\n",
    "#     pinecone_vs.add_documents(documents=documents[start:end], ids=uuids[start:end])\n",
    "\n",
    "#     start = end\n",
    "#     end = end + batch_size\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1abbb71b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='2249cb3a-b9c3-4e86-b0f7-714dfaabe1e9', metadata={'page': 3425.0}, page_content='that go beyond those of traditional generative AI. While generative AI primarily focuses on content \\ncreation, agentic systems can autonomously plan, decide, and act, making their safe deployment'),\n",
       " Document(id='36e707fc-c0e0-46b1-a713-186ce23f042c', metadata={'page': 3425.0}, page_content='that go beyond those of traditional generative AI. While generative AI primarily focuses on content \\ncreation, agentic systems can autonomously plan, decide, and act, making their safe deployment'),\n",
       " Document(id='2e59c31a-0f40-4721-ada8-efa2cdfe19f5', metadata={'page': 486.0}, page_content='scenarios, and provide intelligent recommendations or automated decision-making capabilities. \\nAgentic AI systems have been applied in domains such as finance, healthcare, transportation,'),\n",
       " Document(id='83273843-3194-44c3-b869-78cd81c0aa47', metadata={'page': 486.0}, page_content='scenarios, and provide intelligent recommendations or automated decision-making capabilities. \\nAgentic AI systems have been applied in domains such as finance, healthcare, transportation,'),\n",
       " Document(id='a4a80dc9-b971-4ec3-9dc2-a4f8443bc2c2', metadata={'page': 1155.0}, page_content='back into the learning mechanisms to refine the agent’s knowledge and decision models based \\non experience\\nStart building agentic AI')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pinecone_vs.similarity_search(\"what is agentic ai\",k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a24da8ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = pinecone_vs.as_retriever(kwargs={'k':5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "0ccf9a47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id='36e707fc-c0e0-46b1-a713-186ce23f042c', metadata={'page': 3425.0}, page_content='that go beyond those of traditional generative AI. While generative AI primarily focuses on content \\ncreation, agentic systems can autonomously plan, decide, and act, making their safe deployment'),\n",
       " Document(id='2249cb3a-b9c3-4e86-b0f7-714dfaabe1e9', metadata={'page': 3425.0}, page_content='that go beyond those of traditional generative AI. While generative AI primarily focuses on content \\ncreation, agentic systems can autonomously plan, decide, and act, making their safe deployment'),\n",
       " Document(id='83273843-3194-44c3-b869-78cd81c0aa47', metadata={'page': 486.0}, page_content='scenarios, and provide intelligent recommendations or automated decision-making capabilities. \\nAgentic AI systems have been applied in domains such as finance, healthcare, transportation,'),\n",
       " Document(id='2e59c31a-0f40-4721-ada8-efa2cdfe19f5', metadata={'page': 486.0}, page_content='scenarios, and provide intelligent recommendations or automated decision-making capabilities. \\nAgentic AI systems have been applied in domains such as finance, healthcare, transportation,')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = retriever.invoke(\"what is agentic ai?\")\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f5c0c5eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['that go beyond those of traditional generative AI. While generative AI primarily focuses on content \\ncreation, agentic systems can autonomously plan, decide, and act, making their safe deployment',\n",
       " 'that go beyond those of traditional generative AI. While generative AI primarily focuses on content \\ncreation, agentic systems can autonomously plan, decide, and act, making their safe deployment',\n",
       " 'scenarios, and provide intelligent recommendations or automated decision-making capabilities. \\nAgentic AI systems have been applied in domains such as finance, healthcare, transportation,',\n",
       " 'scenarios, and provide intelligent recommendations or automated decision-making capabilities. \\nAgentic AI systems have been applied in domains such as finance, healthcare, transportation,']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context = [doc.page_content for doc in context]\n",
    "context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2521d024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatGoogleGenerativeAI(model='models/gemini-1.5-flash', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x000001BA8845CEC0>, default_metadata=())"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = ChatGoogleGenerativeAI(model='gemini-1.5-flash')\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "fcbc3a13",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, metadata={'lc_hub_owner': 'rlm', 'lc_hub_repo': 'rag-prompt', 'lc_hub_commit_hash': '50442af133e61576e74536c6556cefe1fac147cad032f4377b60c436e6cdcb6e'}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = hub.pull('rlm/rag-prompt')\n",
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3e095758",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptValue(messages=[HumanMessage(content=\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: what is agentic ai? \\nContext: langchain is very super framework for LLM. \\nAnswer:\", additional_kwargs={}, response_metadata={})])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt.invoke({'question':'what is agentic ai?', 'context': 'langchain is very super framework for LLM.'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3633d352",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = model.invoke(prompt.invoke({\n",
    "    'question': 'what is agentic ai?',\n",
    "    'context': context\n",
    "}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "573ae3d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Agentic AI goes beyond traditional generative AI by autonomously planning, deciding, and acting.  Unlike generative AI which focuses on content creation, agentic AI systems can make decisions and take actions.  This makes their safe deployment a key concern.'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b47237",
   "metadata": {},
   "source": [
    "'Agentic AI systems can autonomously plan, decide, and act, unlike generative AI which focuses on content creation.  They utilize learned knowledge to make decisions and refine their actions based on experience.  These systems are being applied in various fields like finance and healthcare.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "188f35ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"Topic\": {\"description\": \"selected topic\", \"title\": \"Topic\", \"type\": \"string\"}, \"Reasoning\": {\"description\": \"Reasoning behind the topic selection.\", \"title\": \"Reasoning\", \"type\": \"string\"}}, \"required\": [\"Topic\", \"Reasoning\"]}\\n```'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class TopicSelectionParser(BaseModel):\n",
    "    Topic: str = Field(description='selected topic')\n",
    "    Reasoning: str = Field(description='Reasoning behind the topic selection.')\n",
    "\n",
    "parser=PydanticOutputParser(pydantic_object=TopicSelectionParser)\n",
    "\n",
    "parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89c0d5dd",
   "metadata": {},
   "source": [
    "'The output should be formatted as a JSON instance that conforms to the JSON schema below.\\n\\nAs an example, for the schema {\"properties\": {\"foo\": {\"title\": \"Foo\", \"description\": \"a list of strings\", \"type\": \"array\", \"items\": {\"type\": \"string\"}}}, \"required\": [\"foo\"]}\\nthe object {\"foo\": [\"bar\", \"baz\"]} is a well-formatted instance of the schema. The object {\"properties\": {\"foo\": [\"bar\", \"baz\"]}} is not well-formatted.\\n\\nHere is the output schema:\\n```\\n{\"properties\": {\"Topic\": {\"description\": \"selected topic\", \"title\": \"Topic\", \"type\": \"string\"}, \"Reasoning\": {\"description\": \"Reasoning behind the topic selection.\", \"title\": \"Reasoning\", \"type\": \"string\"}}, \"required\": [\"Topic\", \"Reasoning\"]}\\n```'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c09d7d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgentState(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], operator.add]\n",
    "    validation_passed: bool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "ff4a413d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# supervisor function\n",
    "def supervisor(state: AgentState):\n",
    "    \n",
    "    print(f\"[supervisor]: START: {state}\")\n",
    "\n",
    "    question = state['messages'][0]\n",
    "\n",
    "    template = \"\"\"Your task is to classify the given user question into one of the category only: [rag, llm, web]. \n",
    "    Expected response is one of the given category only nothing else at all.\n",
    "\n",
    "    user query: {question}\n",
    "    {format_instructions}\n",
    "    \"\"\"\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "        template=template,\n",
    "        input_variables=['question'],\n",
    "        partial_variables={'format_instructions': parser.get_format_instructions()}\n",
    "    )\n",
    "\n",
    "    chain = prompt | model | parser\n",
    "\n",
    "    response = chain.invoke({'question': question})\n",
    "    \n",
    "    print(f\"[supervisor]: END: {state}\")\n",
    "    print(f\"messages: {response.Topic}\")\n",
    "    print(f'EXIT from supervisor')\n",
    "    # return {'messages': [SystemMessage(content=response.Topic)]}\n",
    "    return {'messages': [response.Topic]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "92f521e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[supervisor]: START: {'messages': [HumanMessage(content='What is agentic AI?', additional_kwargs={}, response_metadata={})]}\n",
      "[supervisor]: END: {'messages': [HumanMessage(content='What is agentic AI?', additional_kwargs={}, response_metadata={})]}\n",
      "messages: llm\n",
      "EXIT from supervisor\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': ['llm']}"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "supervisor({\n",
    "    \"messages\": [HumanMessage(content=\"What is agentic AI?\")],\n",
    "    # \"validation_passed\": False,\n",
    "    # \"format_instructions\": \"Respond in 2 lines using clear, structured explanation.\"\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "1b21ff1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rag function\n",
    "\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join(doc.page_content for doc in docs)    \n",
    "\n",
    "def rag(state: AgentState):\n",
    "    print(f\"[rag]: START: {state}\")\n",
    "\n",
    "    question = state['messages'][0]\n",
    "\n",
    "    prompt = PromptTemplate(\n",
    "                                template=\"\"\"You are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\"\",\n",
    "                                input_variables=['question', 'context']\n",
    "                            )\n",
    "\n",
    "    rag_chain = ({'context': retriever | format_docs, 'question': RunnablePassthrough()}\n",
    "                | prompt\n",
    "                | model\n",
    "                | parser)\n",
    "    \n",
    "    response = rag_chain.invoke(question)\n",
    "\n",
    "    print(f\"[rag]: END: {state}\")\n",
    "    print(f\"messages: {response}\")\n",
    "    \n",
    "    return {'messages': [response.content]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "796ca278",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM function\n",
    "\n",
    "def llm(state: AgentState):\n",
    "    print('inside llm node')\n",
    "    print(f\"[llm]: START: {state}\")\n",
    "\n",
    "    question = state['messages'][0].content\n",
    "    \n",
    "    print(f'question: {question}')\n",
    "\n",
    "    complete_query = \"Anwer the follow question with you knowledge of the real world. Following is the user question: \" + question\n",
    "    response = model.invoke(complete_query)\n",
    "\n",
    "    print(f\"[llm]: END: {state}\")\n",
    "    print(f\"messages: {response}\")\n",
    "    print('EXIT from llm')\n",
    "\n",
    "    return {'messages': [SystemMessage(content=response.content)]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "95220f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # web function\n",
    "\n",
    "def web(state: AgentState):\n",
    "\n",
    "    print(f\"[web]: START: {state}\")\n",
    "\n",
    "    question = state['messages']\n",
    "    print(f'question: {question}')\n",
    "    # question = state['messages']\n",
    "\n",
    "    search = DuckDuckGoSearchRun()\n",
    "\n",
    "    response = search.invoke(question)\n",
    "\n",
    "    print(f\"[web]: END: {state}\")\n",
    "    print(f\"messages: {response}\")\n",
    "\n",
    "    return {'messages': [HumanMessage(content=response)]}\n",
    "\n",
    "# ans = web({\n",
    "#     'messages': \"APJ Abdul Kalam's first name?\"\n",
    "# })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "762cbf82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "4bada9d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# router function: rag, llm, web\n",
    "\n",
    "def router(state: AgentState):\n",
    "    message = state['messages'][-1]\n",
    "\n",
    "    if 'rag' in message:\n",
    "        return 'rag'\n",
    "    elif 'web' in message:\n",
    "        return 'web'\n",
    "    elif 'llm' in message:\n",
    "        return 'llm'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "9d03db95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def validation_router(state: AgentState) -> str:\n",
    "#     if state[\"validation_passed\"]:\n",
    "#         return 'end'       # Moves to __end__\n",
    "#     else:\n",
    "#         return 'supervisor'  # Re-routes to supervisor\n",
    "\n",
    "def validation_router(state: AgentState)-> AgentState:\n",
    "    \"\"\"Validates LLM response based on different use case rules.\"\"\"\n",
    "    print(f\"[validation_router]: START: {state}\")\n",
    "\n",
    "    messages = state[\"messages\"]\n",
    "    response = messages[-1].content if isinstance(messages[-1], AIMessage) else \"\"\n",
    "\n",
    "    # Utility flags\n",
    "    is_multiline = len(response.strip().splitlines()) >= 2\n",
    "    no_hallucination = not re.search(r\"\\b(I am an AI|I'm just an AI|I'm a language model)\\b\", response, re.I)\n",
    "    no_generic_response = not any(\n",
    "        phrase in response.lower()\n",
    "        for phrase in [\n",
    "            \"i'm sorry\", \"as an ai\", \"i don't know\", \"i cannot\", \"i'm not sure\", \"this depends\"\n",
    "        ]\n",
    "    )\n",
    "    not_incomplete = not response.strip().endswith(\"...\")\n",
    "    \n",
    "    # -----------------------\n",
    "    # 🧠 1. Factual Q&A (RAG)\n",
    "    # Must cite at least 1 chunk (assume via [1], (source:...), etc.)\n",
    "    has_reference = bool(re.search(r\"\\[\\d+\\]|\\(source:.*?\\)\", response, re.I))\n",
    "\n",
    "    # -----------------------\n",
    "    # 🧠 2. Structured Output (JSON or Pydantic-style)\n",
    "    is_structured = response.strip().startswith(\"{\") and response.strip().endswith(\"}\")\n",
    "    # OR check if it was expected to return structured and fails to do so (up to use case)\n",
    "\n",
    "    # -----------------------\n",
    "    # 🧠 3. Customer Support Bot\n",
    "    has_empathy = any(word in response.lower() for word in [\"understand\", \"sorry\", \"i can help\", \"let me assist\"])\n",
    "    has_solution = any(word in response.lower() for word in [\"please try\", \"you can\", \"we suggest\", \"solution\", \"steps\", \"recommend\"])\n",
    "\n",
    "    # -----------------------\n",
    "    # Global validation logic — you can OR/AND depending on routing\n",
    "    # is_valid = all([\n",
    "    #     is_multiline,\n",
    "    #     no_hallucination,\n",
    "    #     no_generic_response,\n",
    "    #     not_incomplete,\n",
    "    #     has_reference or is_structured or (has_empathy and has_solution)\n",
    "    # ])\n",
    "\n",
    "    # is_valid = all([no_hallucination, not_incomplete])\n",
    "\n",
    "    # Debug logs\n",
    "    # print(\"----Validation Breakdown----\")\n",
    "    # print(\"Multiline:\", is_multiline)\n",
    "    # print(\"No Hallucination:\", no_hallucination)\n",
    "    # print(\"No Generic Response:\", no_generic_response)\n",
    "    # print(\"Not Incomplete:\", not_incomplete)\n",
    "    # print(\"Has Reference:\", has_reference)\n",
    "    # print(\"Is Structured:\", is_structured)\n",
    "    # print(\"Has Empathy:\", has_empathy)\n",
    "    # print(\"Has Solution:\", has_solution)\n",
    "    is_valid = True\n",
    "    \n",
    "    # return {\n",
    "    #     **state,\n",
    "    #     \"validation_passed\": is_valid\n",
    "    # }\n",
    "\n",
    "    print(f\"[validation_router]: END: {state}\")\n",
    "    print(f\"validation_passed: {is_valid}\")\n",
    "    print(\"EXIT from validation_router\")\n",
    "    \n",
    "    state[\"validation_passed\"] = is_valid\n",
    "    print(f\"[validate]: END: validation_passed = {is_valid}\")\n",
    "    return state\n",
    "\n",
    "    # return {\"validation_passed\": True}\n",
    "\n",
    "    # return {'validation_passed': SystemMessage(content=str(is_valid))}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "6fc0fefb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "workflow.add_node('supervisor', supervisor)\n",
    "workflow.add_node('rag', rag)\n",
    "workflow.add_node('llm', llm)\n",
    "workflow.add_node('web', web)\n",
    "workflow.add_node('validation_router', validation_router)\n",
    "\n",
    "workflow.add_conditional_edges('supervisor', router, {\n",
    "    'rag': 'rag',\n",
    "    'web': 'web',\n",
    "    'llm': 'llm'\n",
    "})\n",
    "\n",
    "workflow.add_edge('rag', 'validation_router')\n",
    "workflow.add_edge('llm', 'validation_router')\n",
    "workflow.add_edge('web', 'validation_router')\n",
    "\n",
    "workflow.add_conditional_edges('validation_router', validation_router, {\n",
    "    'pass': '__end__',\n",
    "    'fail': 'supervisor'\n",
    "})\n",
    "\n",
    "workflow.set_entry_point('supervisor')\n",
    "workflow.add_edge(\"validation_router\", END)  # NOT set_finish_point('__end__')\n",
    "\n",
    "app = workflow.compile()\n",
    "display(Image(app.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "5b27d689",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[supervisor]: START: {'messages': [HumanMessage(content='Do you think India will be able to develop there own LLM?', additional_kwargs={}, response_metadata={})], 'validation_passed': False}\n",
      "[supervisor]: END: {'messages': [HumanMessage(content='Do you think India will be able to develop there own LLM?', additional_kwargs={}, response_metadata={})], 'validation_passed': False}\n",
      "messages: llm\n",
      "EXIT from supervisor\n",
      "inside llm node\n",
      "[llm]: START: {'messages': [HumanMessage(content='Do you think India will be able to develop there own LLM?', additional_kwargs={}, response_metadata={}), 'llm'], 'validation_passed': False}\n",
      "question: Do you think India will be able to develop there own LLM?\n",
      "[llm]: END: {'messages': [HumanMessage(content='Do you think India will be able to develop there own LLM?', additional_kwargs={}, response_metadata={}), 'llm'], 'validation_passed': False}\n",
      "messages: content=\"India has the potential to develop its own LLMs, but whether it will successfully create LLMs that are globally competitive is a complex question with no guaranteed answer.  Here's a breakdown of the factors:\\n\\n**Factors Favoring Success:**\\n\\n* **Large and Diverse Linguistic Data:** India has a vast population and a multitude of languages, providing a rich source of data for training LLMs.  This diversity could lead to LLMs better suited for multilingual applications.\\n* **Growing Tech Talent Pool:** India has a large and rapidly growing pool of skilled software engineers and data scientists, providing the human capital necessary for LLM development.\\n* **Government Support:** The Indian government has shown increasing interest in AI and has launched initiatives to promote its development, potentially leading to funding and infrastructure support for LLM projects.\\n* **Existing AI Infrastructure:** India already possesses a developing AI ecosystem with several research institutions and companies working on AI-related technologies.\\n* **Cost Advantage:** Developing LLMs in India can be comparatively cheaper than in countries like the US or Europe, offering a competitive edge.\\n\\n\\n**Factors Hindering Success:**\\n\\n* **Computational Resources:** Training large LLMs requires significant computational power and infrastructure, which can be a constraint for Indian developers. Access to powerful GPUs and data centers might be limited.\\n* **Data Quality and Bias:** While India has abundant data, ensuring its quality and mitigating biases present in the data is crucial for developing fair and reliable LLMs.  This requires careful curation and preprocessing.\\n* **Talent Retention:**  Attracting and retaining top AI talent can be challenging, as many skilled individuals may seek opportunities abroad.\\n* **Research and Development Investment:**  Sustained and significant investment in fundamental AI research is necessary for breakthroughs in LLM technology.  This requires both public and private sector commitment.\\n* **Infrastructure Gaps:**  Reliable and high-speed internet access is crucial for both training and deploying LLMs.  Addressing digital divides within India is essential.\\n\\n\\n**Conclusion:**\\n\\nIndia *can* develop its own LLMs.  The potential is there, driven by its large population, linguistic diversity, and growing tech talent. However, overcoming challenges related to computational resources, data quality, talent retention, and sustained investment will be critical for achieving global competitiveness.  Success will depend on a concerted effort from the government, academia, and the private sector.  It's more likely to see a gradual development of increasingly capable LLMs rather than a sudden, groundbreaking leap.\" additional_kwargs={} response_metadata={'prompt_feedback': {'block_reason': 0, 'safety_ratings': []}, 'finish_reason': 'STOP', 'safety_ratings': []} id='run--b6a4d95d-a870-4865-9dfc-e7bf9049f038-0' usage_metadata={'input_tokens': 33, 'output_tokens': 508, 'total_tokens': 541, 'input_token_details': {'cache_read': 0}}\n",
      "EXIT from llm\n",
      "[validation_router]: START: {'messages': [HumanMessage(content='Do you think India will be able to develop there own LLM?', additional_kwargs={}, response_metadata={}), 'llm', SystemMessage(content=\"India has the potential to develop its own LLMs, but whether it will successfully create LLMs that are globally competitive is a complex question with no guaranteed answer.  Here's a breakdown of the factors:\\n\\n**Factors Favoring Success:**\\n\\n* **Large and Diverse Linguistic Data:** India has a vast population and a multitude of languages, providing a rich source of data for training LLMs.  This diversity could lead to LLMs better suited for multilingual applications.\\n* **Growing Tech Talent Pool:** India has a large and rapidly growing pool of skilled software engineers and data scientists, providing the human capital necessary for LLM development.\\n* **Government Support:** The Indian government has shown increasing interest in AI and has launched initiatives to promote its development, potentially leading to funding and infrastructure support for LLM projects.\\n* **Existing AI Infrastructure:** India already possesses a developing AI ecosystem with several research institutions and companies working on AI-related technologies.\\n* **Cost Advantage:** Developing LLMs in India can be comparatively cheaper than in countries like the US or Europe, offering a competitive edge.\\n\\n\\n**Factors Hindering Success:**\\n\\n* **Computational Resources:** Training large LLMs requires significant computational power and infrastructure, which can be a constraint for Indian developers. Access to powerful GPUs and data centers might be limited.\\n* **Data Quality and Bias:** While India has abundant data, ensuring its quality and mitigating biases present in the data is crucial for developing fair and reliable LLMs.  This requires careful curation and preprocessing.\\n* **Talent Retention:**  Attracting and retaining top AI talent can be challenging, as many skilled individuals may seek opportunities abroad.\\n* **Research and Development Investment:**  Sustained and significant investment in fundamental AI research is necessary for breakthroughs in LLM technology.  This requires both public and private sector commitment.\\n* **Infrastructure Gaps:**  Reliable and high-speed internet access is crucial for both training and deploying LLMs.  Addressing digital divides within India is essential.\\n\\n\\n**Conclusion:**\\n\\nIndia *can* develop its own LLMs.  The potential is there, driven by its large population, linguistic diversity, and growing tech talent. However, overcoming challenges related to computational resources, data quality, talent retention, and sustained investment will be critical for achieving global competitiveness.  Success will depend on a concerted effort from the government, academia, and the private sector.  It's more likely to see a gradual development of increasingly capable LLMs rather than a sudden, groundbreaking leap.\", additional_kwargs={}, response_metadata={})], 'validation_passed': False}\n",
      "[validation_router]: END: {'messages': [HumanMessage(content='Do you think India will be able to develop there own LLM?', additional_kwargs={}, response_metadata={}), 'llm', SystemMessage(content=\"India has the potential to develop its own LLMs, but whether it will successfully create LLMs that are globally competitive is a complex question with no guaranteed answer.  Here's a breakdown of the factors:\\n\\n**Factors Favoring Success:**\\n\\n* **Large and Diverse Linguistic Data:** India has a vast population and a multitude of languages, providing a rich source of data for training LLMs.  This diversity could lead to LLMs better suited for multilingual applications.\\n* **Growing Tech Talent Pool:** India has a large and rapidly growing pool of skilled software engineers and data scientists, providing the human capital necessary for LLM development.\\n* **Government Support:** The Indian government has shown increasing interest in AI and has launched initiatives to promote its development, potentially leading to funding and infrastructure support for LLM projects.\\n* **Existing AI Infrastructure:** India already possesses a developing AI ecosystem with several research institutions and companies working on AI-related technologies.\\n* **Cost Advantage:** Developing LLMs in India can be comparatively cheaper than in countries like the US or Europe, offering a competitive edge.\\n\\n\\n**Factors Hindering Success:**\\n\\n* **Computational Resources:** Training large LLMs requires significant computational power and infrastructure, which can be a constraint for Indian developers. Access to powerful GPUs and data centers might be limited.\\n* **Data Quality and Bias:** While India has abundant data, ensuring its quality and mitigating biases present in the data is crucial for developing fair and reliable LLMs.  This requires careful curation and preprocessing.\\n* **Talent Retention:**  Attracting and retaining top AI talent can be challenging, as many skilled individuals may seek opportunities abroad.\\n* **Research and Development Investment:**  Sustained and significant investment in fundamental AI research is necessary for breakthroughs in LLM technology.  This requires both public and private sector commitment.\\n* **Infrastructure Gaps:**  Reliable and high-speed internet access is crucial for both training and deploying LLMs.  Addressing digital divides within India is essential.\\n\\n\\n**Conclusion:**\\n\\nIndia *can* develop its own LLMs.  The potential is there, driven by its large population, linguistic diversity, and growing tech talent. However, overcoming challenges related to computational resources, data quality, talent retention, and sustained investment will be critical for achieving global competitiveness.  Success will depend on a concerted effort from the government, academia, and the private sector.  It's more likely to see a gradual development of increasingly capable LLMs rather than a sudden, groundbreaking leap.\", additional_kwargs={}, response_metadata={})], 'validation_passed': False}\n",
      "validation_passed: True\n",
      "EXIT from validation_router\n",
      "[validate]: END: validation_passed = True\n",
      "[validation_router]: START: {'messages': [HumanMessage(content='Do you think India will be able to develop there own LLM?', additional_kwargs={}, response_metadata={}), 'llm', SystemMessage(content=\"India has the potential to develop its own LLMs, but whether it will successfully create LLMs that are globally competitive is a complex question with no guaranteed answer.  Here's a breakdown of the factors:\\n\\n**Factors Favoring Success:**\\n\\n* **Large and Diverse Linguistic Data:** India has a vast population and a multitude of languages, providing a rich source of data for training LLMs.  This diversity could lead to LLMs better suited for multilingual applications.\\n* **Growing Tech Talent Pool:** India has a large and rapidly growing pool of skilled software engineers and data scientists, providing the human capital necessary for LLM development.\\n* **Government Support:** The Indian government has shown increasing interest in AI and has launched initiatives to promote its development, potentially leading to funding and infrastructure support for LLM projects.\\n* **Existing AI Infrastructure:** India already possesses a developing AI ecosystem with several research institutions and companies working on AI-related technologies.\\n* **Cost Advantage:** Developing LLMs in India can be comparatively cheaper than in countries like the US or Europe, offering a competitive edge.\\n\\n\\n**Factors Hindering Success:**\\n\\n* **Computational Resources:** Training large LLMs requires significant computational power and infrastructure, which can be a constraint for Indian developers. Access to powerful GPUs and data centers might be limited.\\n* **Data Quality and Bias:** While India has abundant data, ensuring its quality and mitigating biases present in the data is crucial for developing fair and reliable LLMs.  This requires careful curation and preprocessing.\\n* **Talent Retention:**  Attracting and retaining top AI talent can be challenging, as many skilled individuals may seek opportunities abroad.\\n* **Research and Development Investment:**  Sustained and significant investment in fundamental AI research is necessary for breakthroughs in LLM technology.  This requires both public and private sector commitment.\\n* **Infrastructure Gaps:**  Reliable and high-speed internet access is crucial for both training and deploying LLMs.  Addressing digital divides within India is essential.\\n\\n\\n**Conclusion:**\\n\\nIndia *can* develop its own LLMs.  The potential is there, driven by its large population, linguistic diversity, and growing tech talent. However, overcoming challenges related to computational resources, data quality, talent retention, and sustained investment will be critical for achieving global competitiveness.  Success will depend on a concerted effort from the government, academia, and the private sector.  It's more likely to see a gradual development of increasingly capable LLMs rather than a sudden, groundbreaking leap.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Do you think India will be able to develop there own LLM?', additional_kwargs={}, response_metadata={}), 'llm', SystemMessage(content=\"India has the potential to develop its own LLMs, but whether it will successfully create LLMs that are globally competitive is a complex question with no guaranteed answer.  Here's a breakdown of the factors:\\n\\n**Factors Favoring Success:**\\n\\n* **Large and Diverse Linguistic Data:** India has a vast population and a multitude of languages, providing a rich source of data for training LLMs.  This diversity could lead to LLMs better suited for multilingual applications.\\n* **Growing Tech Talent Pool:** India has a large and rapidly growing pool of skilled software engineers and data scientists, providing the human capital necessary for LLM development.\\n* **Government Support:** The Indian government has shown increasing interest in AI and has launched initiatives to promote its development, potentially leading to funding and infrastructure support for LLM projects.\\n* **Existing AI Infrastructure:** India already possesses a developing AI ecosystem with several research institutions and companies working on AI-related technologies.\\n* **Cost Advantage:** Developing LLMs in India can be comparatively cheaper than in countries like the US or Europe, offering a competitive edge.\\n\\n\\n**Factors Hindering Success:**\\n\\n* **Computational Resources:** Training large LLMs requires significant computational power and infrastructure, which can be a constraint for Indian developers. Access to powerful GPUs and data centers might be limited.\\n* **Data Quality and Bias:** While India has abundant data, ensuring its quality and mitigating biases present in the data is crucial for developing fair and reliable LLMs.  This requires careful curation and preprocessing.\\n* **Talent Retention:**  Attracting and retaining top AI talent can be challenging, as many skilled individuals may seek opportunities abroad.\\n* **Research and Development Investment:**  Sustained and significant investment in fundamental AI research is necessary for breakthroughs in LLM technology.  This requires both public and private sector commitment.\\n* **Infrastructure Gaps:**  Reliable and high-speed internet access is crucial for both training and deploying LLMs.  Addressing digital divides within India is essential.\\n\\n\\n**Conclusion:**\\n\\nIndia *can* develop its own LLMs.  The potential is there, driven by its large population, linguistic diversity, and growing tech talent. However, overcoming challenges related to computational resources, data quality, talent retention, and sustained investment will be critical for achieving global competitiveness.  Success will depend on a concerted effort from the government, academia, and the private sector.  It's more likely to see a gradual development of increasingly capable LLMs rather than a sudden, groundbreaking leap.\", additional_kwargs={}, response_metadata={})], 'validation_passed': True}\n",
      "[validation_router]: END: {'messages': [HumanMessage(content='Do you think India will be able to develop there own LLM?', additional_kwargs={}, response_metadata={}), 'llm', SystemMessage(content=\"India has the potential to develop its own LLMs, but whether it will successfully create LLMs that are globally competitive is a complex question with no guaranteed answer.  Here's a breakdown of the factors:\\n\\n**Factors Favoring Success:**\\n\\n* **Large and Diverse Linguistic Data:** India has a vast population and a multitude of languages, providing a rich source of data for training LLMs.  This diversity could lead to LLMs better suited for multilingual applications.\\n* **Growing Tech Talent Pool:** India has a large and rapidly growing pool of skilled software engineers and data scientists, providing the human capital necessary for LLM development.\\n* **Government Support:** The Indian government has shown increasing interest in AI and has launched initiatives to promote its development, potentially leading to funding and infrastructure support for LLM projects.\\n* **Existing AI Infrastructure:** India already possesses a developing AI ecosystem with several research institutions and companies working on AI-related technologies.\\n* **Cost Advantage:** Developing LLMs in India can be comparatively cheaper than in countries like the US or Europe, offering a competitive edge.\\n\\n\\n**Factors Hindering Success:**\\n\\n* **Computational Resources:** Training large LLMs requires significant computational power and infrastructure, which can be a constraint for Indian developers. Access to powerful GPUs and data centers might be limited.\\n* **Data Quality and Bias:** While India has abundant data, ensuring its quality and mitigating biases present in the data is crucial for developing fair and reliable LLMs.  This requires careful curation and preprocessing.\\n* **Talent Retention:**  Attracting and retaining top AI talent can be challenging, as many skilled individuals may seek opportunities abroad.\\n* **Research and Development Investment:**  Sustained and significant investment in fundamental AI research is necessary for breakthroughs in LLM technology.  This requires both public and private sector commitment.\\n* **Infrastructure Gaps:**  Reliable and high-speed internet access is crucial for both training and deploying LLMs.  Addressing digital divides within India is essential.\\n\\n\\n**Conclusion:**\\n\\nIndia *can* develop its own LLMs.  The potential is there, driven by its large population, linguistic diversity, and growing tech talent. However, overcoming challenges related to computational resources, data quality, talent retention, and sustained investment will be critical for achieving global competitiveness.  Success will depend on a concerted effort from the government, academia, and the private sector.  It's more likely to see a gradual development of increasingly capable LLMs rather than a sudden, groundbreaking leap.\", additional_kwargs={}, response_metadata={}), HumanMessage(content='Do you think India will be able to develop there own LLM?', additional_kwargs={}, response_metadata={}), 'llm', SystemMessage(content=\"India has the potential to develop its own LLMs, but whether it will successfully create LLMs that are globally competitive is a complex question with no guaranteed answer.  Here's a breakdown of the factors:\\n\\n**Factors Favoring Success:**\\n\\n* **Large and Diverse Linguistic Data:** India has a vast population and a multitude of languages, providing a rich source of data for training LLMs.  This diversity could lead to LLMs better suited for multilingual applications.\\n* **Growing Tech Talent Pool:** India has a large and rapidly growing pool of skilled software engineers and data scientists, providing the human capital necessary for LLM development.\\n* **Government Support:** The Indian government has shown increasing interest in AI and has launched initiatives to promote its development, potentially leading to funding and infrastructure support for LLM projects.\\n* **Existing AI Infrastructure:** India already possesses a developing AI ecosystem with several research institutions and companies working on AI-related technologies.\\n* **Cost Advantage:** Developing LLMs in India can be comparatively cheaper than in countries like the US or Europe, offering a competitive edge.\\n\\n\\n**Factors Hindering Success:**\\n\\n* **Computational Resources:** Training large LLMs requires significant computational power and infrastructure, which can be a constraint for Indian developers. Access to powerful GPUs and data centers might be limited.\\n* **Data Quality and Bias:** While India has abundant data, ensuring its quality and mitigating biases present in the data is crucial for developing fair and reliable LLMs.  This requires careful curation and preprocessing.\\n* **Talent Retention:**  Attracting and retaining top AI talent can be challenging, as many skilled individuals may seek opportunities abroad.\\n* **Research and Development Investment:**  Sustained and significant investment in fundamental AI research is necessary for breakthroughs in LLM technology.  This requires both public and private sector commitment.\\n* **Infrastructure Gaps:**  Reliable and high-speed internet access is crucial for both training and deploying LLMs.  Addressing digital divides within India is essential.\\n\\n\\n**Conclusion:**\\n\\nIndia *can* develop its own LLMs.  The potential is there, driven by its large population, linguistic diversity, and growing tech talent. However, overcoming challenges related to computational resources, data quality, talent retention, and sustained investment will be critical for achieving global competitiveness.  Success will depend on a concerted effort from the government, academia, and the private sector.  It's more likely to see a gradual development of increasingly capable LLMs rather than a sudden, groundbreaking leap.\", additional_kwargs={}, response_metadata={})], 'validation_passed': True}\n",
      "validation_passed: True\n",
      "EXIT from validation_router\n",
      "[validate]: END: validation_passed = True\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[236]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mlangchain_core\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mmessages\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m HumanMessage\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mapp\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmessages\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mHumanMessage\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcontent\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mDo you think India will be able to develop there own LLM?\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalidation_passed\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mformat_instructions\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mRespond in 2 lines using clear, structured explanation.\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m      7\u001b[39m \u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Learning\\Agentic_AI_V2_Projects\\agentic-RAG-with-supervisor-node\\venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2719\u001b[39m, in \u001b[36mPregel.invoke\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, **kwargs)\u001b[39m\n\u001b[32m   2716\u001b[39m chunks: \u001b[38;5;28mlist\u001b[39m[Union[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], Any]] = []\n\u001b[32m   2717\u001b[39m interrupts: \u001b[38;5;28mlist\u001b[39m[Interrupt] = []\n\u001b[32m-> \u001b[39m\u001b[32m2719\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2720\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   2721\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2722\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2723\u001b[39m \u001b[43m    \u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2724\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_before\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2725\u001b[39m \u001b[43m    \u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterrupt_after\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2726\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcheckpoint_during\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2727\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdebug\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2728\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2729\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2730\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[43m \u001b[49m\u001b[43m==\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mvalues\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m   2731\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2732\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   2733\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mints\u001b[49m\u001b[43m \u001b[49m\u001b[43m:=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mINTERRUPT\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\n\u001b[32m   2734\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Learning\\Agentic_AI_V2_Projects\\agentic-RAG-with-supervisor-node\\venv\\Lib\\site-packages\\langgraph\\pregel\\__init__.py:2436\u001b[39m, in \u001b[36mPregel.stream\u001b[39m\u001b[34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, checkpoint_during, debug, subgraphs)\u001b[39m\n\u001b[32m   2434\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m task \u001b[38;5;129;01min\u001b[39;00m loop.match_cached_writes():\n\u001b[32m   2435\u001b[39m             loop.output_writes(task.id, task.writes, cached=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m2436\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrunner\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtick\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2437\u001b[39m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtasks\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrites\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2438\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mstep_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2439\u001b[39m \u001b[43m            \u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m=\u001b[49m\u001b[43mget_waiter\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2440\u001b[39m \u001b[43m            \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mloop\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccept_push\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   2441\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   2442\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# emit output\u001b[39;49;00m\n\u001b[32m   2443\u001b[39m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01myield from\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2444\u001b[39m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Learning\\Agentic_AI_V2_Projects\\agentic-RAG-with-supervisor-node\\venv\\Lib\\site-packages\\langgraph\\pregel\\runner.py:161\u001b[39m, in \u001b[36mPregelRunner.tick\u001b[39m\u001b[34m(self, tasks, reraise, timeout, retry_policy, get_waiter, schedule_task)\u001b[39m\n\u001b[32m    159\u001b[39m t = tasks[\u001b[32m0\u001b[39m]\n\u001b[32m    160\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m161\u001b[39m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    162\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[43m=\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    165\u001b[39m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    166\u001b[39m \u001b[43m                \u001b[49m\u001b[43m_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    167\u001b[39m \u001b[43m                \u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    168\u001b[39m \u001b[43m                \u001b[49m\u001b[43mretry\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    169\u001b[39m \u001b[43m                \u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m=\u001b[49m\u001b[43mweakref\u001b[49m\u001b[43m.\u001b[49m\u001b[43mref\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfutures\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    170\u001b[39m \u001b[43m                \u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m=\u001b[49m\u001b[43mschedule_task\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    171\u001b[39m \u001b[43m                \u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msubmit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    172\u001b[39m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    174\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    175\u001b[39m     \u001b[38;5;28mself\u001b[39m.commit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Learning\\Agentic_AI_V2_Projects\\agentic-RAG-with-supervisor-node\\venv\\Lib\\site-packages\\langgraph\\pregel\\retry.py:40\u001b[39m, in \u001b[36mrun_with_retry\u001b[39m\u001b[34m(task, retry_policy, configurable)\u001b[39m\n\u001b[32m     38\u001b[39m     task.writes.clear()\n\u001b[32m     39\u001b[39m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m40\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43mproc\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m.\u001b[49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m     42\u001b[39m     ns: \u001b[38;5;28mstr\u001b[39m = config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Learning\\Agentic_AI_V2_Projects\\agentic-RAG-with-supervisor-node\\venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:625\u001b[39m, in \u001b[36mRunnableSeq.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    623\u001b[39m                 \u001b[38;5;28minput\u001b[39m = context.run(step.invoke, \u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m    624\u001b[39m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m625\u001b[39m             \u001b[38;5;28minput\u001b[39m = \u001b[43mstep\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    626\u001b[39m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[32m    627\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Learning\\Agentic_AI_V2_Projects\\agentic-RAG-with-supervisor-node\\venv\\Lib\\site-packages\\langgraph\\utils\\runnable.py:377\u001b[39m, in \u001b[36mRunnableCallable.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    375\u001b[39m         run_manager.on_chain_end(ret)\n\u001b[32m    376\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m377\u001b[39m     ret = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    378\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.recurse \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(ret, Runnable):\n\u001b[32m    379\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m ret.invoke(\u001b[38;5;28minput\u001b[39m, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Learning\\Agentic_AI_V2_Projects\\agentic-RAG-with-supervisor-node\\venv\\Lib\\site-packages\\langgraph\\graph\\branch.py:174\u001b[39m, in \u001b[36mBranch._route\u001b[39m\u001b[34m(self, input, config, reader, writer)\u001b[39m\n\u001b[32m    172\u001b[39m     value = \u001b[38;5;28minput\u001b[39m\n\u001b[32m    173\u001b[39m result = \u001b[38;5;28mself\u001b[39m.path.invoke(value, config)\n\u001b[32m--> \u001b[39m\u001b[32m174\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_finish\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32me:\\Learning\\Agentic_AI_V2_Projects\\agentic-RAG-with-supervisor-node\\venv\\Lib\\site-packages\\langgraph\\graph\\branch.py:210\u001b[39m, in \u001b[36mBranch._finish\u001b[39m\u001b[34m(self, writer, input, result, config)\u001b[39m\n\u001b[32m    207\u001b[39m     result = [result]\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.ends:\n\u001b[32m    209\u001b[39m     destinations: Sequence[Union[Send, \u001b[38;5;28mstr\u001b[39m]] = [\n\u001b[32m--> \u001b[39m\u001b[32m210\u001b[39m         r \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(r, Send) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mends\u001b[49m\u001b[43m[\u001b[49m\u001b[43mr\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m result\n\u001b[32m    211\u001b[39m     ]\n\u001b[32m    212\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    213\u001b[39m     destinations = cast(Sequence[Union[Send, \u001b[38;5;28mstr\u001b[39m]], result)\n",
      "\u001b[31mTypeError\u001b[39m: unhashable type: 'dict'",
      "During task with name 'validate' and id '48496951-28e6-5c04-d780-2509b28b28c2'"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "app.invoke({\n",
    "    \"messages\": [HumanMessage(content=\"Do you think India will be able to develop there own LLM?\")],\n",
    "    \"validation_passed\": False,\n",
    "    \"format_instructions\": \"Respond in 2 lines using clear, structured explanation.\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e4a5ce8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d7d83e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
